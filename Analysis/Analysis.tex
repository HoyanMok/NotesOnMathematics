% Used TeXplate:
% TeXplates/Mathematics.tex
% v0.1.10
% https://github.com/HoyanMok/TeXplates
\documentclass[openany]{book} 
% \documentclass{ctexbook} 如果用中文
% \documentclass[10pt,a4paper]{ctexart}  字体大小和纸张大小，默认分别为10pt和letterpaper
% 五号 = 10.5pt，小四=12pt，四号=14pt
% 其他可选参量如twocolumn, 两行排版
\newcommand{\PATH}{./}

\usepackage{biblatex} %[style=gb7714-2015]{biblatex} 可以选择样式
\addbibresource{Analysis.bib} % 把这里改成实际的文件名

% 令参考资料能够加入目录中:
\defbibheading{bibliography}[\bibname]{% 
	% \addcontentsline{toc}{chapter}{参考文献}
	\chapter{#1}% 
	\markboth{#1}{#1}}

\usepackage[notbib, notindex]{tocbibind} % 解决TOC在TOC中的问题

\usepackage{imakeidx} %索引
	\makeindex[intoc, title={Index}]
	\makeindex[intoc, name=symbol, title={Symbol List}]
	\newcommand*{\indexbf}[1]{\emph{\textbf{#1}}\index{#1}} % Index for definition
	\newcommand*{\indexmath}[2][\ ]{#2\index[symbol]{#1@$#2$}} % Used Symbol
	% \indexmath[name for sort]{display} 

% 将PATH换成绝对路径 (Windows) 或相对路径 (Mac OS或Linux)
% 使用「/」而不是「\」

% 对目录项等的修改
\usepackage{chngcntr}
	\counterwithout{section}{chapter} % So that the section won't reset when newing a chapter
\renewcommand{\thesection}{\textmd{\S}\arabic{section}}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}


% 引用的宏包:
% 宏包的使用, 可以在命令行运行texdoc <宏包名>获得文档
\usepackage{multicol} % 分栏 (全局分栏建议在文档类处设置)
\usepackage{amsmath} % AMS数学标准
	\makeatletter % '@' now normal "letter"
	\@addtoreset{equation}{section} % 每次换section就把equation清零
	\makeatother  % '@' is restored as "non-letter"
	\renewcommand\theequation{\oldstylenums{\arabic{section}}%
					-\oldstylenums{\arabic{equation}}} % 显示为section数-equation数
\usepackage{amsthm} %定义、证明、定理等
	\theoremstyle{plain}
		\newtheorem{axiom}{Axiom} %公理
		\newtheorem{theorem}{Theorem}[section] %定理
		\newtheorem{corollary}{Corollary} %推论
		\newtheorem{lemma}{Lemma} %引理
	\theoremstyle{definition}
		\newtheorem{definition}{Definition}[section] %定义
		\newtheorem{proposition}{Proposition} %命题
	\renewcommand{\proofname}{\textbf{Proof}}

\renewcommand{\thetheorem}{%
	\arabic{section}.\arabic{theorem}%
} % 公式编号不显示`\S`
\renewcommand{\thedefinition}{%
	\arabic{section}.\arabic{definition}%
} % 定义编号不显示`\S`
\usepackage{amssymb} % 数学符号
\usepackage{mathrsfs} % 花体
\usepackage{esint} % 积分
\usepackage{siunitx} % 标准SI数值和单位处理

\usepackage{tikz} % 绘图
\usepackage{float} % 浮动体 (供图片, 表格等) 扩展, 主要用于提供h模式
\usepackage{graphicx} % 插入图片
\usepackage{titlepic}
\usepackage[font=small, skip=5pt]{caption} % 缩小题注字体和题注与图片距离
\usepackage{subcaption} % 子图和子图的题注
\usepackage{svg} % svg位图
\usepackage{wrapfig} % 简单的图文绕排
\usepackage[inline]{enumitem} % 编号
	% 新列表:
	\newlist{conditionlist}{enumerate}{2}
	\setlist[conditionlist,1]{topsep = 0pt, itemsep = 0pt, parsep = 0pt,%
		label=\arabic*), leftmargin=2\parindent}
	\setlist[conditionlist,2]{topsep = 0pt, itemsep = 0pt, parsep = 0pt,%
		label=\alph*), leftmargin=3\parindent}
\usepackage{geometry} % 调整页边距
% \geometry{left=1.6cm,right=1.6cm}
\usepackage{xcolor} % 颜色
\usepackage[colorlinks=true,bookmarks=true]{hyperref} % 引用, 交叉引用, 图表等的链接; 生成书签
\hypersetup{linkcolor=[rgb]{1,0.27,0},bookmarksopen = true}% 更多设置请查阅: texdoc hyperref


% 定义一些笔者常用的指令:
\newcommand{\me}{\mathrm{e}} % 自然对数的底
\newcommand{\mi}{\mathrm{i}} % 虚数单位
\newcommand{\dif}{\mathop{}\!\mathrm{d}} % 微分算子d
\newcommand*{\basis}[1]{\hat{\boldsymbol{#1}}} % 基底
\newcommand*{\bv}{\boldsymbol} % 向量加粗
\newcommand*{\IFF}{\;\leftrightarrow\;} % 充要条件

\newcommand*{\diff}[3][1]
{\if#11%
	\frac{\mathrm{d} #2}{\mathrm{d} #3}% 导数\diff{y}{x}
\else%
	\frac{\mathrm{d}^{#1} #2}{\mathrm{d} {#3}^{#1}}% n阶导数\diff[n]{y}{x}
\fi}
\newcommand*{\pdiff}[3][1]
{\if#11%
	\frac{\partial #2}{\partial #3}% 偏导数\pdiff{y}{x}
\else%
	\frac{\partial^{#1} #2}{\partial {#3}^{#1}}% n阶偏导数\pdiff[n]{y}{x}
\fi}
\newcommand{\emphbf}[1]{\emph{\textbf{#1}}}
% \indexbf 的定义见前imakeidx的引用下

% 笔者习惯的运算符:
\DeclareMathOperator{\tg}{tg}
\DeclareMathOperator{\ctg}{ctg}
\DeclareMathOperator{\arctg}{arctg}
\DeclareMathOperator{\sh}{sh}
\DeclareMathOperator{\ch}{ch}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\SO}{SO}
\DeclareMathOperator{\SU}{SU}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Inn}{Inn}
\DeclareMathOperator{\id}{id}
% \DeclareMathOperator*{\指令}{显示} 
% 带星号的版本会像\lim一样

% 文章标题页信息:
\title{Analysis}
\author{Hoyan Mok\thanks{E-mail: victoriesmo@hotmail.com}
}
\date{\today} % 自动生成日期
\begin{document}
\pagenumbering{Alph}
\maketitle % 打印标题
\frontmatter
\chapter{Preface}
The latest version: \url{https://github.com/HoyanMok/NotesOnMathematics/tree/master/Analysis} .

\tableofcontents

\mainmatter
\part{Mathematical Analysis}

\chapter{Metric Space and Continuous Mapping}

\section{Metric Space}
\begin{definition}[Metric]\label{definition: metric} 
	A function
	\begin{equation*}
		d \colon X^2 \to \mathbb R
	\end{equation*}
	$\forall x, y, z\in X$ satisfying: 
	\begin{conditionlist}[label=\alph*)]
	\item	$d(x, y)=0 \IFF x = y$;
	\item	$d(x, y)=d(y, x)$ (symmetry);
	\item	$d(x, z) \leq d(x,y)+d(y,z)$ (triangle inequality),
	\end{conditionlist}
	is called a \indexbf{metric} or \indexbf{distance} in $X$. 
	Such $X$ is said to be equiped with a metric $d$, $\indexmath[X d]{(X, d)}$ is called a \indexbf{metric space}. 
	If the metric defined over $X$ is definite, we just simply call the $X$ the metric space.
\end{definition}

Some examples:
\begin{itemize}
	\item 
	We can define $\indexmath[R n p]{\mathbb R^n_p} := (\mathbb R^n, \indexmath[d p]{d_p})$, where
	\begin{equation}\label{equation:d_p}
		d_p (x, y) := \left(
			\sum_{i \in n}\big|x^i - y^i \big|^p \right)^{1/p}\,,
	\end{equation}
	while
	\begin{equation}\label{equation:d_infty}
		\indexmath[d infty]{d_\infty} (x, y) :=
		\max_{i \in n} \big|x^i - y^i\big|\,.
	\end{equation}
	\item 
	Similarly we can define metric spaces as $(C[a, b], d_p)$ or simplified $\indexmath[C p a b]{C_p[a, b]}$. 
	\begin{equation}
		d_p(f, g) =
		\left(
			\int^b_a \big| f - g \big|^p \dif x
		\right)^{1/p}\,.
	\end{equation}
	while $\indexmath[C infty a b]{C_\infty [a, b]}$ is called a \indexbf{Chebyshev metric}, 
	where the metric is defined as $d_\infty(f, g) := \max_{x \in [a, b]} |f(x) - g(x)|$.
	\item 
	On equivalence class $\tilde {\mathfrak R}[a,b]$ over $\mathfrak R[a,b]$ similar metric can be defined. 
	Functions are considered equicalent if they are equal up to a null set. 
\end{itemize}

\begin{lemma}[Quadruple inequality]\label{lemma: quadruple inequality}
	Let $(X, d)$ be a metric space. 
	\begin{equation}\label{equation: quadruple inequality}
		\forall a, b, u, v \in X,\; \big| d(a, b) - d(u, v) \big| \leq d(a, u) + d(b, v) 
	\end{equation}
\end{lemma}
\begin{proof}
	Without loss of generality, we assume that $d(a, b) > d(u, v)$. 
	According to the triangle inequality (see def.~\ref{definition: metric}), $d(a, b) \leq d(a, u) + d(u, v) + d(v,b)$, which is to prove.  
\end{proof}

\begin{definition}[$\delta$-ball]\label{definition: delta ball}
	Let $(X, d)$ be a metric space, and $\delta \in \mathbb R_+$, $a \in X$. 
	A set
	\begin{equation*}
		\indexmath[B a delta]{B(a; \delta)} = \{x \in X \mid d(a, x) < \delta\}
	\end{equation*}
	is then called a \indexbf{ball} with a centre at $a \in X$ and a radius of $\delta$, or a \emphbf{ball} of point $a$.
\end{definition}

\begin{definition}
	The \indexbf{diametre} of a set $A \subset X$, is defined as:
	\begin{equation*}
		d(A) := \sup \{d(x, y) \mid x, y \in A\}.
	\end{equation*}

	The distance between a set and a point, and the distance between sets are defined as:\
	\begin{equation*}
		d(A, a) := \inf\{d(x, a) \mid x \in A\},
		\quad
		d(A, B) := \inf\{d(x, y) \mid x \in A, y \in B\}.
	\end{equation*}
\end{definition}

\begin{definition}[Open set]\label{definition: open set (metric)}
	An \indexbf{open set}~$G \in 2^X$ in a metric space~$(X, d)$ is a set that satisfies: 
	$\forall x\in G$, $\exists \delta \in \mathbb R_+$, s.t.\ $B(X, \delta) \in 2^G$.
\end{definition}

\begin{definition}[Closed set]\label{closed_set}
	A \indexbf{closed set}~$F \in 2^X$ in a metric space~$(X, d)$ is a set that satisfies: 
	$X - F$ is an open set in $(X, d)$.
\end{definition}

A \indexbf{closed ball}~$\indexmath[tilde B x delta]{\tilde B(X, \delta)} := \{x \in X \mid d(a, x) \leq r \}$ is an example of closed sets in $(X, d)$.

\begin{proposition}\label{proposition: open sets (metric)}
	\begin{conditionlist}[label=\alph*)]
	\item An infinite union of open sets is an open set.
	\item A definite intersection of open sets is an open set.
	\item A definite union of closed sets is a closed set.
	\item An infinite intersection of closed sets is a closed set.
	\end{conditionlist}
\end{proposition}
\begin{proof}
	Let $\forall \alpha \in A$, $G_\alpha$ be open sets.
	\begin{enumerate}[label=\alph*)]
		\item
			$\forall x \in \bigcup_{\alpha \in A} G_\alpha$, $\exists \alpha \in A$ s.t.\ $x \in G_\alpha$. 
			Since $G_\alpha$ is open, $\exists \delta \in \mathbb R_+$ s.t.\ $B(X, \delta) \subset G_\alpha \subset \bigcup_{\alpha \in A} G_\alpha$.
		\item 
			Let $G_1$, $G_2$ be open sets in $(X, d)$. 
			$\forall a \in G_1 \cap G_2$, $\exists \delta_1, \delta_2 \in \mathbb R_+$ s.t.\ $B(a; \delta_1) \subset G_1$, $B(a;\delta_2)\subset G_2$. 
			Without loss of generality, let $\delta_1 \geq \delta_2$, therefore $a \in B(a; \delta_1)\cap B(a; \delta_2) = B(a; \delta_2) \subset G_1 \cap G_2$.
		\item 
			Just consider $\complement_X
			\left(\bigcap_{\alpha\in A}F_\alpha\right)
			=\bigcup_{\alpha\in A}\complement_X(F_\alpha)$ and a).
		\item 
		Similarly, $\complement_X\left(F_1\cup F_2\right)=\complement_X(F_1)\cap\complement_X(F_2)$.
	\end{enumerate}
\end{proof}

\begin{definition}[Neighbourhood]\label{definition: neighbourhood (metric)}
	If $x \in X$ is an element of an open set, then such open set is called a \indexbf{neighbourhood} of point $x$ in $X$, denoted by $\indexmath[U x]{U(x)}$.
	The collection of all neighbourhoods of $x$ can be denoted by $\indexmath[U x]{\mathscr U(x)}$.
\end{definition}

\begin{definition}[Interior point]\label{definition: interior point (metric)}
	Let $x \in X$, $E \subset X$.
	\begin{conditionlist}[label=\alph*)]
	\item If $\exists U(x) \subset E$, $x$ is called an \indexbf{interior point} of $E$.
	\item If $\exists U(x) \subset X - E$, $x$ is called an \indexbf{exterior point} of $E$.
	\item If $x$ isn't an interior point nor exterior point of $E$, it is called a \indexbf{boundary point} of $E$. The set of boundary points is called \indexbf{boundary}, denoted by $\indexmath[partial E]{\partial E}$.
\end{conditionlist}
\end{definition}

\begin{definition}[Limit point]\label{definition: limit point (metric)}
	$a \in X$, $E \subset X$. If $\forall U(a)$, $\card\big(E \cap U(a) \big) = \infty$, $a$ is called a \indexbf{limit point} of $E$.
\end{definition}

\begin{definition}[Closure]\label{definition: closure (metric)}
	The intersections of $E \subset X$ and set of all its limit points is called the \indexbf{closure} of $E$, denoted by $\indexmath[overline]{\overline E}$.
\end{definition}

\begin{theorem}\label{theorem: closed sets' closure (metric)}
	Let $F\in 2^X$.
	$F$ is a closed set in $X$ $\IFF$ $\overline F = F$.
\end{theorem}
\begin{proof}
	$\to$: 
	$\complement_X(F)$ is open, hence its elements are all its interior points. 
	Therefore $\overline F - F = \overline F \cup \complement_X(F) = \varnothing$, also we know that $F \subset \overline F$, hence $F = \overline F$.

	$\gets$: 
	$F = \overline F$ means that $\forall x \in \complement_X(F)$, $x$ is not a boundary of $F$, which implies that $x$ is an interior point of $X - F$. Therefore $X - F$ is open while $F$ is closed.
\end{proof}

\begin{theorem}\label{theorem: closure is closed (metric)}
	$\overline E$ is always closed.
\end{theorem}
\begin{proof}
	$\forall x \in X - \overline E$, since it is not an element of the set $E$ nor its limit points, $\exists U(x) $ s.t.\ $U(x) \cap \overline E =\varnothing$, which implies that $x$ is an extorior point of $E$, therefore $\overline E$ is closed.
\end{proof}

\begin{theorem}\label{theorem: closure's closure}
	$\overline E = \overline{ \overline E}$.
\end{theorem}
\begin{proof}
	Since $\overline E$ is closed, its complement is open, which implies that its elements are all exterior points of $\overline E$, therefore $\overline E$ has contained all of its limit points.
\end{proof}

\begin{definition}(Metric subspace)\label{definition: metric subspace}
	We called $(X', d')$ a \indexbf{subspace} of $(X, d)$ when $X' \subset X$ and $\forall x, y \in X'$, $d'(x, y)=d(x, y)$.
\end{definition}

\section{Topological Space}

\begin{definition}[Topology]\label{definition: topology}
	We say $X$ is epuiped with a \indexbf{topology} if we assigned a $\mathscr T \subset 2^X$, with the following propoties:
	\begin{conditionlist}[label=\alph*)]
		\item 
		$\varnothing \in \mathscr T$; 
		$X \in \mathscr T$.
		\item 
		$\big(\forall \alpha \in A, G_\alpha \in \mathscr T\big)
			\to \bigcup_{\alpha \in A} G_\alpha \in \mathscr T$.
		\item $\forall G_1, G_2 \in \mathscr T$, $G_1 \cap G_2 \in \mathscr T$.
	\end{conditionlist}

	We call $\indexmath[X T]{(X, \mathscr T)}$ a \indexbf{topological space}, and sometimes we might simply call $X$ the topological space.
\end{definition}

These conditions is the intrinsic propoties of the open sets we have defined in the metric space%
	\footnote{See proposition~\ref{proposition: open sets (metric)}%
		}. 
The topology consisting of all the open sets defined in the metric space $(\mathbb R; d_2)$ is called the \indexbf{standard topology} of the $n$-dimension Euclidean space.

\begin{definition}[Open set]\label{definition: open set (topology)}
	Topology $\mathscr T$'s elements are called \emphbf{open sets}%
		\index{open set}%
	, and their complements are called \emphbf{closed sets}%
		\index{closed set}%
	.
\end{definition}

\begin{definition}[Base]\label{definition: base}
	Let $(X, \mathscr T)$ be a topological space, and $\mathfrak B \subset 2^X$. 
	If $\forall G \in \mathscr T$, $\exists \{B_\alpha\}_{\alpha \in A} \in 2^\mathfrak B$ s.t.\ $\bigcup_{\alpha \in A} B_\alpha = G$, we called $\mathfrak B$ a (topological or open) \indexbf{base}%
		\index{topological base}\index{open base} 
		of the topology $\mathscr T$.
\end{definition}

\begin{definition}[Weight]\label{definition: weight}
	The smallest possible cardinity of a base of a topology is called the \indexbf{weight} of the topological space.
\end{definition}

\begin{definition}[Neighbourhood]\label{definition: neighbourhood (topology)}
	If $x \in U(x)$ and $U(x) \in \mathscr T$, then $\indexmath[U x]{U(x)}$ is a \indexbf{neighbourhood} of $x$ in topological space $(X, \mathscr T)$. 
	All neighbourhoods of a point $x$ is denoted by $\indexmath[U x]{\mathscr U(x)}$.

	If $\indexmath[U x]{\mathring U(x)} := U(x) - \{x\} \neq \varnothing$, then it is a \indexbf{deleted neighbourhood}. 
	The collection of deleted neighbourhoods of $x$ is denoted as $\mathring{\mathscr U} (x)$.
\end{definition}

For example, we define an equivalence relation $\sim$ in $C(\mathbb R;\mathbb R)$. If $f, g\in C(\mathbb R; \mathbb R)$, at point $a \in \mathbb R$:
\begin{equation}\label{equation: germ}
	f \sim_a g \IFF
			\exists U(a) \big(\forall x \in U(a),\; f(x) = g(x)\big)\,.
\end{equation}

By collecting all of the continuous functions that are euivalent to $f$, 
we call $f$ define a \indexbf{germ} at point $a$, denoted by $f_a$.
If $f \in C(\mathbb R; \mathbb R)$ is defined in $U(a)$, then we can call $\{f_x \mid x \in U(a)\}$ a neighbourhood of germ $f_a$. 
Class of neighbourhoods of each $f_x$ constructs a base of topological space $(C(\mathbb R; \mathbb R); \mathscr T)$, where $\mathscr T$ is made of the sets of germs of continuous function in $C(\mathbb R; \mathbb R)$.



\begin{definition}[Hausdorff space]\label{definition: Hausdorff space}
	We call a topological space $(X, \mathscr T)$ a \indexbf{Hausdorff space}, \indexbf{separated space} or \indexbf{$\mathrm T_2$ space}, if $\forall x,y \in X$, $x \neq y \to \big( \exists U(x), U(y)$ s.t.\ $U(x) \cap U(y) = \varnothing \big)$%
		\footnote{This definition is also called \indexbf{Hausdorff axiom} or \indexbf{separation axiom}. }%
	.
\end{definition}

\begin{definition}[Dense set]\label{definition: dense set}
	$E \subset X$ is a \indexbf{dense set} in the topological space $(X, \mathscr T)$, if $\forall x \in X$, $\forall U(x)$, $U(x) \cap E \neq \varnothing$.
\end{definition}

\begin{definition}[Separable]\label{definition: separable}
	If there is a \emph{countable} dense set in topological space $(X, \mathscr T)$, then $(X,\mathscr T)$ is \indexbf{separable}.
\end{definition}

We can also define interior points, exterior points, boundary points, limit points in topological space as in metric space.

\begin{definition}[Topological subspace]\label{subspace (topology)}
	Each subset $Y$ of $X$ equiped with topology $\mathscr T$ can be given a \indexbf{subspace topology} $\mathscr T_Y$ whose elements $G_Y$ are intersections of the subset with an open set $G$ in $(X, \mathscr T)$ i.e.\ $\forall G_Y \in \mathscr T_Y$, $\exists G \in \mathscr T$ s.t.\ $G_Y = G \cap Y$. 
	Subsets equiped with such topology construct a \emphbf{topological subspace}%
		\index{subspace}%
		~$(Y, \mathscr T_Y)$. 
\end{definition}

If two topology~$\mathscr T_1, \mathscr T_2$ are defined on the same $X$, $\mathscr T_1$ is said to be \indexbf{stronger} than $\mathscr T_2$ if $\mathscr T_1 \subsetneqq \mathscr T_2$.

\begin{definition}[Direct product]\label{definition: direct product}
	Let $(X_1, \mathscr T_1)$ and $(X_2, \mathscr T_2)$ be two topological spaces. 
	Their \indexbf{direct product} is defined as $(X_1 \times X_2, \mathscr T)$, where $\mathscr T$ has a basis $\mathscr B := \{ G_1 \times G_2 \mid G_1 \in \mathscr T_1 \wedge G_2 \in \mathscr T_2\}$.
\end{definition}

\section{Compact Set}

\begin{definition}[Open cover]\label{definition: open cover}
	Let $(X, \mathscr T)$ be a topological space, $K \in 2^X$ and $\varOmega \in 2^\mathscr T$. We call $\varOmega$ to be an \indexbf{open cover} over $K$, if $K \subset \cup \varOmega$. 
	If there are two open covers~$\varOmega$, $\varOmega'$ over $K$, and $\varOmega' \subset \varOmega$, we say that $\varOmega'$ is a \indexbf{subcover} of $\varOmega$.
\end{definition}

\begin{definition}[Compact set]\label{definition: compact set}
	A set~$K \in 2^X$ in topological space $(X, \mathscr T)$ is called a \indexbf{compact set} if each of its open covers has a \emph{finite} subcover. 
\end{definition}

Specially, $\varnothing$ is compact.

\begin{theorem}\label{theorem: compact iff compact in subspace}
	A set $K \subset X$ is compact in $(X,\mathscr T)$ \emphbf{iff} $K$ is compact in $(K, \mathscr T_K)$ itself. 
\end{theorem}

This theorem tells a truth that whether $K$ is compact or not doesn't dependent on the topological space it's in. 
This fact can be easily proved: we just need to notice that every open set $G_K$ in $(K, \mathscr T_K)$ is an intersection of an open set $G$ in $(X, \mathscr T)$ and $K$. 

\begin{theorem}[Compact $\to$ closed (Hausdorff)]\label{theorem: compact sets are closed in Hausdorff space}
	If $K$ is compact in a Hausdorff space $(X, \mathscr T)$%
		\footnote{See definition~\ref{definition: Hausdorff space}. }%
	, then $K$ is a closed set in $(X, \mathscr T)$.
\end{theorem}
\begin{proof}
	Let $x_0$ be a limit point of $K$, which means $\forall U(x_0)$, 
	\[
		\card U(x_0)\cap K \notin \mathbb{N}.
	\]

	Assume that $x_0 \notin K$. 
	In a Hausdorff space, $\forall x \in K - \{x_0\}$, $\exists U(x)$ s.t. $U(x)\cap U(x_0)=\varnothing$. 
	Such $U(x)$ construct an open cover $\varOmega=\left\{U(x)|x\in K \right\}\subset 2^K$. 
	Since $K$ is compact, $\exists \varOmega' \subset \varOmega$ s.t.\ $\card \Omega \in \mathbb{N}$. 
	\[
		\left(\cup\Omega'\right)
		\cap U(x_0)
		=
		\left(\bigcup_{k=1}^n{U_k}\right)
		\cap U(x_0)
		=
		\bigcup_{k=1}^n\left(
			U_k\cap U(x_0)
		\right)
		=
		\varnothing\,.
	\]

	Since $K\subset \cup \Omega'$, $x_0$ is an exterior point of $K$, which leads to a contradiction. 

	Hence $x_0 \in K$. $\overline K = K$.
\end{proof}

\begin{theorem}\label{theorem: compact nested sequences have non-empty limit}
	Each decreasing \emph{\textbf{nested sequences}}\index{nested sequence} of non-empty compact sets has a non-empty limit, i.e.\ 
	$\forall (K_n)_{n \in \mathbb N} \in \mathscr P(X)^\mathbb N$ s.t.\ $\forall n \in \mathbb N_+$, $K_n \supset K_{n+1}\wedge K_n \neq \varnothing$ $\wedge$ ($K_n$ is compact): 
	$K_n \downarrow K \neq \varnothing$.
\end{theorem}
\begin{proof}
	Assume that $K = \varnothing$. 
	Compact subsets of $K_1$ are all colsed, while their complements are all open. An open cover $\varOmega$ can be constructed as $\{K_1 - K_n \mid n \in \mathbb N_+\}$. 
	Since $K_1$ is compact, there would be a finite subcover $\varOmega' \subset \varOmega$, notice that $(X - K_n)_{n \in \mathbb N}$ is also a nested sequence, there must be one single $X - K_{n_0} \in \varOmega'$ that covers $K_1$, which means $K_{n_0} = \varnothing$ contradicting that $\forall n \in \mathbb N_+$, $K_n$ is non-empty.
\end{proof}

\begin{theorem}\label{theorem: closed subset of compact set}
	A Closed subset $F$ of a compact set $K$ is also compact.
\end{theorem}
\begin{proof}
	If $\varOmega_F \subset 2^K$ is an open cover of $F$. 
	Notice that $K - F$ is open, $\varOmega = (\cup \varOmega_F) \cap \{K - F\}$ constructs an open cover over over $K$. 
	Since $K$ is compact there must be a finite cover $\varOmega' \subset \varOmega$ which obviously also covers over $F$.
\end{proof}

The following propoties of compact sets are about topological spaces induced from metric spaces.

\begin{definition}[net]\label{defintion: e-net}
	$(X, d)$ is a metric space, $E \in 2^X$. 
	$E$ is called an \indexbf{$\varepsilon$-net} if $\forall x \in X$,$\exists e \in E$, $d(e, x) < \varepsilon$.
\end{definition}

\begin{theorem}[Finite $\varepsilon$-net exists]\label{theorem: finite e-net exists (metric, compact)}
	If $(K, d)$ is a compact metric space, then $\forall \varepsilon \in \mathbb R_+$, $\exists$ \emph{finite} $\varepsilon$-net in $(K, d)$. 
\end{theorem}
\begin{proof}
	For each point $x\in K$, find it a $B(x,\varepsilon)$, of which an infinite cover $\Omega$ over $K$ is made. 
	Since $K$ is compact, there exists a finite subcover $\varOmega' = \{B(x_i,\varepsilon)\}_{i \in n}$ ($n \in \mathbb N_+$). Therefore $\{x_i\}_{i \in n}$ is a finite $\varepsilon$-net in $K$.
\end{proof}

\begin{theorem}[Sequentially compact]\label{theorem: sequentially compact iff compact (metric)}
	A metric space~$(K, d)$ is compact \emphbf{iff} it is \indexbf{sequentially compact}, 
	that is, $\forall (x_n)_{n \in \mathbb N} \in K^\mathbb N$, it has a convergent subsequence $(x_{k_n})_{n \in \mathbb N}$ 
		($k_n \in \mathbb N$; $k_{n+1} > k_n$)
	whose limit $a \in K$.
\end{theorem}

To prove Theorem~\ref{theorem: sequentially compact iff compact (metric)}, we need to prove two lemmata first.

\begin{lemma}\label{lemma: finite e-net exists (metric, sequentially compact)}
	If $(K, d)$ is sequentially compact, then $\forall \varepsilon \in \mathbb R_+$, $\exists$ finite $\varepsilon$-net in $(K, d)$. 
\end{lemma}
\begin{proof}
	Assume that $\exists \varepsilon_0 \in \mathbb R_+$, there were no finite  $\varepsilon_0$-net in $(K, d)$. 
	Define such sequence: $ (x_n)_{n \in \mathbb N}$ s.t.\ $\forall n \in \mathbb N \; \forall k \in n$, $d(x_n, x_k) \geq \varepsilon_0$ 
		(There would always be a next one since there exists no finite $\varepsilon_0$-net or $\{B(x_n; \varepsilon_0)\}_{n \in N}$ gives such). 
		It has no convergent subsequence: 
		if there were a $(x_{k_n})_{n \in \mathbb N}$ convergent to $a\in K$, $\exists N,M\in\mathbb{N}_+$, $d(x_N, x_M)\leq d(x_N, a)+d(x_M, a)\leq \varepsilon_0$, which lead to a contradictary. 
\end{proof}

\begin{lemma}\label{lemma: intersection of closed nested sequence (sequentially compact)}
	If $(K, d)$ is sequentially compact then every nested sequence of closed non-empty sets $\{F_n\}_{n \in \mathbb N}$ in $K$ have a non-empty intersection.
\end{lemma}
\begin{proof}
	Let $(x_{k_n})_{n \in \mathbb N}$ be a convergent subsequence of $(x_n)_{n \in \mathbb N}$, where $\forall n \in \mathbb N$, $x_n \in F_n$. 
	Let $a$ be the limit of $(x_{k_n})_{n \in \mathbb N}$. 

	Assume that $a \notin \bigcap_{n \in \mathbb N} F_n$, in a metric space, $\exists U(a) \in \mathscr U(a)$ s.t.\ $U(a) \cap \big(\bigcap_{n \in \mathbb N} F_n \big) = \varnothing$, therefore $U(a) \cap \big(\bigcap_{n \in \mathbb N} F_{k_n} \big)=\varnothing$. 
	But this conflict the fact that $\exists N \in \mathbb N$, s.t.\ $n > N \to x_{k_n}\in U(a)$ while $x_{k_n} \in F_{k_n}$.
\end{proof}

Then we get back to the Theorem~\ref{theorem: sequentially compact iff compact (metric)}. 
\begin{proof}

	$\to$: 
	If $\card \{x_n\}_{n \in \mathbb N} \in \mathbb N$, it is obvious; 
	Now we let $\card \{x_n\}_{n \in \mathbb N} \notin \mathbb N$. 
	We can always find finite $1/k$-net~$\{B(a_{k, i}, 1/k)\}_{i \in m}$
		(Theorem~\ref{theorem: finite e-net exists (metric, compact)}, 
			$m \in \mathbb N$, $a_i \in K$)%
	, for all $k \in \mathbb N_+$. 
	For each $k$, there must be at least one $B(a_{k, i_0}; 1/k)$
		(for simplication, we denote $a_{k, i_0}$ by $a_k$)
	that includes infinite elements in $(x_n)_{n \in \mathbb N}$. 
	$\forall n \in \mathbb N_+$
		(let $k_0 = 0$), 
	select $x_{k_n} \in B(a_{n, 0}; 1/n)$, and $\{\overline B(x_n; 1/k)\}$ is a nested sequence of a closed non-empty sets in sequentially compact $K$,
		(Lemma~\ref{lemma: intersection of closed nested sequence (sequentially compact)})
	$\lim_{n\to \infty} x_{k_n} \in K$.
	
	$\gets$: 
	Assume that there were an open cover $\varOmega$ over $K$ having no finite subcover, $\forall n \in \mathbb N_+$, $\exists$ finite $1/n$-net 
		(Lemma~\ref{lemma: intersection of closed nested sequence (sequentially compact)})%
	, in which there would be at least one $x_n$ whose $\overline B(x_n;\frac{1}{n})$ can't be covered finitely. 
	Then $\overline B(x_n; 1/n) \downarrow B = \{a\}$ 
		(Theorem~\ref{theorem: compact nested sequences have non-empty limit})
	can't be finitely covered by any subcover of $\varOmega$, 
	which means $\varOmega$ can't cover the whole $K$, leading to the contradiction.
\end{proof}

We now prove a very useful special case for compact sets: compact sets in $\mathbb R$.

\begin{lemma}[$n$-dimemsional cuboids are compact]
	\label{lemma: n-dimensional cuboids are compact}
	Let $I$ be a cuboid in $\mathbb R^n$ i.e.\ 
	\begin{equation*}
		I := \{\bv x \in \mathbb R_n \mid a_i \leq x_i \leq b_i, \forall i \in n\}\,.
	\end{equation*}
	The cuboid $I$ is compact.
\end{lemma}
\begin{proof}
	We only need to prove that $I$ is sequentially compact (Theorem~\ref{theorem: sequentially compact iff compact (metric)}). 
	Let $(\bv x_i)_{i \in \mathbb N} \in I^\mathbb N$. 
	
	Denote $S_0 := I$.
	We divide $S_m$ ($m \in \mathbb N$) into $2^n$ parts by equally dividing every $I_i := \{\bv x \in \mathbb R_n \mid a_i \leq x_i \leq b_i\}$ into two. 
	Choose one that contains inifinite points of $(\bv x_i)_{i \in \mathbb N}$ as $S_{m+1}$. 
	Then we get a closed nested sequence $S := (S_i)_{i \in \mathbb N}$.
	Notice that $\forall i \in \mathbb N$, $S_i$ can be conceived as a product of $n$ 1-dimension intervals. These intervals are also closed nested sequence, but in $\mathbb R$. 
	We have leaned that $\exists! \bv \xi := (\xi_i)_{i \in n}$ s.t.\ $\{\bv \xi\} := \bigcap S$ from the theory of real numbers.

	In every $S_k$ we can find a $\bv x_{i_k}$, which is a convergent subsequence of the arbitary sequence~$(\bv x_i)_{i \in \mathbb N}$.
\end{proof}

\begin{theorem}[Compact iff closed and bounded in $\mathbb R^n$]
	\label{theorem: compact iff closed and bounded in Rn}
	Let $K \in \mathscr P(\mathbb R^n)$, $n \in \mathbb N_+$.
	The set~$K$ is compact \emph{iff} it is closed and bounded.
\end{theorem}
\begin{proof}
	$\to$: 
	We have proved that compact sets are closed in a Hausdorff space (Theorem~\ref{theorem: compact sets are closed in Hausdorff space}). 
	Now we prove that $K$ is also bounded. 
	Let $\bv x \in \mathbb R^n$, and we could find an open covers of $K$: 
	\begin{equation*}
		\varOmega := \{B(\bv x; n) \mid n \in \mathbb N_+\}\,.
	\end{equation*}

	Assume that we find a finite subcover $\varOmega' := \{B(\bv x; n_k) \mid k \in m\}$, then $d(K) < n_m$.

	$\gets$: Since $K$ is bounded, we can find it a $n$-dimension cuboid~$I$, which we have proved to be compact (Lemma~\ref{lemma: n-dimensional cuboids are compact}). 
	The closed set~$K$ in the compact set~$I$ is compact (Theorem~\ref{theorem: closed subset of compact set}).

\end{proof}

\section{Connected Set}

\begin{definition}[Connected space]\label{definition: connected space}
	Topological space $(X, \mathscr T)$ is called \indexbf{connected}%
		\index{connected space}
	if there is no \indexbf{open-closed set} (i.e.\ both open and closed) besides $\varnothing$ and $X$ itself. 
\end{definition}

Notice that if $A \in 2^X$ is open-closed, its complement $X - A$ is also open-closed, which means a topological space is connected \emphbf{iff} it is not a union of its two open subsets. 

\begin{definition}[Connected set]\label{definition: connected set}
	Let $(X, \mathscr T)$ be a topological space. 
	Subset $C$ is said to be \indexbf{connected}%
		\index{connected set}
	if subspace $(C, \mathscr T_C)$ is connected. 
\end{definition}

\begin{theorem}\label{theorem: union of connected sets}
	Let $(X, \mathscr T)$ be a topological space, and $\{C_\alpha\}_{\alpha \in A}$ be connected subsets of $X$. 
	If $\bigcap_{ \alpha \in A} C_\alpha \neq \varnothing$, then $\bigcup\limits_{\alpha \in A} C_\alpha$ is also connected. 
\end{theorem}
\begin{proof}
	Assume that $C = \bigcup_{\alpha \in A} C_\alpha$ were not connected, $\exists E \in 2^C$ s.t.\ $E \neq \varnothing$, $E \neq C$ and $E, C - E \in \mathscr T_C$. 
	For $E$ is not empty there exists a $\beta \in A$ s.t.\ $E \cap C_\beta \neq \varnothing$. 
	
	Now we show that $C_\beta \subset  E$.
	Suppose that $C_\beta \nsubseteq  E$, which implies that $(C - E) \cap C_\beta \neq \varnothing$. 
	$E, C - E, C_\beta \in \mathscr T_C$, by the definition of the topology, 
	$E \cap C_\beta, (C - E) \cap C_\beta \in \mathscr T_C$. 
	This conflicts to the fact that $C_\beta$ is connected. 
	Therefore $C_\beta \subset  E$. 

	Hence, there exists a $B \subsetneqq A$, $\bigcup_{ \beta \in B} C_\beta = A$. 
	Since $C_\gamma$, $\gamma \in A - B$ would have a empty intersection with $E$, which contradicts $\bigcap_{ \alpha \in A} C_\alpha \neq \varnothing$.
\end{proof}

\begin{theorem}\label{theorem: closure of connected set}
	Connected sets have connected closure.
\end{theorem}
\begin{proof}

\end{proof}


\begin{theorem}\label{theorem: real connected sets}
	$C \subset \mathbb R$ is connected \emphbf{iff}  $\forall x, z \in C \forall y \in \mathbb R (x < y < z)$  $\to $ $y \in C$.
\end{theorem}
\begin{proof}
	$\to$:
	Assume that there were such $y \in \mathbb R$ that $\exists x, z \in C$, $x < y < z$ but $y \notin C$. 
	$\{x \in C \mid x < y\}$ and $\{x \in C \mid x > y\}$ are open in $C$ for they are intersection of open sets in $\mathbb R$ and $C$. 
	Since they're each other's complement, they are both open-closed, which conflicts to the definition of a connected set.
	
	$\gets$: 
	It can be proved that $(\inf C, \sup C) \subset C$. 
	Assume that there were an open-closed proper subset $E \neq \varnothing$ contained in $C$. 
	Find two points $x \in E$, $z \in C - E$. 
	Without loss of generality, let $x < z$. 
	Since $E$ and $C - E$ are closed, $c_1 = \inf \big( E \cap [a,b] \big) \in E$ while $c_2 = \inf \big((C - E) \cap [a, b]\big) \in C - E$. 
	However $E \cap (C - E) = \varnothing$, hence $c_1 < c_2$, which means $(c_1, c_2) \cap E = \varnothing$. 
	Here's the contradiction.
\end{proof}

\begin{definition}[Locally connected]\label{definition: locally connected}
	A topological space $(X, \mathscr T)$ is said to be \indexbf{locally connected} if $\forall x \in X$, $\exists U(x) $ s.t.\ $U(x)$ is connected.
\end{definition}

\section{Complete Metric Spaces}
We now take a closer look at one of the most important examples of metric spaces: complete spaces.

\begin{definition}[Cauchy sequence]\label{definition: Cauchy sequence}
	A sequence~$(x_n)_{n \in \mathbb N}$ of points in a metric space $(X, d)$ is called a \indexbf{fundamental sequence} or \indexbf{Cauchy sequence} if $\forall \varepsilon \in \mathbb R_+$, $\exists N \in \mathbb N$ s.t.\ as long as $m, n > N$, $d(x_n, x_m) < \varepsilon$.
\end{definition}

\begin{definition}[complete space]\label{definition: complete space}
	A metric space $(X, d)$ is \indexbf{complete} if any Cauchy sequence of its points is convergent.
\end{definition}

For example, a metric space~$C_\infty[a,b]$ is complete while $C_1[a,b]$ isn't. The proof see \cite[p.~22]{Zorich:2137923}.

\begin{theorem}[Closed subspace of a complete space is complete]
	\label{theorem: closed subspace of a complete space is complete}
	Let $(X, d)$ be a complete space, $A$ is a colsed set of $X$. 
	The subspace~$(A, d)$ is also complete.
\end{theorem}
\begin{proof}
	Let $\langle x_n \rangle_{n \in \mathbb N} \in A^\mathbb N$ be a Cauchy sequence in $A$.
	Since $X$ is complete, $\lim_{n \to \infty} x_n = x \in X$. 
	If $x \notin A$, then $\forall U \in \mathscr U(x)$, $\card(U \cap A) = \infty$ i.e.\ $x$ is a limit point of $A$. By Theorem~\ref{theorem: closed sets' closure (metric)}, $x \in A$.
\end{proof}

Let us consider an incomplete space~$\mathbb Q_1$, which is a subspace of the complete space $\mathbb R_1$. 
If $\mathbb R_1$ is the smallest complete space containing $\mathbb Q_1$, we can say that we have achieved a \emphbf{completion} of $\mathbb Q_1$. 
However, the term ``smallest'' hasn't been properly defined yet.

\begin{definition}[completion]\label{definition: completion}
	If a metric space $(X, d)$ is a subspace of a complete metric space $(Y, d)$ and everywhere dense in it, we call the latter one the \indexbf{completion} of $(X, d)$. 
\end{definition}

We need to confirm that such completion is the smallest and unique. So we introduce:

\begin{definition}[isometry]\label{definition: isometric}
	If there exists a \indexbf{isometry} $f \colon X_1 \to X_2$ when $(X_1, d_1)$ and $(X_2, d_2)$ are both metric space, i.e.\ 
		$f$ is a bijective and $\forall a, b \in X_1$, $d_2 \big(f(a), f(b)\big)=d_1 (a, b)$, then these two metric spaces are \indexbf{isometric}.
\end{definition}

This relation is reflexive ($\id_X$), symmetric ($f^{-1}$), and transitive ($f \circ g$), so it is a equivalence relation, denoted by $\sim$. 
We shall consider isometric spaces as identical, when only discussing within metric topological topics.

\begin{theorem}\label{theorem: completion is unique}
	If metirc spaces $(Y_1, d_1)$ and $(Y_2, d_2)$ are both completions of $(X, d)$, then they are isometric.
\end{theorem}
\begin{proof}
	Between two completions such isometry $f \colon Y_1 \to Y_2$ can be defined: if $x_1, x_2 \in X$, 
	\[
		d_2 \big(f(x_1), f(x_2) \big)
		= d \big(f(x_1), f(x_2) \big) 
		= d(x_1, x_2)
		= d_1 (x_1, x_2).
	\]

	For each $y_1 \in Y_1 - X_1$, a Cauchy sequence $(x_n)_{n \in \mathbb N}$ can be found in the nested sequence of balls centered in $y_1$. 
	It is obvious that $(x_n)_{n \in \mathbb N}$ is also fundamental in $Y_2$, limitting to $y_2\in Y_2$. 
	
	Differently selected sequences of points $(x'_n)_{n \in \mathbb N}$ won't limit to a different $y'_2$, namely $d(x_n, x'_n)$ shall converge to $0$, or the fact that the radii of balls converge to $0$ would be violated. 
	
	Let $f(y_1) = y_2$. 

	\begin{conditionlist}[label=\alph*)]
		\item
		For each $y_2 \in Y_2 - X$, there always exists a Cauchy sequence converging to it, which implies that $f$ is a surjection.
		\item
		On the other hand, we shall notice that $\forall y'_1, y''_1 \in Y_1 - X$,
		\[
			d_1(y'_1, y''_1)= \lim_{n \to \infty} d(x'_n, x''_n)=d_2(y'_2, y''_2)
		\]
		while $(x'_n)_{n \in \mathbb N}$ and $(x''_n)_{n \in \mathbb N}$ are both Cauchy sequence. 
		This equality proved that $f$ is a injection.
	\end{conditionlist}
\end{proof}

\begin{theorem}\label{theorem: completion exists}
	There always exists a completion for every metric space.
\end{theorem}
\begin{proof}
	Let $C_X := \{(x_n)_{n \in \mathbb N} \in X^\mathbb N \mid \forall \varepsilon \in \mathbb R_+,\, \exists N \in \mathbb N \text{ s.t. } \forall n, m \in \mathbb N (n > N \wedge m > N \to d_X(x_n, x_m) < \varepsilon)\}$, namely the collections of Cauchy sequences in $X$. 

	We say two Cauchy sequences $(x_n)_{n \in \mathbb N}$, $(x'_n)_{n \in \mathbb N}$ are equivalent (or, we shall say in a complete space, that they have a same limit) if $\lim_{n \to \infty} d(x_n, x'_n) = 0$. 

	It can be easily proved that such relation is a equivalence relation, and it divides $C_X$ into equivalence classes~$S$. 

	$\forall (x_n)_{n \in \mathbb N}, (x'_n)_{n \in \mathbb N} \in C_X$, $\forall \varepsilon \in \mathbb R_+$, $\exists N \in \mathbb N$ s.t.\ $\forall n, m \in \mathbb N$, as long as $n > N$ and $m > N$ (by Lemma~\ref{lemma: quadruple inequality}):
	\begin{equation*}
		|d_X(x_n, x'_n) - d_X(x_m, x'_m)| \leq  d_X(x_n, x_m) + d_X(x'_n, x'_m) 
			< 2 \varepsilon\,.
	\end{equation*}
	Hence, $(d(x_n, x'_n))_{n \in \mathbb N}$ is a Cauchy sequence in $\mathbb R_1$. Since $\mathbb R_1$ is a complete space, $\lim_{n \to \infty} d(x_n, x'_n)$ always exists. This fact allows us to introduce%
		\footnote{We implicitly use the (countable) axiom of choice: we must find a Cauchy sequence for each equivalence class. }%
	:
	\begin{equation*}
		d \colon S^2 \to \mathbb R; \;
			\big([(x_n)_{n \in \mathbb N}], [(x'_n)_{n \in \mathbb N}]\big)
				\mapsto \lim_{n \to \infty} d(x_n, x'_n) 
	\end{equation*}

	A metric space~$(S_X, d)$ isometric to any given metric space~$(X, d_X)$ can be constructed, where $S_X := \{[(x)_{n \in \mathbb N}] \mid x \in X\}$.

	Then we shall show that $S$ is the completion of $S_X$. 

	Let $\big([(x^i_n)_{n \in \mathbb N}]\big)_{i \in \mathbb N}$ be a Cauchy sequence in $S$. 
	By definition, for any $i \in \mathbb N_+$, there exists a $N$ that is large enough such that as long as $j> N$, $k > N$, $d_X(x^i_j, x^i_k) < 1/i$. 
	Choose $a^i := x^i_k$ for such $k > N$, so that $d \big([(a^i)_{n \in \mathbb N}], [(x^i_n)_{n \in \mathbb N}]\big) < 1/i$. 
	
	$\forall \varepsilon \in \mathbb R_+$, $\exists N \in \mathbb N$ 
		(e.g.\ we can choose $N = \lfloor 4/\varepsilon\rfloor$) 
	s.t.\ $\forall n, m \in \mathbb N$, $p > N \wedge q > N \;\to$
	\begin{equation*}
		d\big([(x^p_n)_{n \in \mathbb N}], [(x^q_n)_{n \in \mathbb N}]\big) < \frac \varepsilon 2
		\,\wedge\,
		d\big([(x^p_n)_{n \in \mathbb N}], [(a^p)_{n \in \mathbb N}]\big) < \frac 1 p
		\,\wedge\,
		d\big([(x^q_n)_{n \in \mathbb N}], [(a^q)_{n \in \mathbb N}]\big) < \frac 1 q
		\,,
	\end{equation*}
	therefore when $p, q$ are great enough, (by the triangle inequality)
	\begin{equation*}
		d\big([(a^p)_{n \in \mathbb N}], [(a^q)_{n \in \mathbb N}]\big) 
		\leq \frac \varepsilon 2 + \frac 1 p + \frac 1 q 
		< \varepsilon\,.
	\end{equation*}
	So, $[(a^n)_{n \in \mathbb N}]$ is a Cauchy sequence, therefore it is an element of $S$. 
	
	By $\lim_{i \to \infty} d\big([(x^i_n)_{n \in \mathbb N}], [(a^n)_{n \in \mathbb N}]\big) = 0$, we found a limit for the arbitary Cauchy sequence $\big([(x^i_n)_{n \in \mathbb N}]\big)_{i \in \mathbb N}$ in $S$.

	Finally, we have to check that $S_X$ is everywhere dense in $S$. For any aribitary $[(x_n)_{n \in \mathbb N}] \in S$, $\forall \varepsilon$, we can always choose a $N \in \mathbb N$ great enough so that $[(x_N)_{n \in \mathbb N}] \in S_X \cap B\big([(x_n)_{n \in \mathbb N}], \varepsilon\big)$. 
	Since every neighbourhood of $[(x_n)_{n \in \mathbb N}]$ contains a ball centred at it, we have proved that $\forall U \in \mathscr U([(x_n)_{n \in \mathbb N}]) \big( U \cap S_X \neq \varnothing \big)$.
\end{proof}

\textbf{Note}: We have already seem such technique when we construct the real numbers from the sequences of rational numbers.

\section{Continuous Mapping}
Let's recall the definition of the limitation.

\begin{definition}[Filter base]\label{definition: filter base}
	A set~$\mathscr{B} \subset 2^X$ is called a \textbf{(filter) base}\index{filter base}\index{base} in $X$ if the following conditions hold:
	\begin{conditionlist}[label=\alph*)]
		\item $\varnothing \notin \mathscr{B}$.
		\item $\forall B_1, B_2 \in \mathscr{B}$, $\exists B \in \mathscr{B}$ s.t.\ $B \subset B_1 \cap B_2 \subset B_2$. 
	\end{conditionlist}
\end{definition}

Here is a list of some importants filter bases:

\begin{enumerate}[label=(\arabic*)]
	\item $x \to a$, where $a \in X$, means $\mathring{\mathscr U}(a)$;
	\item $x \to \infty$, means $\{V \mid X - V \in \mathscr U(a) - \{X\}\}$;
	\item $E \ni x \to a$, means $\{\mathring U(a) \cap E \mid \mathring U(a) \in \mathring{\mathscr U}(a)\}$;
	\item $E \ni x \to \infty$, means $\{E \cap V \mid X - V \in \mathscr U(a) - \{X\}\}$.
\end{enumerate}

Introduction of the limits in a topological space is as follows.

\begin{definition}[Limit]\label{definition: limit}
	Let $a \in Y$ be the \indexbf{limit} over the base $\mathscr{B} \subset 2^{\mathscr{D}(f)}$ of a mapping $f \colon \mathscr{D}(f) \to Y$, in which $Y$ is epuiped with a topology $\mathscr T$. 
	\[
		\lim_\mathscr{B} f = a 
		\quad := \quad
		\forall U(a) \in \mathscr U(a)\;
		\exists B\in \mathscr B (f(B) \subset U(a)).
	\]
\end{definition}

Such definition is parallel to the definition we have introduced on the limits of real number, hence it basically holds the same propoties, except for:

\begin{theorem}[Uniqueness of limit in Hausdorff space]
	Let $Y$ be a Hausdorff space, $\mathscr B$ be a filter base in $X$, $f \in Y^X$. The limit of $f$ over $\mathscr B$ is unique.
\end{theorem}

\begin{definition}[Oscillation]
	Let $X$, $Y$ be two topological spaces, $f \in Y^X$, $E \in \mathscr P(X)$.
	\begin{equation*}
		\indexmath[omega f E]{\omega(f; E)} 
			:= \sup \{d_Y(f(x_1), f(x_2)) \mid x_1, x_2 \in E\}
	\end{equation*}
	is called the \indexbf{oscillation} of the function~$f$ in set~$E$.
	We can also define the \indexbf{oscillation} of $f$ at a point $x \in X$ as
	\begin{equation*}
		\indexmath[omega f x]{\omega(f; x)} 
			:= \inf \{\omega(f; B) \mid B \in \mathscr B\}\,,
	\end{equation*}
	where $\mathscr B$ is a filter base that $\cap \mathscr B = \{x\}$.
\end{definition}

\begin{theorem}[Cauchy criterion for existance of limit]
	\label{theorem: Cauchy criterion of existance of limit}
	Let $\mathscr B$ be a filter base in $X$, $(Y, d)$ be a complete metric space, and $f \in Y^X$.
	The mapping~$f$ has a limit over base $\mathscr B$ \emphbf{iff}
	$\forall \varepsilon \in \mathbb R_+$, $\exists B \in \mathscr B$ s.t.\ $\omega(f; B) < \varepsilon$.
\end{theorem}
\begin{proof}
	$\to$:
	Denote $a := \lim_{\mathscr B} f$.
	$\forall \varepsilon$, $\exists B \in \mathscr B$ s.t.\ $f(B) \subseteq B(a; \varepsilon/2)$
	\begin{equation*}
		\forall x, x' \in B,\quad
		d(f(x), f(x')) \leq d(f(x), a) + d(f(x'), a) < \varepsilon\,.
	\end{equation*}

	$\gets$:
	$\forall n \in \mathbb N_+$, $\exists B_n \in \mathscr B$ s.t.\ $\omega(f; B_n) < 1/n$. 
	Since $B_n \neq \varnothing$ (the definition of filter base), we can choose\footnote{I don't know any proof that can avoid using axiom of choices} $x_n \in B_n$ for any $n$, so that we get a sequence $\langle f(x_n) \rangle_{n \in \mathbb N} \in Y^\mathbb N$. Let $x \in B_n \cap B_m$ for any $m$, $n$ that $m > 1/\varepsilon$, $n > 1/ 2\varepsilon$ for any $\varepsilon$
	\begin{equation*}
		d(f(x_n), f(x_m)) \leq d(f(x_n), f(x)) + d(f(x_m), f(x)) < \varepsilon\,,
	\end{equation*}
	hence $\langle f(x_n) \rangle_{n \in \mathbb N}$ is a Cauchy sequence, by the completeness of $Y$ we can find a limit~$a$ for it.

	Let $m \to \infty$ we get $d(f(x_n), a) \leq \varepsilon$. This inequality holds for any $\varepsilon$ and $n$ great enough.
	$\forall x' \in B_n$,
	\begin{equation*}
		d(f(x'), a) \leq d(f(x'), f(x_n)) + d(f(x_n), a)
		< \frac 1 n + \varepsilon\,,
	\end{equation*}
	the right-hand side can be arbitary small, if $n$ is even greater.
\end{proof}

\begin{definition}[Continuity]
		\label{definition: continuous}
	A mapping $f \colon X \to Y$, where $X$, $Y$ is equiped with topology $\mathscr T_X$, $\mathscr T_Y$, respectively, is said to be \indexbf{continuous} at $x_0 \in X$ (let $y_0 = f( x_0 ) \in Y$), if $\forall U( y_0 )$, $\exists U( x_0 )$ s.t. $f( U(x_0) )\subset U( y_0 )$. 
	It is \indexbf{continuous} in $X$ if it is continuous at each point $x \in X$. 
\end{definition}

The set of continuous mappings from $X$ into $Y$ can be denoted by $C(X, Y)$ or $C(X)$ when $Y$ is clear. 

\begin{theorem}[\textbf{Criterion for continuity}]
	\index{criterion for continuity}\label{theorem: criterion of continuity}
	Let $(X, \mathscr T_X)$ and $(Y, \mathscr T_Y)$ be two topological spaces, $f \in Y^X$. 
	The function~$f$ is continuous \emphbf{iff} $\forall G_Y \in \mathscr T_Y$, $f^{-1} (G_Y) \in \mathscr T_X$.
\end{theorem}
\begin{proof}
	$\to$: 
	It is obvious if $f^{-1}(G_Y) = \varnothing$. 
	Hence we assume that $f^{-1}(G_Y) \neq \varnothing$. 
	Let $x_0 \in X$. 
	Since $f \in C(X, Y)$, for $G_Y$, $\exists U( x_0) $ s.t.\ $f\big(U(x_0) \big) \subset G_Y$. 
	Also notice that $f\big(U(x_0) \big) \subset G_Y \Rightarrow  U(x_0) \subset f^{-1}(G_Y)$, therefore $f^{-1}(G_Y)$ is open.

	$\gets$: 
	$\forall x_0 \in X$, let $y_0 = f(x_0)$, $f^{-1} (U( y_0)) \in \mathscr T_X$. 
	Notice that $x_0 \in f^{-1}(U( y_0))$, therefore $f \in C(X, Y) $.
\end{proof}

\begin{definition}[Homeomorphism]\label{definition: homeomorphism}
	Let $(X, \mathscr T_X)$ and $(Y, \mathscr T_Y)$ be two topological spaces. 
	A bijective mapping $f \colon X \to Y$ is a \indexbf{homeomorphism} if $f \in C(X, Y) \wedge f^{-1} \in C(Y, X)$. 
\end{definition}

\begin{definition}[Homeomorphic spaces]\label{definition: homeomorphic}
	Two topological spaces $(X,\mathscr T_X)$ and $(Y,\mathscr T_Y)$ are said to be \indexbf{homeomorphic} if there exists a homeomorphism $f \colon X \to Y$.
\end{definition}

Homeomorphic topological spaces are identical with respect to their topological propoties since the theorem~\ref{theorem: criterion of continuity} has shown that their open sets correspond to each other.

\begin{theorem}[Continuity of compositions of functions]
	Let $X$, $Y$, $Z$ be three topological spaces, $E \in \mathscr P(X)$. 
	$f \in C(E, Y)$, $g \in C(f(E), Z)$, then
	\begin{equation*}
		g \circ f \in C(E, Z) \,.
	\end{equation*}
\end{theorem}

\begin{theorem}[Continuous then locally bounded]
	Let $(X, \mathscr T)$ be a topological space and $(Y, d)$ be a metric space, $f \in Y^X$, $x \in X$. 
	If $f$ is continuous at $x$, then $\exists U(x) \in \mathscr U(x)$ s.t.\ $U(x)$ is bounded.
\end{theorem}

\begin{theorem}[Continuous iff oscillation is zero]
		\label{theorem: continuous iff oscillation is zero}
	Let $X$ be a topological space and $Y$ be a metric space, $f \in Y^X$, $x \in X$. 
	The function~$f$ is continuous at $x$ \emphbf{iff} $\omega(f; x) = 0$. 	
\end{theorem}

Then we shall introduce some global properties of continuous mappings.

\begin{theorem}[Conservation of compactness]
		\label{theorem: conservation of compactness}
	Let $(X, \mathscr T_X)$ and $(Y, \mathscr T_Y)$ be two topological spaces. 
	Let $K \subset X$ be a compact set. 
	If $f \colon X \to Y \in C(X, Y)$, then $f(K)$ is compact.
\end{theorem}
\begin{proof}
	For each open cover $\Omega_Y = \{ G_Y \in \mathscr T_Y\} \subset \mathscr T_Y$ over $f( K)$, $f^{-1} ( G_Y) \in \mathscr T_X$ (Therem~\ref{theorem: criterion of continuity}). $f( K) \subset \cup\,\Omega_Y \Rightarrow K \subset f^{-1} \left(  \cup\,\Omega_Y \right) = \cup\,\Omega_X $, where $\Omega_X = \{ f^{-1} ( G_Y) \mid G_Y \in \Omega_Y\} $ is an open cover over $K$. Since $K$ is compact,
	$\exists \Omega'_X \subset \Omega_X\left( 
	\lvert \Omega'_X \rvert \in \mathbb{N}_+ 
	\;\wedge\;K\subset \cup\,\Omega'_X
	\right)$, $f( K) \subset f ( \cup\,\Omega'_X) $. $f ( G'_X) \in \Omega_Y$, hence $\Omega'_Y = \{ f ( G'_X) \mid G'_X \in \Omega'_X\}$ is a finite subcover over $f( K)$.
\end{proof}


\begin{theorem}[Weierstrass maximum-value theorem]
	\label{theorem: Weierstrass maximum-value}
	Let $K$ be a compact topological space, and $f \in C (K, \mathbb R)$.
	$\exists x_m, x_M \in K$, s.t.\ $f(x_m) = m := \inf f(K)$, $f(x_M) = M := \sup f(K)$.
\end{theorem}
\begin{proof}
	By Theorem~\ref{theorem: conservation of compactness}, $f(K)$ is also compact, and therefore closed and bounded (Theorem~\ref{theorem: theorem: compact iff closed and bounded in Rn}). 
	If $M \notin f(K)$, then open covers $\{ B(M; (M-m)/n) - \tilde B(M; (M-m)/(n + 1)) \mid  n \in \mathbb N_+\} $ would not have a finite subcover, which is a contradiction to the compactness of $f(K)$.
\end{proof}

\begin{theorem}[Bijective from compact space to Hausdorff space is homeomorphism]
		\label{theorem: bijective from compact space to Hausdorff space is homeomorphism}
	Let $(K, \mathscr T_K)$ be a compact space and $(Y, \mathscr T_Y)$ be a Hausdorff space. 
	Let $f \in Y^K$ be a bijective.
	If $f \in C(K, Y)$, then $f$ is a homeomorphism.
\end{theorem}
\begin{proof}
	$\forall F = K - G$ s.t.\ $G \in \mathscr T_K$ is compact (Theorem~\ref{theorem: closed subset of compact set}). 
	Hence $f(F)$ is compact (Theorem~\ref{theorem: conservation of compactness}), then it is also closed
	(Theorem~\ref{theorem: compact sets are closed in Hausdorff space}). 
	This fact shows that $f^{-1}$ is continuous (Theorem~\ref{theorem: criterion of continuity}).
\end{proof}

\begin{definition}[Uniformly continuous]
	Let $(X, d_X)$, $(Y, d_Y)$ be metric spaces, $f \in Y^X$.
	If $\forall \varepsilon \in \mathbb R_+$, $\exists \delta \in \mathbb R$, $\forall x \in X$ s.t.\ $\forall E \in \mathscr P(X)$, 
	\begin{equation*}
		d_X E < \delta 
		\quad \to \quad
		\omega(f; E) < \varepsilon\,,
	\end{equation*}
	then $f$ is said to be a \indexbf{uniformly continuous} mapping.
\end{definition}

\begin{theorem}[Heine-Cantor theorem]
	\label{theorem: Heine-Cantor}
	Let $(K, d_K)$ be a compact metric space, and $(Y, d_Y)$ be a metric space.
	$\forall f \in C(K, Y)$, $f$ is uniformly continuous.
\end{theorem}
\begin{proof}
	$\forall \varepsilon \in \mathbb R_+$, we can find it a collections of open balls
	\begin{equation*}
		\varOmega = \big\{B(x; \delta(x)/2) \mid
			 x \in X,\, \omega\big(f; B(x; \delta(x))\big) < \varepsilon \big\}\,,
	\end{equation*}
	that covers the compact set~$K$, then there exists a finite subcover $\varOmega' = \big\{B(x_i; \delta(x_i)/2)\big\}_{i \in n}$. Let $\delta := \min \{\delta(x_i)\}_{i \in n}$.
	
	$\forall x', x'' \in K$, $\exists i \in n$, $x' \in B(x_i; \delta(x_i)/2)$, if $d(x', x'') < \delta$, 
	\begin{equation*}
		\delta(x'', x_i) \leq \delta(x', x'') + \delta(x', x'') < \delta + \delta(x_i) \leq \delta(x_i)\,,
	\end{equation*}
	therefore $x', x'' \in B(x_i; \delta(x_i))$, we have assume that $\omega(f; B(x_i; \delta(x_i)))$.
\end{proof}

\begin{theorem}[Cantor (generalised)]
	\label{theorem: generalised Cantor}
	Let $K$ be a compact set, $f \in \mathbb R^K$.
	If $\forall x \in K$, $\omega(f, x) \leq \omega_0$, then $\forall \varepsilon \in \mathbb R_+$, $\exists \delta \in \mathbb R_+$ s.t.\ $\forall \bv x \in K$, $\omega(f, B_K(\bv x; \delta)) < \omega_0 + \varepsilon$.
\end{theorem}
\begin{proof}
	We will get the proof if we repeat the prove of Theorem~\ref{theorem: Heine-Cantor}, only to replace $\varepsilon$ in the definition of $\varOmega$ by $\omega_0 + \varepsilon$.
\end{proof}

\begin{theorem}[Conservation of connectedness]\label{theorem: conservation of connectedness}
	Let $(X, \mathscr T_X)$ and $(Y, \mathscr T_Y)$ be two topological spaces, and $E \subset X$ be a connected set. 
	If $f \in C(X, Y)$, then $f(E)$ is also connected.
\end{theorem}
\begin{proof}
	Only to notice that the open-closed sets in $(f(E), \mathscr T_{ f(E)})$ have concurrently open-closed pre-images in $(E, \mathscr T_E)$.
\end{proof}

\begin{theorem}[Intermediate-value theorem]
	\label{theorem: intermediate-value}
	Let $(X, \mathscr T)$ be a connected topological space, and $f \in C(X, \mathbb R)$, $f(a) = A$, $f(b) = B$, $A < B$.
	$\forall C \in [A, B]$, $\exists c \in X$, $f(c) = C$.
\end{theorem}
\begin{proof}
	by Theorem~\ref{theorem: conservation of connectedness}, $f(X)$ must be a connected set. Hence by Theorem~\ref{theorem: real connected sets}, we know that $\forall C \in [A, B]$, $C \in f(X)$.
\end{proof}

\section{Contraction}

\begin{definition}[Fixed point]\label{definition: fixed point}
	A point $a\in X$ is a \indexbf{fixed point} of a mapping $f \colon X \to X$ if $f( a) = a$.
\end{definition}

\begin{definition}[Contraction]\label{definition: contraction}
	Let~$(X, d)$ be a metric space. 
	A mapping~$f \colon X \to X$ is called a \indexbf{contraction} if~$\exists q \in (0, 1) \subset \mathbb R$ s.t. $\forall x_1,x_2 \in X$, 
	\begin{equation}\label{equation: contraction inequality}
		d(f(x_1), f (x_2)) \leq q d(x_1, x_2).
	\end{equation}
\end{definition}

\begin{lemma}\label{lemma: contraction is continuous}
	A contraction $f \colon X \to X$ is always continuous.
\end{lemma}
\begin{proof}
	$\forall x \in X$, $\forall \varepsilon \in \mathbb R_+ $, $\exists \delta < \varepsilon / q$, according to inequality~\ref{equation: contraction inequality}:
	\[
	f\big( B(x; \delta ) \big) 
	\subset 
	B\big( f(x); \varepsilon \big).
	\]
\end{proof}

\begin{theorem}[\textbf{Picard-Banach fixed-point principle} or \textbf{contraction mapping principle}]
		\label{theorem: Picard-Banach}%
		\index{Picard-Banach fixed-point principle}\index{contraction mapping principle}%
	Let $(X, d)$ be a complete metric space. 
	Each contraction $f \colon X \to X$ has a unique fixed point $a$. 
	Also, $\forall \{x_n\} \subset X$ s.t.\ 
	$\forall n \in \mathbb{N} \big(f (x_n) = x_{n+1} \big)$ then $\lim_{n\to \infty} x_n = a$, and
	\begin{equation}\label{equation: fixed-point principle}
		d(x_n, a) \leq \frac{q^n}{1 - q} d(x_1, x_0).
\end{equation}
\end{theorem}
\begin{proof}
	By the inequality~\ref{equation: contraction inequality}:
	\[
		d(x_{n+1}, x_n) \leq q d(x_n, x_{n-1})
		\leq \cdots 
		\leq q^n d(x_1, x_0)
	\]

	Therefore, $\forall n, k \in \mathbb{N}$, 
	\begin{equation}\label{equation: contraction Cauchy sequence}
		d(x_{n+k}, x_n) \leq 
			\sum^{k-1}_{i=0} d(x_{n+i+1}, x_{n+i}) \leq
			\sum^{k-1}_{i=0} q^{n+i} d(x_1, x_0) \leq
			\frac{q^n}{1 - q} d(x_1, x_0) \,,
	\end{equation}
	which implies that $\langle x_n \rangle_{n \in \mathbb N}$ is a Cauchy sequence in a complete space $(X, d)$, hence it converges to a point $a \in X$.

	To proof that $a$ is a fixed point of $f$, since $f$ is continuous (Lemma~\ref{lemma: contraction is continuous}), just notice that 
	\[
		a = \lim_{n \to \infty} f(x_n) 
			= f(\lim_{n\to \infty} x_n) = f(x_n).
	\]

	If there were another fixed point~$a' \in X$ of $f$, then:
	\[
		0 \leq d(a, a')  = d(f(a), f(a')) \leq q d(a, a')
	\]
	which can't be true unless $a = a'$. 

	By passing to the limit as $k \to \infty$ in the inequality~\ref{equation: contraction Cauchy sequence}, we have the inequality~\ref{equation: fixed-point principle}.
\end{proof}

If the factor $q$ is not limited within $1$, we obtain:
\begin{definition}[Lipschitz continuity]
	Let $(X, d_X)$, $(Y, d_Y)$ be two metric spaces, $f \in Y^X$. If $\exists M \in \mathbb R_+$ s.t.\ $\forall x_1, x_2 \in X$, 
	\begin{equation}\label{equation: Lipschitz condition}
		d_Y(f(x_1), f(x_2)) \leq M d_X(x_1, x_2)\,,
	\end{equation}
	then $f$ is said to be \indexbf{Lipschitz continuous}. 
	Inequality~\ref{equation: Lipschitz condition} is called the \indexbf{Libschitz condition}.
\end{definition}

It is almost obvious that a Lipschitz continuous mapping is continuous.

\chapter{Normed Linear Space and Differential Calculus}
\section{Normed Linear Space}

\begin{definition}[Norm]
	Let $V$ be a linear space over $\mathbb R$ or $\mathbb{C}$. 
	A function $\|\;\| \colon X \to \mathbb R$ assigning to each vector $\bv{x}\in X$ a real number $\|\bv x\|$ is called a \indexbf{norm} in the linear space $X$ if:
	\begin{conditionlist}[label=\alph*)]
		\item 
		$\|\bv x\| = 0 \IFF \bv x = \boldsymbol{0}$ (nondegeneracy);
		\item
		$\|\lambda \bv x\| = |\lambda| \|\bv x\|$ (homogeneity);
		\item
		$\|\bv x_1 + \bv x_2\| \leq \|\bv x_1\| + \|\bv x_2\|$ (the triangle inequality).
	\end{conditionlist}	

	A linear space with a norm defined on it is said to be \indexbf{normed}.
\end{definition}

Over every normed space a distance can be defined as:
\begin{equation}\label{equation: distance of normed space}
	d(\bv x_1, \bv x_2) = \|\bv x_1 - \bv x_2\|
\end{equation} 

\begin{definition}[Banach space]
	Let $V$ be a normed space.
	If $(V, d)$ is a complete space, where the distance~$d$ is defined as Eq.~\eqref{equation: distance of normed space}, then we call $V$ a \indexbf{complete normed space} or \indexbf{Banach space}. 
\end{definition}

\begin{definition}[Hermitian form]
	A linear space~$X$ on the complex field~$\mathbb C$ is said to be given a \indexbf{Hermitian space} if there is a mapping~$\indexmath[langle rangle]{\langle, \rangle} \colon X^2 \to \mathbb C$ defined, s.t.\ $\forall \bv x_1, \bv x_2, \bv x_3 \in X$, $\forall \lambda \in \mathbb C$.
	\begin{conditionlist}[label=\alph*)]
		\item $\langle \bv x_1, \bv x_2 \rangle = \overline{\langle \bv x_2, \bv x_1 \rangle}$;
		\item $\langle \lambda \bv x_1, \bv x_2\rangle = \lambda \langle \bv x_1, \bv x_2 \rangle$;
		\item $\langle \bv x_1 + \bv x_2, \bv x_3\rangle = \langle \bv x_1, \bv x_3 \rangle + \langle \bv x_2, \bv x_3 \rangle$.
	\end{conditionlist}
\end{definition}

A Hermitian form is said to be \emphbf{positive semi-definite}, if $\forall \bv x \in X$, $\langle \bv x, \bv x \rangle \geq 0$\footnote{%
	$\langle \bv x, \bv x\rangle = \overline{\langle \bv x, \bv x\rangle}$, hence $\langle \bv x, \bv x\rangle \in \mathbb R$.%
}.
A Hermitian form is said to be \emphbf{degenerate}, if $\exists \bv x \in X - \{\bv 0\}$ s.t.\ $\langle \bv x, \bv x \rangle = 0$. 
A Hermitian form that is not degenerate is said to be \emphbf{non-degenerate}.

\begin{definition}[Inner product]
	A non-degenerate positive semi-definite Hermitian form%
		\footnote{Equivalently, a positive definite Hermitian form.}%
	is said to be an \indexbf{inner product}. 
	A space equiped with an inner product is said to be a \indexbf{inner product space}.
\end{definition}

\begin{theorem}[Cauchy-Bunyakovskii's inequality]\label{theorem: Cauchy-Bunyakovskii}%
	\index{Cauchy-Bunyakovskii's inequality}%
	A linear space~$X$ on the complex field~$\mathbb C$ is equiped with an inner product $\langle , \rangle$. $\forall \bv x, \bv y \in X$, 
	\begin{equation}
		|\langle \bv x, \bv y \rangle|^2 
			\leq \langle \bv x, \bv x \rangle \langle \bv y, \bv y \rangle\,.
	\end{equation}
\end{theorem}
\begin{proof}
	The theorem is trivial as $\bv y = \bv 0$. Let us assume that $\bv y \neq \bv 0$, therefore $\langle \bv y, \bv y\rangle > 0$.

	$\forall \lambda \in \mathbb C$, 
	\begin{equation*}
		0 \leq \langle \bv x + \lambda \bv y, \bv x + \lambda \bv y \rangle
			= \langle \bv x, \bv x \rangle + \lambda \overline{\langle \bv x, \bv y \rangle} + \overline \lambda \langle \bv x, \bv y \rangle + |\lambda|^2\langle \bv y, \bv y \rangle 
	\end{equation*}

	Let $\lambda = - \langle \bv x, \bv y \rangle / \langle \bv y, \bv y\rangle$, we have:
	\begin{equation*}
		0 \leq \langle \bv x, \bv x \rangle 
			- \frac{ |\langle \bv x, \bv y \rangle|^2}{\langle \bv y, \bv y \rangle}
			\,. 
	\end{equation*}
\end{proof}

By the theorem~\ref{theorem: Cauchy-Bunyakovskii} we can claim that a linear space on complex number with an inner product $\langle, \rangle$ induces a norm
\begin{equation}
	\|\bv x\| := \sqrt{\langle \bv x, \bv x \rangle}\,,
\end{equation} 
and a metric
\begin{equation}
	d(\bv x, \bv y) = \|\bv x - \bv y\|\,.
\end{equation}

\begin{theorem}[Continuity of norm]
	\label{theorem: continuity of norm}
	Let $X$ be a normed space with a norm $\|*\|$.
	The mapping $\|*\| \in \mathbb R^X$ is continuous in $X$. 
\end{theorem}
\begin{proof}
	$\forall \bv x \in X$, $\forall \varepsilon \in \mathbb R_+$, if $\|\Delta \bv x\| < \varepsilon$, then
	\begin{equation*}
		\|\bv x + \Delta \bv x\| \leq \| \bv x\| + \|\Delta \bv x\| 
			< \|\bv x\| + \varepsilon \,.
	\end{equation*}
\end{proof}

\begin{definition}[Hilbert space]
	If a linear space is equiped with an inner poduct, and together with its induced metric constructs a complete metric space, we call it a \indexbf{Hilbert space}. If the induced metric space is not complete, we shall call it a \indexbf{pre-Hilbert space}.
\end{definition}

\section{Linear Operators}

\begin{definition}[Norm]
	Let $\mathscr A$ be a $n$-multilinear operator space over normed space $(\bv X_i)_{i \in n}$ to a normed space $Y$ i.e.\ $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$. 
	We define the norm $\indexmath[vert vert]{ \Vert \mathscr A \Vert }$ as:
	\begin{equation}\label{equation: norm of operator}
		\|\mathscr A\| := \sup 
		\left\{
			\frac{\|\mathscr A(\bv x_i)_{i \in n}\|_Y}
				{\prod_{i \in n} \|\bv x_i\|_{X_i}}
		\middle|
			\forall i \in n,\;\bv x_i \in X_i - \{\bv 0\}
		\right\}\,,
	\end{equation}
	where the subscripts denote which spaces the norms are defined in.
\end{definition}

The following theorem gives an equivalent definition:

\begin{theorem}
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$.
	\begin{equation}
		\|\mathscr A\| = 
		\{ 
			\|\mathscr A(\bv e_i)_{i \in n}\|_Y
		\mid
			\forall i \in n,\; \bv e_i \in X_i \wedge \|\bv e_i\|_{X_i} = 1
		\} \,.
	\end{equation}
\end{theorem}

\begin{theorem}
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$, and let $\|\mathscr A\| < \infty$.
	\begin{equation}
		\|\mathscr A(\bv x_i)_{i \in n}\|_Y 
			\leq \|\mathscr A\| \prod_{i \in n} \|\bv x_i\|_{X_i}\,.
	\end{equation}
\end{theorem}

\begin{definition}[Bounded linear operators]
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$. 
	If $\|\mathscr A\| < \infty$, then $\mathscr A$ is said to be \indexbf{bounded}.
\end{definition}

\begin{theorem}[Continuous at zero iff bounded]\label{theorem: continuous at zero iff bounded}
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$.
	Denote $\prod_{i \in n} X_i$ by $X$.
	The operator~$\mathscr A$ is continuous at $\bv 0 \in X$\footnote{Be reminiscent of the Defintion~\ref{definition: direct product}} \emphbf{iff} it is bounded.
\end{theorem}
\begin{proof}
	First assume that $\mathscr A$ is bounded. 

	When $\|\mathscr A\| = 0$ it is trivial. 
	Hence we assume that $\|\mathscr A\| > 0$.
	
	$\forall \varepsilon \in \mathbb R_+$, if $\Delta \bv x := (\Delta \bv x_i)_{i \in n} \in X$ meets the condition that $\forall i \in n$, $\|\Delta \bv x_i\|_{X_i} < \sqrt[n]{\varepsilon / \|\mathscr A\|}$ then
	\begin{align*}
		d_Y(&\mathscr A(\bv 0 + \Delta \bv x), \mathscr A(\bv 0))
		= d_Y(\mathscr A(\Delta \bv x), \bv 0)
		= \|\mathscr A(\Delta \bv x)\|_Y
		\\
		&\leq \|\mathscr A\| \prod_{i \in n} \|\Delta \bv x_i\|_{X_i}
		< \varepsilon \,.
	\end{align*}

	Then we assume that $\mathscr A$ is continuous at $\bv 0$.

	Set any positive $\varepsilon \in \mathbb R_+$, $\exists \delta \in \mathbb R_+$, when $\forall i \in n$, $\bv x_i \in X_i - \{\bv 0\}$ and $\|\bv x_i\|_{X_i} \leq \delta$, $\|\mathscr A(\bv x)\| \leq \varepsilon$. 

	Since every unit vector $\bv e_i$ can be written as $\delta \bv e_i / \delta$, where $\delta \bv e_i \in X_i - \{\bv 0\}$ and $\|\delta \bv e_i\|_{X_i} = \delta$, then
	\begin{equation*}
		\|\mathscr A(\bv e_i)_{i \in n}\|_Y 
		= \frac 1 {\delta^n} \|\mathscr A(\delta e_i)_{i \in n}\|_Y
		\leq \frac \varepsilon {\delta^n}\,,
	\end{equation*}
	which implies that the operator~$\mathscr A$ is bounded.
\end{proof}

\begin{theorem}[Continuous at zero then at everywhere]\label{theorem: Continuous at zero then at everywhere}
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$.
	Denote $\prod_{i \in n} X_i$ by $X$.
	If the operator is continuous at $\bv 0 \in X$, then it is continuous in $X$.
\end{theorem}
\begin{proof}
	By theorem~\ref{theorem: continuous at zero iff bounded}, we have learned that an operator continuous at $\bv 0$ is bounded.

	$\forall \bv x, \Delta \bv x \in X$, 
	\begin{align*}
		d_Y(&\mathscr A(\bv x + \Delta \bv x), \mathscr A(\bv x))
		= \|\mathscr A(\bv x + \Delta \bv x) - \mathscr A(\bv x)\|_Y 
		\\
		&= \Big\|\mathscr A(\Delta \bv x_0, \bv x_1, \cdots, \bv x_{n-1})
			+ \mathscr A(\bv x_1, \Delta \bv x_1, \cdots, \bv x_{n-1})
			+ \cdots
			+ \mathscr A(\bv x_0, \bv x_1, \cdots, \Delta \bv x_{n-1}) 
		\\&\qquad
			+ \mathscr A(\Delta \bv x_0, \Delta \bv x_1, \cdots, \bv x_{n-1})
			+ \cdots 
			+ \mathscr A(\bv x_0, \cdots, \Delta \bv x_{n-2}, \Delta \bv x_{n-1})
			+ \cdots 
			+ \mathscr A(\Delta \bv x)
		\Big\|_Y
		\\
		&\leq
			\|\mathscr A(\Delta \bv x_0, \bv x_1, \cdots, \bv x_{n-1})\|_Y
			+ \cdots
			+ \|\mathscr A(\bv x_0, \bv x_1, \cdots, \Delta \bv x_{n-1})\|_Y
		\\&\qquad
			+ \cdots 
			+ \|\mathscr A(\Delta \bv x)\|_Y
		\\
		&\leq
			\|\mathscr A\|  \sum_{S \in \mathscr P(n) - \{\varnothing\}} 
			\prod_{i \in n - S}\|\bv x_i\|_{X_i}
			\prod_{j \in S} \|\Delta\bv x_j\|_{X_j}\,.
	\end{align*}

	By setting $\max\{\|x_i\|_{X_i} \mid i \in n\} < \varepsilon \max \Big\{ \sqrt[n]{\prod_{i \in n - S}\|\bv x_i\|_{X_i}} \mid S \in \mathscr P(n) - \{\varnothing\} \Big\} / (2^n - 1)\|\mathscr A\|$ we have $d_Y(\mathscr A(\bv x + \Delta \bv x), \mathscr A(\bv x)) < \varepsilon$ for any $\varepsilon \in \mathbb R_+$.
\end{proof}

Theorem~\ref{theorem: continuous at zero iff bounded} and Theorem~\ref{theorem: Continuous at zero then at everywhere} show the equivalence for linear operators of being bounded and being continuous.
We shall denote the space of all the bounded $n$-multilinear operators from $X_0$, $\cdots$, $X_{n-1}$ to $Y$ by $\indexmath[B Xi Y]{\mathcal B(X_0, \cdots, X_{n-1}; Y)}$. 

\begin{corollary}[Linear operators from finite dimensional space are continuous]
	\label{corollary: linear operators from finite dimensional space are continuous}
	If $\forall i \in n$, $\dim X_i < \infty$, then
	\begin{equation*}
		\mathcal L(X_0, \cdots, X_{n-1}; Y) = \mathcal B(X_0, \cdots, X_{n-1}; Y)
		\,.
	\end{equation*}
\end{corollary}

\begin{corollary}[Continuous at a point then at everywhere]\label{theorem: Continuous at a point then at everywhere}
	Let $\mathscr A \in \mathcal L(X_0, X_1, \cdots, X_{n - 1}; Y)$.
	Denote $\prod_{i \in n} X_i$ by $X$, and Let $\bv x = (\bv x_i)_{i \in n} \in X$.
	If the operator is continuous at $\bv x$, then it is continuous in $X$.
\end{corollary}
\begin{proof}

\end{proof}

\begin{definition}[Isomorphism]
	Two normed space are \indexbf{isomorphic} if their exists an \indexbf{isomorphism} $f$ between them, s.t.\ $f$ is a isomorphsm between two linear space, and $f$ and $f^-1$ are continuous.
\end{definition}

\begin{theorem}
	If two normed spaces have the same finite dimension, they are isomorphic.
\end{theorem}

\begin{theorem}[Space of bounded linear operators is normed linear space]\label{theorem: space of bounded linear operators is normed linear space}
	$\mathcal B(X_0, \cdots, X_{n-1}; Y)$ is a normed linear space, the norm is defined as in Eq.~\eqref{equation: norm of operator}.
\end{theorem}

\begin{theorem}[Norm of operator composition]
	\label{theorem: norm of operator composition}
	Let $X, Y, Z$ be three normed spaces, and $\mathscr A \in \mathcal B(X; Y)$, $\mathscr B \in \mathcal B(Y; Z)$.
	\begin{equation*}
		\|\mathscr B \mathscr A\| \leq \|\mathscr B\| \|\mathscr A\|\,.
		\footnote{By convention, we denote $\mathscr B \circ \mathscr A$ by $\mathscr B \mathscr A$, and $(\mathscr B \mathscr A)(\bv x)$ by $\mathscr B \mathscr A \bv x$ (since the compositions of the operator is associative).}
	\end{equation*}
\end{theorem}
\begin{proof}
	\begin{align*}
		\|\mathscr B \mathscr A\| 
		&= \sup\big\{ \|\mathscr B \mathscr A\bv x\|_Z / \|\bv x\|_X \mid \bv x \in X - \{\bv 0\}\big\} \\
		&\leq \|\mathscr B\| \sup\big\{ \|\mathscr A\bv x\|_Y / \|\bv x\|_X \mid \bv x \in X - \{\bv 0\}\big\}
		= \|\mathscr B\| \|\mathscr A\|\,.
	\end{align*}
\end{proof}

\begin{theorem}[completeness]
	\label{theorem: Y is complete so is the space of linear operators onto it}
	If $Y$ is a Banach space, so is $\mathcal B(X_0, \cdots, X_{n-1}; Y)$.
\end{theorem}
\begin{proof}
	Let $(\mathscr A_i)_{i \in \mathbb N} \in \mathcal B(X_0, \cdots, X_{n-1}; Y)^{\mathbb N}$ be a Cauchy sequence. 
	$\forall \bv x := (\bv x_i)_{i \in n} \in X := \prod_{i \in n} X_i$, 
	\begin{equation*}
		\|\mathscr A_\ell \bv x - \mathscr A_m \bv x\|_Y
		= \|(\mathscr A_\ell - \mathscr A_m) \bv x\|_Y
		\leq \|\mathscr A_\ell - \mathscr A_m\| \prod_{i \in n} \|\bv x_i\|_{X_i}
		\,,
	\end{equation*}
	therefore $(\mathscr A_i \bv x)_{i \in \mathbb N} \in Y^\mathbb N$ is also a Cauchy sequence.

	Since $Y$ is a Banach space, we denote the limit of the Cauchy sequence $(\mathscr A_i \bv x)_{i \in n}$ by $\mathscr A \bv x$. 
	We need to prove that $\mathscr A \in \mathcal B(X_0, \cdots, X_{n-1}; Y)$.

	It is obvious that $\mathscr A \in \mathcal L(X_0, \cdots, X_{n-1}; Y)$, therefore we only need to show that $\|\mathscr A\| < \infty$.

	Let $\bv e := (\bv e_i)_{i \in n} \in X$, where $\forall i \in n$, $\|\bv e_i\|_{X_i} = 1$. 
	$\forall \varepsilon \in \mathbb R_+$, $\exists N \in \mathbb N$, if $\ell > N$, then
	\begin{equation*}
		0 \leq \|\mathscr A \bv e\|_Y
			\leq \|\mathscr A_\ell \bv e\|_Y + \varepsilon
			\leq \|\mathscr A_\ell\| + \varepsilon\,, 
	\end{equation*} 

	Since $\{\|\mathscr A_i\| \mid i \in \mathbb N\}$ is bounded, we claim that $\big\{\|\mathscr A \bv e\| \mid \bv e = (\bv e_i)_{i \in n} \in X \wedge \forall i \in n \big( \|\bv e_i\|_{X_i} = 1\big)\big\}$ is also bounded.
\end{proof}

\begin{theorem}
	$\forall m \in n$, 
	\begin{equation*}
		\exists f \in \mathcal B(X_0, \cdots, X_{n-1}; Y)^{\mathcal B (X_0, \cdots, X_{m-1}; B(X_m, \cdots, X_{n-1}; Y))}
	\end{equation*}
	s.t.\ $f$ is a isomorphism between two linear spaces and it conserves the norm structure i.e.\ 
	\begin{equation*}
		\|f(\mathscr B)\| = \|\mathscr B\|\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	$\forall \mathscr B \in \mathcal B \big(X_0, \cdots, X_{m-1}; B(X_m, \cdots, X_{n-1}; Y)\big)$, $\forall \bv x := (\bv x_i)_{i \in n} \in X := \prod_{i \in n} X_i$, $f(\mathscr B) \bv x := \mathscr B(\bv x_i)_{i \in n} (\bv x_j)_{j \in n \backslash m}$.

	Obviously $f \in \mathcal L\big(\mathcal B (X_0, \cdots, X_{m-1}; B(X_m, \cdots, X_{n-1}; Y)); \mathcal B(X_0, \cdots, X_{n-1}; Y)\big)$. 
	If $f(\mathscr B) = \mathscr O_X$, $\mathscr B = \mathscr O_{\prod_{i \in m} X_m}$, therefore $\ker f = \{\mathscr O_{\prod_{i \in m} X_m}\}$, which implies that $f$ is a isomorphism between two linear spaces.

	\begin{align*}
		\|\mathscr B\| &= \sup 
		\left\{ 
			\frac{\|\mathscr B(\bv x_i)_{i \in m}\|}{\prod_{i \in m} \|\bv x_i\|_{X_i}}
		\middle|
			\forall i \in m,\; \bv x_i \in X_i \wedge \bv x_i \neq \bv 0
		\right\}
		\\
		&= \sup 
		\left\{ 
			\frac{\sup \left\{ 
				\frac{\|f(\mathscr B)(\bv x)\|_Y}{\prod_{i \in n \backslash m} \|\bv x_i\|_{X_i}}
			\middle|
				\forall i \in n \backslash m,\; \bv x_i \in X_i \wedge \bv x_i \neq \bv 0
			\right\}}{\prod_{i \in m} \|\bv x_i\|_{X_i}}
		\middle|
			\forall i \in m,\; \bv x_i \in X_i \wedge \bv x_i \neq \bv 0
		\right\}
		\\
		&=
		\sup \left\{ 
				\frac{\|f(\mathscr B)(\bv x)\|_Y}{\prod_{i \in n} \|\bv x_i\|_{X_i}}
				\middle|
				\forall i \in n,\; \bv x_i \in X_i \wedge \bv x_i \neq \bv 0
			\right\}
		= \|f(\mathscr B)\|
	\end{align*}
\end{proof}

\begin{corollary}\label{corollary: important isomorphism}
	$\mathcal B(X_0; \mathcal B(X_1; \cdots; \mathcal B(X_{n-1}; Y) \cdots ))$  and $\mathcal B(X_0, \cdots, X_{n-1}; Y)$ are isomorphic.
\end{corollary}

\section{Differentiation}

\begin{definition}[Differentiation]
	Let $X$, $Y$ be two normed spaces. A mapping~$f$ from $D \in \mathscr P(X)$ to $Y$ is said to be \indexbf{differentiable} at an interior point $\bv x \in D$ if $\exists \mathscr L(\bv x) \in \mathcal B(X; Y)$\footnote{$\bv x$ here is an argument.} s.t.\ $\forall \Delta \bv x \in X\, \big(\bv x + \Delta \bv x \in D\big)$,
	\begin{equation}\label{equation: differential}
		f(\bv x + \Delta \bv x) - f(\bv x) 
			= \mathscr L(\bv x) \Delta \bv x + \alpha(\bv x; \Delta \bv x)\,,
	\end{equation}
	where $\alpha(\bv x; \Delta \bv x) = o(\Delta \bv x)$ as $\Delta \bv x \to 0$, i.e.\ $\lim_{\Delta \bv x \to \bv 0} \|\alpha(\bv x; \Delta \bv x)\|_Y / \|\Delta \bv x\|_X = 0$.

	Such $\left.\mathscr L\right\vert_{\bv x}$ is called the \indexbf{differential} of $f$ at $\bv x$\footnote{Alternatively, \indexbf{tangent mapping} or \indexbf{derivative}.}, denoted by $\indexmath[df x]{\dif f(\bv x)}$ or $\indexmath[f prime x]{f'(\bv x)}$. 
\end{definition}


\begin{theorem}[Uniqueness]
	\label{theorem: uniqueness (differential)}
	Let $X$ and $Y$ be two normed spaces. 
	If a mapping~$f \in Y^D$ where $D \in \mathscr P(X)$ is differentiable at $\bv x$ which is an interior point of $D$, then the differential of $f$ at $\bv x$ is unique.
\end{theorem}
\begin{proof}
	Let their be two differentials $\mathscr L_1(\bv x)$, $\mathscr L_2(\bv x)$, by the definition~\eqref{equation: differential}, we have:
	\begin{equation*}
		\big(\mathscr L_1(\bv x) - \mathscr L_2(\bv x)\big) \Delta \bv x= o(\Delta \bv x)\,,
	\end{equation*}
	hence $\|(\mathscr L_1(\bv x) - \mathscr L_2(\bv x)) \Delta \bv x\|_Y = o(\|\Delta \bv x\|_X)$, therefore
	\begin{equation*}
		\lim_{\|\Delta \bv x\|_X \to 0} 
		\left\|
			(\mathscr L_1(\bv x) - \mathscr L_2(\bv x))	
				\frac{\Delta \bv x}{\|\Delta \bv x\|_X}	
		\right\|_Y = 0\,,
	\end{equation*}

	This means that whatever the direction of unit vector $\Delta \bv x / \|\Delta \bv x\|_X$ is, the norm of $\big\|(\mathscr L_1(\bv x) - \mathscr L_2(\bv x)) \Delta \bv x / \|\Delta \bv x\|_X \big\|_Y$ is always zero, therefore $\|\mathscr L_1(\bv x) - \mathscr L_2(\bv x)\|$. By the definition of norms, this means that $\mathscr L_1(\bv x) - \mathscr L_2(\bv x) = \mathscr O$, or $\mathscr L_1(\bv x) = \mathscr L_2(\bv x)$.
\end{proof}

Theorem~\ref{theorem: uniqueness (differential)} gives us the right to define:

\begin{definition}[Derivative mapping]
	Let $X$, $Y$ be two normed spaces, $D \in \mathscr P(X)$, $f \in Y^D$, $\indexmath[Delta f]{\Delta(f)} := \{\bv x \in X \mid \text{$f$ is differentiable at $\bv x$}\}$.
	\begin{equation*}
		f' \colon \Delta(f) \to \mathscr B(X, Y);\;
			\bv x \mapsto \dif f(\bv x)
	\end{equation*}
	is called the \indexbf{derivative mapping} of $f$.
\end{definition}

\emphbf{Warning}: We use $f'(\bv x)$ to denote the linear operator on $X$ instead of a point in $Y$ (when $X = Y = \mathbb R$, they are the isomorphic). It is obvious that $\forall \mathscr A \in \mathcal B(X; Y)$, $\forall \bv x \in X$, $\dif \mathscr A(\bv x) = \mathscr A$, which is different from the usual notations that writes $f(x) = \me^x \to f'(x) = \me^x = f(x)$ and $f(x) = ax \to f'(x) = a$.

To make it clear, we must remember: $f \in Y^X$, $f' \in \mathscr B(X; Y)^X$, $f'(\bv x) \in \mathscr B(X; Y)$, $f'(\bv x) \Delta \bv x \in Y$.

It is always convenient to define such notation:
\begin{definition}
	Let $X_i$, $i \in n$ be normed spaces, and $X := \prod_{i \in n} X_i$. 
	We define $\indexmath[d x]{\dif \bv x}_i$ as:
	\begin{equation*}
		\dif \bv x_i \Delta \bv x = \Delta \bv x_i\,,
	\end{equation*}
	for any $\Delta \bv x := (\Delta \bv x_i)_{i \in n} \in X$.
\end{definition}

Actually, $\dif \bv x_i$ can be conceive as the differential of the projective operator $X \to X_i$. If $n = 1$, $\dif \bv x = \id_X$, therefore we can write:
\begin{equation*}
	\dif f(\bv x)= f'(\bv x) \dif \bv x\,,
\end{equation*}
which is the notation we have been very familiar with.

\begin{theorem}[Differentiable then continuous]
	\label{theorem: differentiable then continuous}
	Let $X$ and $Y$ be two normed spaces. 
	If a mapping~$f \in Y^D$ where $D \in \mathscr P(X)$ is differentiable at $\bv x$ which is an interior point of $D$, then $f$ is continuous at $\bv x$.
\end{theorem}
\begin{proof}
	as $\|\Delta \bv x\| \to 0$
	\begin{equation*}
		\|f(\bv x + \Delta \bv x) - f(\bv x) \|_Y 
			\leq \|\mathscr L(\bv x) \Delta \bv x\|_Y
				 + \|\alpha(\bv x; \Delta \bv x)\|_Y 
			\leq \|\mathscr L(\bv x)\| \|\Delta \bv x\|_X 
				+ \|\alpha(\bv x; \Delta \bv x)\|_Y \to 0\,.
	\end{equation*}
\end{proof}

\begin{theorem}[Linearity of differentiation]
	\label{theorem: linearity (differential)}
	Let $X$, $Y$ be two normed space on $\mathbb F$ ($\mathbb C$ or $\mathbb R$), $\bv x \in X$ is an interior point. 
	The space of all mappings differentiable at $\bv x$ is also a linear space on $\mathbb F$.
\end{theorem}

\begin{theorem}[Chain rule]
	Let $X$, $Y$, $Z$ be three normed spaces, $D \in \mathscr P(X)$, $f \in Y^D$, $g \in Z^{f(D)}$, and $f$ be differentiable at $\bv x \in D$, $g$ be differentiable at $\bv y := f(\bv x) \in f(D)$.
	\begin{equation*}
		(g \circ f)'(\bv x) = g'(\bv y) f'(\bv x)\footnote{Remember, we write the composition of two linear operators omitting the ``$\circ$'' in the middle.}\,.
	\end{equation*}
\end{theorem}

For example, $(\mathscr A \circ f)'(\bv x) = \mathscr A f'(\bv x)$, since $\mathscr A'(\bv y) = \mathscr A$.

\begin{theorem}[Differentiation of inverse mappings]
	Let $X$, $Y$ be two normed spaces, $D \in \mathscr P(X)$, bijective~$f \in X^D$, and $f$ be differentiable at $\bv x \in D$, and there be an inverse~$[f'(\bv x)]^{-1}$ for $f'(\bv x)$.
	Then, $f^{-1}$ is also differentiable at $\bv y := f(\bv x)$, and
	\begin{equation*}
		(f^{-1})'(\bv y) = [f'(\bv x)]^{-1}\,.
	\end{equation*}
\end{theorem}

Consider a mappings~$f \colon X \to Y $, where $Y := \prod_{i \in n} Y_i$, normed with $\|\bv y\|_Y := \sqrt[p]{\sum_{i \in n}\|\bv y_i\|_{Y_i}^p}$. 

By writing $f$ as $(f_i)_{i \in n}$ such that $f(\bv x) = (f_i(\bv x))_{i \in n}$, and 
\begin{equation*}
	f'(\bv x)\Delta \bv x = (f'_i(\bv x)\Delta \bv x)_{i \in n}\,,
\end{equation*}
we can conclude that $f$ is differentiable at $\bv x \in X$ \emphbf{iff} for each $f_i \colon X \to Y_i$, $i \in n$, is differentiable at $\bv x$.

\begin{theorem}[Differentiation of multilinear operators]
	\label{theorem: differentiation of multilinear operators}
	Let $X_0, \cdots, X_{n - 1}$, $Y$ be normed spaces, $\mathscr A \in \mathcal B(X_0, \cdots, X_{n - 1}; Y)$. 
	Let $X := \prod_{i \in n} X_i$ be normed space with a norm defined as:
	\begin{equation}\label{equation: norm of product space}
		\forall \bv x := (\bv x_i)_{i \in n} \in X, \quad
		\|\bv x\|_X := \Big( \sum_{i \in n} \|\bv x_i\|_{X_i}^p \Big)^{1/p}\,.
	\end{equation}

	Then, $\mathscr A$ is differentiable at all interior point $\bv x \in X$, and
	\begin{equation*}
		\dif \mathscr A (\bv x) = \mathscr A(\dif \bv x_0, \bv x_1, \cdots, \bv x_{n - 1}) + \cdots + \mathscr A(\bv x_0, \cdots, \bv x_{n-2}, \dif \bv x_{n-1})\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	By Eq.~\eqref{equation: norm of product space}, we have $\forall i \in n$,
	\begin{equation*}
		\|\bv x_i\|_{X_i} \leq \|\bv x\|_X 
			\leq \sum_{j \in n} \|\bv x_j\|_{X_j}\,.
	\end{equation*}

	Therefore $\forall i, j \in n$,
	\begin{equation*}
		\frac{\|\Delta \bv x_i\|_{X_i} \|\Delta \bv x_j\|_{X_j}}{\|\Delta \bv x\|_X} 
		\leq \frac{\|\Delta \bv x_i\|_{X_i} \|\Delta \bv x_j\|_{X_j}}{\|\Delta \bv x_i\|_{X_i}} 
			= \|\Delta \bv x_j\|_{X_j} 
		\leq \|\Delta \bv x\|_X\,,
	\end{equation*}
	or $\|\Delta \bv x_i\|_{X_i} \|\Delta \bv x_j\|_{X_j} = o(\bv x; \Delta \bv x)$.

	\begin{align*}
		\mathscr A(\bv x + \Delta &\bv x) - \mathscr A(\bv x) 
		\\ & =
		\mathscr A(\Delta \bv x_0, \bv x_1, \cdots, \bv x_{n-1})
			+ \mathscr A(\bv x_1, \Delta \bv x_1, \cdots, \bv x_{n-1})
			+ \cdots
			+ \mathscr A(\bv x_0, \bv x_1, \cdots, \Delta \bv x_{n-1}) 
		\\ & \qquad
			+ \mathscr A(\Delta \bv x_0, \Delta \bv x_1, \cdots, \bv x_{n-1})
			+ \cdots 
			+ \mathscr A(\bv x_0, \cdots, \Delta \bv x_{n-2}, \Delta \bv x_{n-1})
			+ \cdots 
			+ \mathscr A(\Delta \bv x)
		\\ & = 
		\mathscr A(\Delta \bv x_0, \bv x_1, \cdots, \bv x_{n-1})
			+ \cdots
			+ \mathscr A(\bv x_0, \cdots, \bv x_{n - 2}, \Delta \bv x_{n-1}) 
			+ o(\bv x; \Delta \bv x)\,,
	\end{align*}
	where we utilize the fact that
	\begin{equation*}
		\|\mathscr A(\Delta \bv x_0, \Delta \bv x_1, \cdots, \bv x_{n-1})\|_Y
			\leq \|\mathscr A\| \|\Delta \bv x_0\|_{X_0} \|\Delta \bv x_1\|_{X_1}
				\prod_{i \in n \backslash 2} \|\bv x_i\|_{X_i} = o(\bv x; \Delta \bv x)\,,\; \cdots
	\end{equation*}

	Therefore
	\begin{equation*}
		\dif \mathscr A(\bv x)\Delta \bv x
			= \mathscr A(\Delta \bv x_0, \bv x_1, \cdots, \bv x_{n-1})
				+ \cdots
				+ \mathscr A(\bv x_0, \cdots, \bv x_{n - 2}, \Delta \bv x_{n-1}) 
	\end{equation*}
	or 
	\begin{equation*}
		\dif \mathscr A (\bv x) 
			= \mathscr A(\dif \bv x_0, \bv x_1, \cdots, \bv x_{n - 1}) + \cdots + \mathscr A(\bv x_0, \cdots, \bv x_{n-2}, \dif \bv x_{n-1})\,.
	\end{equation*}

\end{proof}

Let $\mathcal U(X; Y)$ be the set of \indexbf{reversible operators} in $\mathcal B(X; Y)$ i.e.\ $\forall \mathscr A \in \mathscr U(X; Y)$, $\exists \mathscr A^{-1} \in \mathscr B(Y; X)$ s.t.\ 
\begin{equation*}
	\mathscr A \mathscr A^{-1} = \id_Y; 
	\quad
	\mathscr A^{-1} \mathscr A = \id_X.
\end{equation*}

\begin{theorem}[Differential of reversion]
	\label{theorem: differential of reversion}
	Let $X$ be a complete normed space, and $Y$ be a normed space. $\mathscr A \in \mathcal U(X; Y)$, $\delta \mathscr A \in \mathcal B(X; Y)$.
	If $\|\delta \mathscr A\| < \|\mathscr A^{-1}\|^{-1}$, then $\mathscr A + \delta \mathscr A \in \mathcal U(X; Y)$,
	\begin{equation*}
		(\mathscr A + \delta \mathscr A)^{-1} = \mathscr A^{-1} - \mathscr A^{-1}\delta \mathscr A \mathscr A^{-1} + o(\delta \mathscr A)\,,
	\end{equation*}
	as $\delta \mathscr A \to \mathscr O$.
\end{theorem}
\begin{proof}
	Since $X$ is complte, by Theorem~\ref{theorem: Y is complete so is the space of linear operators onto it}, we know $\mathcal B(X; X)$ is complete.
	Notice $ - \mathscr A^{-1} \delta \mathscr A \in \mathcal B(X; X)$, and by Theorem~\ref{theorem: norm of operator composition},
	\begin{equation*}
		\| -\mathscr A^{-1} \delta \mathscr A\| 
		\leq \|\mathscr A^{-1}\| \|\delta \mathscr A\| 
		< \|\mathscr A^{-1}\| \|\mathscr A^{-1}\|^{-1} = 1\,,
	\end{equation*} 
	$\forall \varepsilon \in \mathbb R_+$, let
	\begin{equation*}
		N > \log_{\|\mathscr A^{-1} \delta \mathscr A\|} 
		\frac{\varepsilon (1 - \|\mathscr A^{-1} \delta \mathscr A\|)}{\|\mathscr A^{-1} \delta \mathscr A\|}
	\end{equation*}
	(we assume that $\mathscr A^{-1} \delta \mathscr A \neq \mathscr O$, or the inequality is trivial), $m > n > N$, then
	\begin{align*}
		\left\|
			\sum_{k = n + 1}^{m}(-\mathscr A^{-1} \delta \mathscr A )^k
		\right\| 
			&\leq \sum_{k = n + 1}^{m} \|\mathscr A^{-1} \delta \mathscr A \|^k
			= \frac{1 - \|\mathscr A^{-1} \delta \mathscr A\|^{m - n}}{1 - \|\mathscr A^{-1} \delta \mathscr A\|} \|\mathscr A^{-1} \delta \mathscr A\|^{n + 1}
			\\
			&\leq \frac{\|\mathscr A^{-1} \delta \mathscr A\|^{n + 1}}{1 - \|\mathscr A^{-1} \delta \mathscr A\|} < \varepsilon\,,
	\end{align*}
	hence $\sum_{k \in n} (- \mathscr A^{-1} \delta \mathscr A)^k$ is a Cauchy sequence, therefore convergent i.e. $\sum_{k \in \mathbb N} (- \mathscr A^{-1} \delta \mathscr A)^k$.

	We can verify $\sum_{k \in \mathbb N} (- \mathscr A^{-1} \delta \mathscr A)^k = (\id_X + \mathscr A^{-1} \delta \mathscr A)^{-1}$.

	Since $\mathscr A + \delta \mathscr A = \mathscr A (\id_X + \mathscr A^{-1} \delta \mathscr A)$, we conclude
	\begin{equation*}
		(\mathscr A + \delta \mathscr A)^{-1} 
		= \sum_{k \in \mathbb N} (- \mathscr A^{-1} \delta \mathscr A)^k \mathscr A^{-1}\,,
	\end{equation*}
	and
	\begin{align*}
		\|(\mathscr A + \delta \mathscr A)^{-1} -& \mathscr A^{-1} + \mathscr A^{-1} \delta \mathscr A \mathscr A^{-1}\| 
		= \left\|
			\sum_{k = 2}^{\infty} (- \mathscr A^{-1} \delta \mathscr A)^k \mathscr A^{-1}
		\right\| 
		\\
		&\leq
		\sum_{k = 2}^{\infty} \|\mathscr A^{-1} \delta \mathscr A\|^k \|\mathscr A^{-1}\| 
		= \frac{\|\mathscr A^{-1}\| \|\mathscr A^{-1} \delta \mathscr A\|^2}{1 - \|\mathscr A^{-1} \delta \mathscr A\|}
		= o(\|\delta \mathscr A\|)\,.
	\end{align*}
\end{proof}

Let $f \in Y^X$ where $X := \prod_{i \in n} X_i$. 
We define a mapping
\begin{equation}\label{equation: local mapping}
	\varphi_i \colon X_i \to X;\;
	 \bv x_i \mapsto (\bv a_0, \bv a_1, \cdots, \bv a_{i-1}, \bv x_i, \bv a_{i + 1}, \cdots, \bv a_{n-1})\,,
\end{equation}
so that $f \circ \varphi_i$ means the mapping of alone $\bv x_i$, leaving other variables unchanged.

\begin{definition}[Partial derivative]
	Let $f \in Y^X$ where $X := \prod_{i \in n} X_i$ be the product of normed spaces, $Y$ be a normed space. 
	$\forall i \in n$, $\varphi_i$ is defined as Eq.~\eqref{equation: local mapping}.
	If $f \circ \varphi_i$ is differentiable at an interior point $\bv a_i \in X_i$, we call its derivative at this point the \indexbf{partial derivative} of $f$ with respect to $\bv x_i$ at $\bv a := (\bv a_i)_{i \in n}$, denoted by $\indexmath[partial i f]{\partial_i f}(\bv a)$ or $\indexmath[pdiff f x i]{\pdiff{f}{\bv x_i}(\bv a)}$.
\end{definition}

\begin{theorem}[Differentiable then partial derivative exists]
	\label{theorem: differentiable then partial derivative exists}
	Let $X_1, \cdots, X_{n - 1}$ and $Y$ be normed spaces, $X := \prod_{i \in n} X_i$, $f \in Y^X$, $\bv a \in X$.
	If $f$ is differentiable at $\bv a$, then $\forall i \in n$, $f \circ \varphi_i$ is differentiable $\bv a_i \in X_i$, and
	\begin{equation}
		\dif f(\bv a) = \sum_{i \in n} \partial_i f(\bv a) \dif \bv x_i\,.
	\end{equation}
\end{theorem}

\begin{definition}[Continuously differentiable]
	Let $f \in Y^X$ and differentiable at $\bv x \in X$. If the derivative mapping~$f' \in \mathscr B(X; Y)^X$ is continuous at $\bv x$, we say that $f$ is \indexbf{continuously differentiable} at point~$\bv x$. 

	We can denote all continuously differentiable mappings from an open set $X$ to $Y$ by $\indexmath[C 1 X Y]{C^{(1)}(X, Y)}$\footnote{or $\indexmath[C 1 X]{C^{(1)}(X)}$ if you are sure about what $Y$ is.}. 
\end{definition}

By Theorem~\ref{theorem: differentiable then continuous} we know that $C^{(1)}(X, Y) \subset C(X, Y)$.

\begin{theorem}[Continuously differentiable iff partial derivative is continuous (differentiable mapping)]
	\label{theorem: continuously differentiable iff partial derivative is continuous (differentiable mapping)}
	Let $X_0, \cdots, X_{n - 1}$, $Y$ be normed spaces, $X := \prod_{i \in n} X_i$, $\bv x \in X$, $f \in Y^X$ is differentiable at $\bv x$.
	$f$ is continuouly differentiable at $\bv x$ \emph{iff} $\forall i \in n$, $\partial_i f \in \mathcal B(X_i; Y)^X$.
\end{theorem}
\begin{proof}
	\begin{align*}
		\|\partial_i f(\bv x + \Delta \bv x) - \partial_i f(\bv x)\| 
			&\leq \left\|\sum_{j \in n} \big(
					\partial_j f(\bv x + \Delta \bv x) - \partial_i f(\bv x)\big)
				\right\|
			= \|\dif f(\bv x + \Delta \bv x) - \dif f(\bv x)\|
			\\
			&\leq \sum_{j \in n}
				\|\partial_j f(\bv x + \Delta \bv x) - \partial_j f(\bv x)\| 
	\end{align*}
\end{proof}

\begin{definition}[Derivative with respect to a vector]\index{derivative with respect to a vector}
	Let $X$ and $Y$ be two normed space over $\mathbb R$ or $\mathbb C$, $U$ be an open set in $X$, $f \in Y^U$, $\bv x \in U$.
	The derivative of $f$ with respect to a vector $\bv \ell$ is defined as:
	\begin{equation*}
		\pdiff{f}{\bv \ell}(\bv x) 
			:= \lim_{t \to 0} \frac 1 t [f(\bv x + t \bv \ell) - f(\bv x)]\,.
	\end{equation*}
\end{definition}

\begin{theorem}[Derivative with respect to a vector when differentiable]
	\label{theorem: derivative with respect to a vector when differentiable}
	Let $X$ and $Y$ be two normed space over $\mathbb R$ or $\mathbb C$, $U$ be an open set in $X$, $f \in Y^U$, $\bv x \in U$.
	If $f$ is differentiable at $\bv x$, then $\forall \bv \ell \in X$, the derivative of $f$ with respect to $\bv \ell$ exists, and
	\begin{equation*}
		\pdiff{\bv f}{\bv \ell} (\bv x) = f'(\bv x) \bv \ell\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	\begin{equation*}
		\lim_{t \to 0} \frac 1 t [f(\bv x + t \bv \ell) - f(\bv x)]
			= \lim_{t \to 0} \frac 1 t [f'(\bv x) t \bv \ell + o(t \bv \ell)]
			= f'(\bv x) \bv \ell\,.
	\end{equation*}
\end{proof}

\section{Finite-Increment Theorem}

We now study the generalisation of the Lagrangian mean value theorem, or the finite-increment theorem.

Let us recall and generalised the definition of interval:
\begin{definition}
	Let $X$ be a linear space over a field~$\mathbb F$ which contains $\mathbb R$, $\bv a, \bv b \in X$. The \emphbf{closed}\index{closed interval} and \indexbf{open interval} is defined as:
	\begin{align*}
		\indexmath[x y]{[\bv x, \bv y]} &:= \{\bv x + \theta(\bv y - \bv x) 
			\mid 0 \leq \theta \leq 1\}\,,\\
		\indexmath[x y]{(\bv x, \bv y)} &:= \{\bv x + \theta(\bv y - \bv x) 
			\mid 0 < \theta < 1\}\,.
	\end{align*}

	Similarly we can define $[\bv x, \bv y)$, $(\bv x, \bv y]$.
\end{definition}

\begin{theorem}[Finite-increment theorem]
	\label{theorem: finite-increment theorem}
	Let $X$ and $Y$ be two normed spaces, $G \in \mathscr T_X$, where $\mathscr T_X$ is the topology induced by the norm $\|*\|_X$. 
	Let $f \in C(G, Y)$, $[\bv x_0, \bv x_0 + \Delta \bv x] \subset G$.
	If $\forall \bv x \in (\bv x_0, \bv x_0 + \Delta \bv x)$, $f$ is differentiable at $\bv x$, then
	\begin{equation*}
		\|f(\bv x_0 + \Delta x) - f(\bv x_0)\|_Y 
			\leq \sup \{\|f'(\bv \xi)\|  \mid \bv \xi \in (\bv x_0, \bv x_0 + \Delta \bv x)\} \|\Delta \bv x\|_X\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	First we assume that $f$ is differentiable in closed interval $[\bv x, \bv x + \Delta \bv x]$ (later we would return to the more generalised situation).

	Let us denote $M_{[t_1, t_2]} := \sup \{\|f'(\bv x_0 + t\Delta \bv x)\|  \mid t \in [t_1, t_2] \}$. 
	If there exists $\varepsilon_0 \in \mathbb R_+$, $\|f(\bv x_0 + \Delta \bv x) - f(\bv x)\|_Y > (M_{[0, 1]} + \varepsilon_0) \|\Delta \bv x\|_X$, since 
	\begin{equation*}
		\|f(\bv x_0 + \Delta \bv x) - f(\bv x)\|_Y \leq
		\|f(\bv x_0 + \Delta \bv x) - f(\bv x_0 + \Delta \bv x / 2)\|_Y
			+ \|f(\bv x_0 + \Delta \bv x / 2) - f(\bv x)\|\,,
	\end{equation*}
	and $M_{[0, 1/2]} \leq M_{[0, 1]}$, $M_{[1/2, 1]} \leq M_{[0, 1]}$, the following two inequality \emph{cannot} be both true: 
	\begin{align*}
		\|f(\bv x_0 + \Delta \bv x) - f(\bv x_0 + \Delta \bv x / 2)\|_Y 
			&\leq (M_{[1/2, 1]} + \varepsilon_0) \|\Delta \bv x\|_X/2\,;
		\\
		\|f(\bv x_0 + \Delta \bv x / 2) - f(\bv x)\| 
			&\leq (M_{[0, 1/2]} + \varepsilon_0) \|\Delta \bv x\|_X / 2 \,.
	\end{align*} 
	
	We would repeatedly divide the interval which does not satisfies the finite-increment theorem into two, and finally we would have a collections of closed intervals $\langle[a_i, b_i]\rangle_{i \in \mathbb N}$ s.t.\ $a_i \leq a_{i + 1} < b_{i +1} \leq b_i$, $\forall i \in \mathbb N$, over which the inequality
	\begin{equation*}
		\|f(\bv x_0 + b_i \Delta \bv x) - f(\bv x_0 + a_i \Delta \bv x)\|_Y
			> (M_{[a_i, b_i]} + \varepsilon_0) |b_i - a_i| \|\Delta \bv x\|_X
	\end{equation*}
	holds.

	Since $[0, 1]$ is a compact set in $\mathbb R$, and $|b_i - a_i| = 2^{-i}$, $\exists c \in [0, 1]$ s.t.\ $\bigcap_{i \in \mathbb N} [a_i, b_i] = \{c\}$.

	Because we can say $c$ divides all $[a_i, b_i]$ into two, we shall always choose one of $\{a_i, b_i\}$ as $c_i$ s.t.\ 
	\begin{equation}\label{equation: inequality that violates differentiable}
		\|f(\bv x_0 + c \Delta \bv x) - f(\bv x_0 + c_i \Delta \bv x)\|_Y
			> (M_{[c, c_i]} + \varepsilon_0) |c_i - c| \|\Delta \bv x\|_X\,.
	\end{equation}

	However, by the differentiability of $f$ at $\bv x_0 + c \Delta \bv x$, $\forall \varepsilon \in \mathbb R_+$, there exists an $N \in \mathbb N$, as long as $i > N$
	\begin{align*}
		\|f(\bv x_0 + c \Delta \bv x) - f(\bv x_0 + c_i \Delta \bv x)\|_Y 
			&\leq \|f'(\bv x_0 + c\Delta \bv x)\||c_i - c|\|\Delta \bv x\|_X
				+ o(|c_i - c|) \|\Delta \bv x\|_X
		\\
			&\leq (M_{[c, c_i]} + \varepsilon) |c_i - c|\|\Delta \bv x\|_X\,.
	\end{align*}

	Letting $\varepsilon = \varepsilon_0$ we would find a contradiction.

	Now if the function~$f$ is only differentiable in $(\bv x_0, \bv x_0 + \Delta \bv x)$, we have proved that $\forall \bv x_1, \bv x_2 \in (\bv x_0, \bv x_0 + \Delta \bv x)$, 
	\begin{equation*}
		\|f(\bv x_2) - f(\bv x_1)\| \leq M_{[t_1, t_2]} \|\bv x_1, \bv x_2\|_X\,.
	\end{equation*}
	where $\bv x_1 = \bv x_0 + t_1 \Delta \bv x$, $\bv x_2 = \bv x_0 + t_2 \Delta \bv x$.

	Since both $\|*\|$ and $f$ is continuous (Theorem~\ref{theorem: continuity of norm} and Theorem~\ref{theorem: differentiable then continuous}), we shall pass $\bv x_1$, $\bv x_2$ to $\bv x_0$ and $\bv x_0 + \Delta \bv x$, and get
	\begin{equation*}
		\|f(\bv x_0 + \Delta \bv x) - f(\bv x_0)\|_Y 
			\leq \sup \{\|f'(\bv \xi)\|  \mid \bv \xi \in (\bv x_0, \bv x_0 + \Delta \bv x)\} \|\Delta \bv x\|_X\,.
	\end{equation*}
\end{proof}

\begin{corollary}
	\label{corollary: difference between derivative and any linear operator}
	Let $X$ and $Y$ be two normed spaces, $G \in \mathscr T_X$, where $\mathscr T_X$ is the topology induced by the norm $\|*\|_X$. 
	Let $f \in C(G, Y)$, $[\bv x_0, \bv x_0 + \Delta \bv x] \subset G$.
	$\forall \mathscr A \in \mathcal B(X, Y)$, 
	\begin{equation*}
		\|f(\bv x + \Delta \bv x) - f(\bv x) - \mathscr A \Delta \bv x\|_Y
			\leq \sup \big\{\|f'(\bv \xi) - \mathscr A\| \|\Delta x\|_X 
				\mid \bv \xi \in [\bv x_0, \bv x_0 + \Delta \bv x]\big\}\,.
	\end{equation*}
\end{corollary}
\begin{proof}
	Define:
	\begin{equation*}
		F \colon [0, 1] \to Y; \; 
		t \mapsto f(\bv x + t \Delta \bv x) - \mathscr A t \Delta \bv x\,.
	\end{equation*}

	By the finite-increment theorem~\ref{theorem: finite-increment theorem}, 
	\begin{align*}
		\|F(1) - F(0)\|_Y 
		&= \|f(\bv x + \Delta \bv x) - f(\bv x) - \mathscr A \Delta \bv x\|_Y
		\\
		&\leq \sup\big\{\|F'(\xi)\| \mid \xi \in [0, 1]\big\} |1 - 0|
		= \sup\big\{\|f'(\bv x + \xi \Delta \bv x)\Delta \bv x - \mathscr A \Delta \bv x \| \mid \xi \in [0, 1]\big\}
		\\
		&\leq \sup\big\{\|f'(\bv x + \xi \Delta \bv x) - \mathscr A \| \mid \xi \in [0, 1]\big\} \|\Delta \bv x\|_X\,.
	\end{align*}
\end{proof}

\begin{theorem}[Continuously differentiable then Lipschitz continuous]
	\label{theorem: continuously differentiable then Lipschitz continuous}
	Let $K$ be a convex%
		\footnote{a \indexbf{convex set} is a set that contains all points on the straight segment jointing any two points i.e.\ $\forall \bv x_1, \bv x_2 \in C$, $[\bv x_1, \bv x_2] \subset C$.}
	compact set in a normed space $X$, and $Y$ be a normed space, $f \in Y^K$.
	If $f \in C^{(1)}(K, Y)$, then $f$ is Lipschitz continuous.
\end{theorem}
\begin{proof}
	$f' \in C(K; \mathcal B(X; Y))$, $\|*\|_Y \in C (Y; \mathbb R)$, hence the composition~$g \colon K \to \mathbb R;\; \bv x \mapsto \|f'(\bv x)\|_Y$ is also continuous. 
	Recall Theorem~\ref{theorem: Weierstrass maximum-value}, we conclude that $\exists M$, $\forall \bv x \in K$, $g(\bv x) \leq M$.

	Since $K$ is convex, $\forall \bv x_1, \bv x_2 \in K$, $[\bv x_1, \bv x_2] \subset K$. 
	By finite-increment theorem~\ref{theorem: finite-increment theorem}, we have:
	\begin{equation*}
		\|f(\bv x_2) - f(\bv x_1)\|_Y 
			\leq \sup\big\{\|f'(\bv x)\| \mid \bv x \in [\bv x_1, \bv x_2]\big\} 
				\|\bv x_2 - \bv x_1\|_X
			\leq M  \|\bv x_2 - \bv x_1\|_X \,.
	\end{equation*}
\end{proof}

\begin{theorem}
	Let $K$ be a convex compact set in a normed space $X$, and $Y$ be a normed space, $f \in C^{(1)}(K, Y)$. 
	$\exists \omega \in \mathbb R^\mathbb R$ s.t.\ $\lim_{x \to + 0} \omega(x) = 0$, and $\forall \bv x \in X$, if $\Delta \bv x \in K \cap B(\bv x; \delta)$, then
	\begin{equation*}
		\|f(\bv x + \Delta \bv x) - f(\bv x) - f'(\bv x) \Delta \bv x\|_Y
			\leq \omega(\delta) \|\Delta \bv x\|_X\,,
	\end{equation*}
	for some $\delta \in \mathbb R_+$.
\end{theorem}
\begin{proof}
	By Corollary~\ref{corollary: difference between derivative and any linear operator}, 
	\begin{equation*}
		\|f(\bv x + \Delta \bv x) - f(\bv x) - f'(\bv x) \Delta \bv x\|_Y
			\leq \sup \big\{\|f'(\bv \xi) - f'(\bv x)\|  
				\mid \bv \xi \in [\bv x_0, \bv x_0 + \Delta \bv x]\big\}
				\|\Delta x\|_X\,.
	\end{equation*}

	Let
	\begin{equation*}
		\omega(\delta) 
		= \sup\big\{\|f'(\bv x_2) - f'(\bv x_1)\| \mid \bv x_1, \bv x_2 \in K 
			\wedge d_X(\bv x_1, \bv x_2) < \delta\big\}\,.
	\end{equation*}
\end{proof}

With the finite-increment theorem, we can generalised Theorem~\ref{theorem: continuously differentiable iff partial derivative is continuous (differentiable mapping)} to any mappings, instead of differentiable mappings alone.

\begin{theorem}[Continuously differentiable iff partial differential is continuous]
	\label{theorem: continuously differentiable iff partial differential is continuous}
	Let $X_0$, $\cdots$, $X_{n-1}$, $Y$ be normed spaces, $X := \prod_{i \in n} X_i$, $G \in \mathscr T_X$, $f \in Y^G$.

	$f \in C^{(1)}(G, Y)$ $\IFF$ $\forall i \in n$, $\partial_i f \in C(G, \mathcal B(X; Y))$.
\end{theorem}
\begin{proof}
	$\to$: 
	We have proved that if the mapping~$f$ is continuously differentiable in $G$, $\forall i \in n$, $\partial_i f$ is continuous. (Theorem~\ref{theorem: continuously differentiable iff partial derivative is continuous (differentiable mapping)}).

	$\gets$:
	Denote
	\begin{equation*}
		\mathscr L := \sum_{i \in n} \partial_i f(\bv x) \dif \bv x_i\,,
	\end{equation*}
	and we shall show that $\mathscr L$ is the differential of $f$ at $\bv x \in G$.

	Let us introduce a notation, 
	\begin{equation*}
		\Delta_i f(\bv a) := f(\bv a_0, \cdots, \bv a_{i-1}, \bv a_i + \Delta \bv x_i, \bv a_{i+1}, \cdots, \bv a_{n-1}) - f(\bv a)\,.
	\end{equation*}

	Then
	\begin{align*}
		&f(\bv x + \Delta \bv x) - f(\bv x) - \mathscr L \Delta \bv x 
		\\
		&= \Delta_0 f(\bv x_0, \bv x_1 + \Delta \bv x_1, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1}) - \partial_0 f(\bv x)\Delta \bv x_0
		\\
		&\quad + \Delta_1 f(\bv x_0, \bv x_1, \bv x_2 + \Delta \bv x_2, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1}) 
			- \partial_1 f(\bv x) \Delta \bv x_2
		\\
		&\quad + \cdots 
		 + \Delta_{n-1} f(\bv x) \Delta \bv x_{n-1} - \partial_{n-1} f(\bv x) \Delta \bv x_{n-1}
		\,.
	\end{align*}

	By Corollary~\ref{corollary: difference between derivative and any linear operator}, we have:
	\begin{align*}
		&\|f(\bv x + \Delta \bv x) - f(\bv x) - \mathscr L \Delta \bv x\|_Y 
		\\
		&\leq \|\Delta_0 f(\bv x_0, \bv x_1 + \Delta \bv x_1, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1}) - \partial_0 f(\bv x)\Delta \bv x_0\|_Y
		\\
		&\quad + \cdots 
		 + \|\Delta_{n-1} f(\bv x) \Delta \bv x_{n-1} - \partial_{n-1} f(\bv x) \Delta \bv x_{n-1}\|_Y
		\\
		&\leq \sup\Big\{\big\|\partial_0 f(\bv \xi_0, \bv x_1 + \Delta \bv x_1, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1}) 
		\\
			&\qquad\qquad - \partial_0 f(\bv x_0, \bv x_1 + \Delta \bv x_1, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1})\big\|_Y
		\mid \bv \xi_0 \in [\bv x_0, \bv x_0 + \Delta \bv x_0]\Big\} 
			\|\Delta \bv x_0\|_{X_0}
		\\
		&\quad + \cdots 
		 + \sup\Big\{\big\|\partial_{n-1} f(\bv x_0, \cdots, \bv \xi_{n-1}) - \partial_{n-1} f(\bv x)\big\|_Y
		 \mid \bv \xi_{n-1} \in [\bv x_0, \bv x_0 + \Delta \bv x_0]\Big\} 
			 \|\Delta \bv x_{n-1}\|_{X_{n-1}} \,.
	\end{align*}

	Since $\partial_i f \in C(X_i, Y)$, we know
	\begin{align*}
		&\lim_{\Delta \bv x_i \to \bv 0}\sup\Big\{\big\|\partial_0 f(\bv x_0, \cdots, \bv \xi_i, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1}) 
		\\
			&\qquad\qquad\qquad - \partial_0 f(\bv x_0, \cdots, \bv x_i, \cdots, \bv x_{n-1} + \Delta \bv x_{n-1})\big\|_Y
		\mid \bv \xi_i \in [\bv x_0, \bv x_0 + \Delta \bv x_0]\Big\} 
		\\
		&= 0\,.
	\end{align*}

	Since $\max\{\|\Delta \bv x_i\|_{X_{i}}\}_{i \in n} \leq \|\Delta \bv x\|_X$ (check Eq.~\eqref{equation: norm of product space}), we know that
	\begin{equation*}
		f(\bv x + \Delta \bv x) - f(\bv x) - \mathscr L \Delta \bv x
		= o(\Delta \bv x)\,,
	\end{equation*}
	which means $\dif f(\bv x) = \mathscr L$.
\end{proof}

Then we shall use finite-increment theorem~\ref{theorem: finite-increment theorem} to prove some useful theorems.

\begin{theorem}[Derivative functions doesn't have removable discontinuity]
	Let $X$, $Y$ be two normed spaces, $\bv x_0 \in X$, $U \in \mathscr U(\bv x_0)$, $f \in Y^U$.
	If $f$ is differentiable in $\mathring U := U - \{\bv x_0\}$, and
	\begin{equation*}
		\lim_{\bv x \to \bv x_0} f'(\bv x) = \mathscr L \in \mathcal B(X; Y)\,,
	\end{equation*}
	then $f$ is differentiable at $\bv x_0$ and $f'(\bv x_0) = \mathscr L$. 
\end{theorem}
\begin{proof}
	Find a $\Delta \bv x$ that satisfies $[\bv x, \bv x + \Delta \bv x] \subset U$.
	By Corollary~\ref{corollary: difference between derivative and any linear operator}, 
	as $\Delta \bv x \to 0$, we have
	\begin{equation*}
		\|f(\bv x_0 + \Delta \bv x) - f(\bv x_0) - \mathscr L \Delta \bv x\|_Y
			\leq \sup\left\{ 
				\|f'(\bv \xi) - \mathscr L\| 
			\middle|
				\bv \xi \in (\bv x_0, \bv x_0 + \Delta \bv x)
			 \right\} \|\Delta \bv x\|_X
			 = o(1) \|\Delta \bv x\|_X
			 = o(\Delta \bv x)\,.
	\end{equation*}
	
	By the definition of differetial, we know $f'(\bv x_0) = \mathscr L$.
\end{proof}

\begin{theorem}[Constant if derivative is zero in a convex open set]
	Let $X$, $Y$ be normed spaces, $U$ be a convex open set in $X$, $f \in Y^U$.
	If $\forall \bv x \in U$, $f$ is differentiable at $\bv x$, and $f'(\bv x) = \mathscr O$, 
	then $f$ is a constant function from $U$ 
		i.e.\ $\exists \bv y_0 \in Y$, $\forall \bv x \in U$, $f(\bv x) = \bv y_0$.
\end{theorem}
\begin{proof}
	Let $\bv x_0 \in U$. $\forall \bv x \in U$, since $U$ is convex, $[\bv x_0, \bv x] \subset U$.
	The finite-increment theorem~\ref{theorem: finite-increment theorem} therefore yields:
	\begin{equation*}
		\|f(\bv x) - f(\bv x_0)\|_Y 
			\leq \sup \{ \|f'(\bv \xi)\| \mid \bv \xi \in [\bv x_0, \bv x]\} \|\bv x - \bv x_0\|_X
			= 0\,.
		\end{equation*} 

	In the normed space $Y$ this implies that $f(\bv x_0) = f(\bv x)$.
\end{proof}

\begin{theorem}[Constant if derivative is zero in a connected open set]
	Let $X$, $Y$ be normed spaces, $U$ be a connected open set in $X$, $f \in Y^U$.
	If $\forall \bv x \in U$, $f$ is differentiable at $\bv x$, and $f'(\bv x) = \mathscr O$, 
	then $f$ is a constant function from $U$.
\end{theorem}
\begin{proof}
	Let $\bv x_0 \in U$. 
	Consider a set $E := \{\bv x \in U \mid f(\bv x) = f(\bv x_0)\}$.

	First, $E$ is open.
	$\forall \bv x \in E$, $\exists B(\bv x; \delta) \subset U$. 
	Since $\forall \bv x' \in B(\bv x; \delta)$, $[\bv x, \bv x'] \subset B(\bv x; \delta)$, $f$ is constant in $B(\bv x; \delta)$ and therefore $B(\bv x; \delta) \subset E$. 
	In conclusion, all points in $E$ are interior.

	Then, $U - E$ is also open in the topological subspace $U$, with the same reason. 

	Since $E$ is not empty, ($\bv x_0 \in E$), the only choice for a open-closed set in a connected set $U$ is $U$ itself, i.e.\ $\forall \bv x \in U$, $f(\bv x) = f(\bv x_0)$.
\end{proof}

\section{Higher-Order Derivative}

We denote the zeroth and first differential of $f \in Y^U$, where $U$ is an open set in a normed space $X$, by $f^{(0)} := f$, $f^{(1)} := f'$.

\begin{definition}[$n$-th differentiation]
	Let $X$ and $Y$ be normed spaces, with induced topologies $\mathscr T_X$ and $\mathscr T_Y$. 
	For brevity, we define $Y_0 := Y$, and $Y_{n+1} := \mathcal B(X; Y_n)$.

	The definition of \emphbf{$n$-th differential}%
		\index{n-th differentiation@$n$-th differentiation}
	is introduced below recursively:
	We have already defined the zeroth and the first defferentiation. 
	If the $n$-th differential $f^{(n)} \in {Y_n}^U$ is differentiable in $U \in \mathscr T_X$
		\footnote{$Y_n$ is also a normed space.},
	we can define the $(n + 1)$-th differential $\indexmath[f n x]{f^{(n)}(\bv x)}$ by:
	\begin{equation*}
		f^{(n + 1)}= (f^{(n)})'\,. 
	\end{equation*}
\end{definition}

\begin{theorem}[Higher-oder differentiation operates on vectors]
	Let $X$ and $Y$ be normed spaces, with induced topologies $\mathscr T_X$ and $\mathscr T_Y$, $U \in \mathscr T_X$, $\bv x \in U$, $(\bv \ell_i)_{i \in n} \in X^n$.
	If $f \in Y^U$ has $n$-th differential $f^{(n)}$ in $U$, 
	\begin{equation}
		\label{equation: higher-oder differentiation operates on vectors}
		((f^{(n)}(\bv x) \bv \ell_0) \cdots \bv \ell_{n-1}) 
			= \pdiff{}{\bv \ell_0} \cdots \pdiff{}{\bv \ell_{n-1}} f(\bv x)\,.
	\end{equation} 
\end{theorem}
\begin{proof}
	See Theorem~\ref{theorem: derivative with respect to a vector when differentiable}.
\end{proof}

\begin{theorem}[Symmetry of higher-order differentiation]
	\label{theorem: symmetry of higher-order differentiation}
	Let $\sigma \in S_n$ where $S_n$ is the symmetric group%
		\footnote{Or permutation}
	on $n$.
	Let $X$ and $Y$ be normed spaces, with induced topologies $\mathscr T_X$ and $\mathscr T_Y$, $U \in \mathscr T_X$, $\bv x \in U$, $(\bv \ell_i)_{i \in n} \in X^n$.
	If $f \in Y^U$ has $n$-th differential $f^{(n)}$ in $U$, then
	\begin{equation*}
		\pdiff{}{\bv \ell_{\sigma(0)}} \cdots \pdiff{}{\bv \ell_{\sigma(n-1)}} f(\bv x)
			= \pdiff{}{\bv \ell_0} \cdots \pdiff{}{\bv \ell_{n-1}} f(\bv x)\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	We shall only prove the case when $n = 2$.

	The second differetial~$f''(\bv x)$ exists implies that the first differential $f'(\bv x)$ also exists. 
	Since $U$ is open, there exists an open ball $B(0; \delta) \subset U$, where $\delta \in \mathbb R_+$.

	Let
	\begin{align*}
		&\Delta(t) := f(\bv x + t \bv \ell_0 + t \bv \ell_1) 
			- f(\bv x + t \bv \ell_0) - f(\bv x + t \bv \ell_1) + f(\bv x)\,,
		\\
		&D(t, t') := f(\bv x + t \bv \ell_0 + t' \bv \ell_1)
			- f(\bv x + t' \bv \ell_1)\,,
	\end{align*}
	where $t \in [0, \delta)$, $t' \in [0, t]$. 

	It is obvious that $\Delta(t) = D(t, t) - D(t, 0)$. 
	By the finite-increment theorem~\ref{theorem: finite-increment theorem}, 
	\begin{align*}
		\|\Delta(t) - &t^2 [f''(\bv x) \bv \ell_0] \bv \ell_1\|_Y
			= \|D(t, t) - D(t, 0) - t^2 [f''(\bv x) \bv \ell_0] \bv \ell_1\|_Y
		\\
			&\leq t \sup \left\{
				\left\|
					\pdiff{D}{t'}(t, \theta) - t \theta [f''(\bv x) \bv \ell_0] \bv \ell_1
				\right\|_Y
			\middle|
				\theta \in (0, t)
			\right\}
		\\
			&\leq t \|\bv \ell_1\|_X \sup \left\{
				\left\|
					f'(\bv x + t \bv \ell_0 + \theta \bv \ell_1)
						- f'(\bv x + \theta \bv \ell_1) 
						- t \theta f''(\bv x) \bv \ell_0
				\right\|
			\middle|
				\theta \in (0, t)
			\right\}
		\\
			&= t  \|\bv \ell_1\|_X \sup \left\{
				\left\|
					 	\theta f''(\bv x) (t\bv \ell_0 + \theta \bv \ell_1 - \theta \bv \ell_1)
						- t \theta f''(\bv x) \bv \ell_0
						+ o(t)
				\right\|
			\middle|
				\theta \in (0, t)
			\right\}
		\\
			&= o(t^2)\,.
	\end{align*} 

	Hence, 
	\begin{equation*}
		[f''(\bv x) \bv \ell_0]\bv \ell_1 = \lim_{t \to 0} \frac{\Delta(t)}{t^2}\,.
	\end{equation*}

	Substituting $(\bv \ell_0, \bv \ell_1)$ by $(\bv \ell_1, \bv \ell_0)$ in the definition of $\Delta(t)$ doesn't change its value, hence we have proved the theorem in the case when $n = 2$.
\end{proof}

Theorem~\ref{theorem: symmetry of higher-order differentiation} implies that the $n$-th derivative~$f^{(n)}(\bv x)$ corresponds to a $n$-symmetric multilinear operator in $\mathcal B(X, \cdots, X; Y)$%
\footnote{By Corollary~\ref{corollary: important isomorphism}, these two spaces are isomorphic}, 
and we shall denote:
\begin{equation} \label{equation: f^(n)(x)(l_i)_i in n}
	f^{(n)}(\bv x)(\bv \ell_i)_{i \in n} :=
	((f^{(n)}(\bv x)\bv \ell_0)\cdots)\bv \ell_{n-1}\,,
\end{equation}
and
\begin{equation}\label{equation: f^(n)(x) l^n}
	f^{(n)}(\bv x) \bv \ell^n := f^{(n)}(\bv \ell, \cdots, \bv \ell)\,.
\end{equation}

\begin{theorem}
	Let $X_0, \cdots, X_{m-1}, Y$ be normed spaces, and $X := \prod_{i \in m} X_i$.
	Let $f \in Y^U$ where $U$ is an open set in $X$.
	If $\forall (i_k)_{k \in n} \in m^n$, $\forall \bv x \in U$, $n$-th partial derivative
	\begin{equation*}
		\partial_{i_0} \cdots \partial_{i_{m-1}} f(\bv x) 
	\end{equation*}
	exists and continuous (with respect to $\bv x$), then $f$ is $n$-th differentiable at $\bv x$ i.e.\ $f^{(n)}$ exists, and is also continous.

	Further more, 
	\begin{equation*}
		f \in C^{(n)}(U) 
			\IFF \forall (i_k)_{k \in n} \in m^n,\; 
				\partial_{i_0} \cdots \partial_{i_{m-1}} f \in C\,,
	\end{equation*}
	where we denote the set of $n$-th differentiable functions on $U$ by $\indexmath[C n U Y]{C^{(n)}(U; Y)}$ ($\indexmath[C n X]{C^{(n)}(U)}$, alternatively).
\end{theorem}

\section{Applications of Differentiation}
\subsection{Taylor's Formula}
\begin{theorem}[Taylor's formula]\index{Taylor's formula}
	Let $X$ and $Y$ be two normed spaces, $\bv x \in X$, $U \in \mathscr U(x)$, $f \in Y^U$. 
	If $f$ is $(n-1)$-th differentiable in $U$, and $n$-th differentiable at point~$\bv x$, then as $\Delta \bv x \to \bv 0$ ($\bv x + \Delta \bv x \in U$), 
	\begin{equation}\label{equation: Taylor}
		f(\bv x + \Delta \bv x) = \sum_{k \in n + 1} f^{(k)}(\bv x) \frac{\Delta \bv x^k}{k !} + o(\|\Delta \bv x\|_X^n)\,,
	\end{equation}
	where we have made use of the notation we introduced at Eq.~\eqref{equation: f^(n)(x) l^n}.
\end{theorem}
\begin{proof}
	If we consider each term of the Taylor's formula as a function of $\Delta \bv x$, we can find them to be differentiable (with respect to $\Delta \bv x$), since $f^{(k)}(\bv x) \in \mathcal B(X, \cdots, X; Y)$. The derivative of the symmetric $k$-linear operator
	\begin{equation*}
		T_k(\Delta \bv x) := \frac{1}{k!} f^{(k)}(\bv x) \Delta \bv x^k
	\end{equation*}
	with respect to $\Delta \bv x$ is%
		\footnote{cf.~Theorem~\ref{theorem: differentiation of multilinear operators}}:
	\begin{equation*}
		T_k'(\Delta \bv x) \bv \ell = \frac{1}{(k - 1)!} f^{(k)}(\bv x) \Delta \bv x^{k - 1} \bv \ell\,.
	\end{equation*}

	Hence, if we assume that the Eq.~\eqref{equation: Taylor} holds for $n - 1$, by the finite-increment theorem~\ref{theorem: finite-increment theorem}, we conclude:
	\begin{align*}
		&\left\|
			f(\bv x + \Delta \bv x) - \sum_{k \in n + 1} T_k(\Delta \bv x)
		\right\|_Y 
		\\
		&\quad
			\leq \sup \left\{
				\left\|
					f'(\bv x + \bv \xi) - \sum_{k \in n} \frac{1}{k!} f^{(k + 1)}(\bv x) \bv \xi^k
				\right\|_Y
			\middle|
				\bv \xi \in [\bv 0, \Delta \bv x]
			\right\} \|\Delta \bv x\|_X 
			\\
		&\quad
			= o(\bv \xi^{n-1}) \|\Delta \bv x\|_X = o(\Delta \bv x^n)\,.
	\end{align*}
\end{proof}

\begin{theorem}
	Let $X$, $Y$ be two normed spaces, $U$ be an open set in $X$, $f \in C^{(n)}(X; Y)$. 
	Let $[\bv x, \bv x + \Delta \bv x] \subset U$, and $f$ be $(n + 1)$-th differentiable in $(\bv x, \bv x + \Delta \bv x)$.

	If $\forall \bv \xi \in (\bv x, \bv x + \Delta \bv x)$, $\|f^{(n+1)}(\bv \xi)\| \leq M$,
	then 
	\begin{equation*}
		\left\|
			f(\bv x + \Delta \bv x) - \sum_{k \in n + 1} \frac{1}{k!} f^{(k)}(\bv x) \Delta \bv x^k
		\right\|_Y \leq \frac{M}{(n + 1)!}\|\Delta \bv x\|_X^{n + 1}\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	Define a function $g \in Y^{[0, 1]}$:
	\begin{equation*}
		g(t) := f(\bv x + \Delta \bv x) - \sum_{k \in n + 1} \frac{(1 - t)^k}{k!} f^{(k)}(\bv x + t \Delta \bv x) \Delta \bv x^k\,,
	\end{equation*}

	Notice the derivative of $(1-t)^k f^{(k)}(\bv x + t \Delta \bv x) / k!$ with respect to $t$ is:
	\begin{equation*}
		\diff{}{t} \left( 
			\frac{(1 - t)^k}{k!} f^{(k)}(\bv x + t \Delta \bv x)  
		 \right)
		= \frac{(1 - t)^k}{k!} f^{(k + 1)}(\bv x + t \Delta \bv x) \Delta \bv x 
		- \frac{k(1 - t)^{k-1}}{k!} f^{(k)}(\bv x + t \Delta \bv x) \,,
	\end{equation*}

	We have:
	\begin{equation*}
		g'(t) = - \frac{(1 - t)^n}{n!} f^{(n + 1)}(\bv x + t \Delta \bv x) \Delta \bv x^{n + 1}\,,
	\end{equation*}
	therefore
	\begin{equation*}
		\|g'(t)\| 
		\leq \frac{|1-t|^n}{n!} \|f^{(n + 1)}(\bv x + t \Delta \bv x)\| \| \Delta \bv x\|_X^{n + 1}
		\leq \frac{M (1-t)^n}{n!} \|\Delta \bv x\|_X^{n+1}\,.
	\end{equation*}

	Making use of $[- (1-t)^{n + 1}]' = (n + 1) (1 - t)^n$ and the definition of differentiation, $\forall \varepsilon \in \mathbb R_+$, $\exists \delta \in \mathbb R_+$, if $1 - t \leq \delta$, then:
	\begin{equation*}
		\|g(t)\|_Y - \frac{\varepsilon}{2}(1 - t) \leq \|g'(t)\|(1 - t) 
		\leq  \frac{M (1-t)^n}{n!} (1 - t) \|\Delta \bv x\|_X^{n+1}
		\leq \frac{M (1-t)^{n + 1}}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \frac{\varepsilon}{2}(1 - t)\,,
	\end{equation*}
	or
	\begin{equation*}
		\|g(t)\|_Y \leq \frac{M (1-t)^{n + 1}}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \varepsilon (1 - t)\,.
	\end{equation*}
	
	Since such $\delta$ exists, for $\varepsilon$, we define $\delta'$ as the supremum of the $\delta$s\cite[p.~64]{coleman2012calculus}, i.e.\ 
	\begin{equation*}
		\delta' := \sup \left\{
			\delta \in \mathbb R_+ 
			\middle| 
			1 - t \leq \delta \;\to\; \|g(t)\|_Y \leq \frac{M (1-t)^{n + 1}}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \varepsilon (1 - t)\,.
		\right\}
	\end{equation*}

	If $\delta' \neq 1$, then for $ t < 1 - \delta'$, again we make use of the definition of differentiation, starting at $\delta'$, $\exists \eta \in \mathbb R_+$, if $\delta' - t \leq \eta$, then
	\begin{equation*}
		\|g(t) - g(\delta')\|_Y \leq \frac{M [(1-\delta')^{n + 1} - (1 - t)^{n+1}]}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \varepsilon (\delta' - t) \,,
	\end{equation*}
	and
	\begin{align*}
		\|g(t)\|_Y &\leq \|g(t) - g(\delta')\|_Y + \|g(\delta')\|_Y
		\\
		&\leq \frac{M [(1-\delta')^{n + 1} - (1 - t)^{n+1}]}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} 
			+ \varepsilon (\delta' - t) 
		+ \frac{M (1-\delta')^{n + 1}}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} 
			+ \varepsilon (1 - \delta')
		\\
		&=  \frac{M (1-t)^{n + 1}}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \varepsilon (1 - t)\,,
	\end{align*}
	which contradicts to the definition of $\delta'$.

	Hence $\delta' = 1$, or:
	\begin{equation*}
		\|g(0)\|_Y \leq \frac{M}{(n + 1)!} \|\Delta \bv x\|_X^{n+1} + \varepsilon\,,
	\end{equation*}
	which holds for any $\varepsilon \in \mathbb R_+$, hence:
	\begin{equation}\label{equation: Lagrange remainder}
		\|g(0)\|_Y \leq \frac{M}{(n + 1)!} \|\Delta \bv x\|_X^{n+1}\,.
	\end{equation}

	Eq.~\eqref{equation: Lagrange remainder} is to prove.
\end{proof}

\begin{lemma}
	\label{lemma: zero symmetric multilinear operator}
	Let $X$, $Y$ be a linear space, $\mathscr A \in \mathcal B(X, \cdots, X; Y)$ i.e.\ $\mathscr A$ is an $n$-linear operators from $X$, \ldots, $X$ to $Y$. 
	If $\forall \bv x \in X$, $\mathscr A \bv x^n = \bv 0$, then $\forall (\bv x_i)_{i \in n} \in X^n$, $\mathscr A(\bv x_i)_{i \in n} = \bv 0$.
\end{lemma}
\begin{proof}
	\begin{align*}
		2 \mathscr A(\bv x_0, \bv x_1) 
			&= \mathscr A(\bv x_0, \bv x_1) + \mathscr A(\bv x_0, \bv x_2)
		\\
			&= \mathscr A(\bv x_0, \bv x_0) + \mathscr A(\bv x_0, \bv x_1 - \bv x_0)
				+ \mathscr A(\bv x_1, \bv x_0 - \bv x_1) + \mathscr A(\bv x_1, \bv x_1)
		\\
			&= \mathscr A(\bv x_0, \bv x_0) + \mathscr A(\bv x_1, \bv x_1) - \mathscr A(\bv x_1 - \bv x_0, \bv x_1 - \bv x_0)\,.
	\end{align*}
\end{proof}

\begin{theorem}[The uniqueness of Taylor's finite expansion]
	Let $X$, $Y$ be normed spaces, $f \in Y^U$ where $U$ is an open set in $X$.
	If $f$ is $n$-th differentiable at point $\bv x \in U$, and $\forall k \in n + 1$, exists $k$-linear operators $\mathscr L_k$ s.t.\ 
	\begin{equation*}
		f(\bv x + \Delta \bv x) = \sum_{k \in n+1} \mathscr L_k \Delta \bv x^k + o(\|\Delta \bv x\|_X^n)
	\end{equation*}
	as $\Delta \bv x \to \bv 0$, then, $\mathscr L_k = f^{(k)}(\bv x)$.
\end{theorem}
\begin{proof}
	It is obvious that $\mathscr L_0 = f^{(0)}(\bv x) = f(\bv x)$. 
	Assume that $\forall i \in k$, $f^{(i)}(\bv x) = \mathscr L_i$, then
	\begin{equation*}
		\sum_{i \in k + 1} \frac{1}{i!} f^{(i)}(\bv x)\Delta \bv x^i + o(\|\Delta \bv x\|_X^k)
		 = \sum_{i \in k + 1} \frac{1}{i!} \mathscr L_i \Delta \bv x^i + o(\|\Delta \bv x\|_X^k)\,,
	\end{equation*}
	hence:
	\begin{equation*}
		[f^{(k)}(\bv x) - \mathscr L_k]\Delta \bv x^k = o(\|\Delta \bv x\|_X^k)\,.
	\end{equation*}

	Divides each sides by $\|\Delta \bv x\|_X^k$ and passing the limit $\Delta \bv x \to 0$, we have:
	\begin{equation*}
		\lim_{\Delta \bv x \to 0} [f^{(k)}(\bv x) - \mathscr L_k] \left( 
			\frac{\Delta \bv x}{\|\Delta \bv x\|_X}
		 \right)^k = \lim_{\Delta \bv x \to 0} o(1) = \bv 0\,,
	\end{equation*}
	which means $\forall \basis e \in X$ s.t. $\|\basis e\|_X = 1$, $[f^{(k)}(\bv x) - \mathscr L_k] \basis e^k = \bv 0$. This means $f^{(k)}(\bv x) - \mathscr L_k = \mathscr O$, by Lemma~\ref{lemma: zero symmetric multilinear operator}.
\end{proof}

\subsection{Interior Extrema}

\begin{definition}[Extremum]
	Let $X$ be a normed space, and $f \in \mathbb R^X$. 
	If $\bv x \in X$ satisfies: $\exists U \in \mathscr U(\bv x)$ s.t.\ 
	$\forall \bv x' \in U - \{\bv x\}$, $f(\bv x) > f(\bv x')$, then $\bv x$ is a \indexbf{locally maximum point} of $f$.
	Similarily, we can define \indexbf{locally minimun point}. Both locally maximum point and minimum point are called \indexbf{extrmum point}.
\end{definition}

\begin{theorem}
	Let $X$ be a normed space, $U$ is an open set in $X$, and $f \in \mathbb R^U$.
	The mapping~$f$ is $n$-th differentiable in $U$, and $(n + 1)$-th differentiable at $\bv x \in U$, where $n \in \mathbb N_+$.
	$\forall k \in n + 1$, $f^{(k)}(\bv x) = \mathscr O$, and $f^{(n + 1)}(\bv x) \neq \mathscr O$.

	If $f$ reach its extremum at $\bv x$, then $n + 1 \in 2\mathbb Z$ and $f^{(n + 1)}(\bv x)$ is semidefinite, i.e.\ $\not\exists \Delta \bv x, \Delta \bv x' \in X$ s.t.\ $f^{(n + 1)}(\bv x) \Delta \bv x^{n+1} f^{(n + 1)}(\bv x) \Delta \bv x'^{n+1} < 0$.
\end{theorem}
\begin{proof}
	$\exists \Delta \bv x \in X$, $f^{(n + 1)}(\bv x)\Delta \bv x^{n+1} \neq 0$ since $f^{(n + 1)}(\bv x) \neq \mathscr O$. $\exists \delta \in \mathbb R_+$, as $t \in (-\delta, \delta)$, 
	\begin{equation*}
		o(1) = \frac{1}{t^{n +1}} o((t\Delta \bv x)^n)  > -\frac{1}{(n+1)!} f^{(n + 1)}(\bv x) \Delta \bv x^{n+1}\,,
	\end{equation*} 
	hence
	\begin{equation*}
		f(\bv x + t \Delta \bv x) - f(\bv x) = \left( 
			\frac{1}{(n+1)!} f^{(n + 1)}(\bv x) \Delta \bv x^{n+1} + o(1)
		 \right)t^{n + 1}\,.
	\end{equation*}

	If the difference remians its sign, then $n + 1$ must be an even number.
\end{proof}

\begin{theorem}
	Let $X$ be a normed space, $U$ is an open set in $X$, and $f \in \mathbb R^U$.
	The mapping~$f$ is $n$-th differentiable in $U$, and $(n + 1)$-th differentiable at $\bv x \in U$, where $n \in \mathbb N_+$.
	$\forall k \in n + 1$, $f^{(k)}(\bv x) = \mathscr O$, and $f^{(n + 1)}(\bv x) \neq \mathscr O$.

	If $\exists \delta \in \mathbb R_+$, $\forall \basis e \in X$ s.t.\ $\|\basis e\|_X = 1$, $|f^{(n + 1)}(\bv x) \basis e^{n+1}| \geq \delta$, then $f$ reaches its extremum.
	If $f^{(n + 1)}(\bv x) \basis e^{n+1} > 0$, then $\bv x$ is a local maximum point; 
	If $f^{(n + 1)}(\bv x) \basis e^{n+1} < 0$, then $\bv x$ is a local minimum point. 
\end{theorem}
\begin{proof}
	Assume that $f^{(n + 1)}(\bv x) \Delta \bv x^{n+1} > 0$.
	
	\begin{align*}
		f(\bv x - \Delta \bv x) - f(\bv x)
		&= \frac{1}{k!} f^{(n + 1)}(\bv x) \Delta \bv x^{n+1} + o(\Delta \bv x^{n+1})
		\\
		&= \|\Delta \bv x\|_X^{n+1} \left( 
			\frac{1}{k!} f^{(n + 1)}(\bv x) \left(\frac{\Delta \bv x}{\|\Delta \bv x\|_X}\right)^{n+1} + o(1)
		 \right)
		\\
		&\geq
		\|\Delta \bv x\|_X^{n+1} \left( 
			\frac{\delta}{k!}  + o(1)
		 \right) \to \|\Delta \bv x\|_X^{n+1} \frac{\delta}{k!} > 0\,.
	\end{align*}	
\end{proof}

\section{Implicit Function Theorem}

\begin{theorem}[Implicit function theorem]
	\label{theorem: implicit function theorem}\index{implicit function theorem}
	Let $X$, $Z$ be normed spaces, and $Y$ be a Banach space.
	$\bv x_0 \in X$, $\bv y_0 \in Y$. Denote
	\begin{equation*}
		W := B(\bv x_0; \alpha) \times B(\bv y_0; \beta)\,,
	\end{equation*}
	where $\alpha, \beta \in \mathbb R_+$.
	If $F \in Z^W$ satisfies:
	\begin{conditionlist}[label=\alph*)]
		\item $F(\bv x_0, \bv y_0) = \bv 0$;
		\item $F$ is continuous at $(\bv x_0, \bv y_0)$;
		\item There exists the partial derivative of $F(\bv x, \bv y)$ with respect to $\bv y \in Y$: $\partial_{\bv y} F(\bv x, \bv y)$ in $W$, and $\partial_{\bv y} F$ is continuous at point $(\bv x_0, \bv y_0)$;
		\item $\partial_{\bv y} F(\bv x_0, \bv y_0) \in \mathcal B(Y; Z)$ is reversible i.e.\ $\exists [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \in \mathcal B(Z; Y)$ s.t.
		\begin{equation*}
			\partial_{\bv y} F(\bv x_0, \bv y_0) \circ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} 
			= [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \circ \partial_{\bv y} F(\bv x_0, \bv y_0) = \id_Y\,,
		\end{equation*}
	\end{conditionlist}
	then, $\exists U \in \mathscr U(\bv x_0)$, $\exists V \in \mathscr U(\bv y_0)$, $\exists f \in V^U$ s.t.\ $f$ is continuous at $\bv x_0$, $U \times V \subset W$ and $\forall \bv x \in U$, $\forall \bv y \in V$, 
	\begin{equation*}
		F(\bv x, \bv y) = \bv 0
		\IFF
		f(\bv x) = \bv y\,.
	\end{equation*}
\end{theorem}

Before our proof of the theorem, some explanation to it might be necessary. 
Given a $\bv x \in B(\bv x_0; \alpha)$, we want to find a $f(\bv x) \in B(\bv y_0; \beta)$ that satisfies $F[\bv x, f(\bv x)] = \bv 0$. 
If we have made an guess~$\bv y$, the error shall be $\Delta = f(\bv x) - \bv y$, of course since we don't know exactly what $f(\bv x)$ is, we shall estimate it.

Then we made an approximation. 
We assume that the behaviour of $F(\bv x, \bv y)$ is linear with respect to $\bv y$ around $(\bv x, f(\bv x))$, i.e.\ 
\begin{equation*}
	F(\bv x, \bv y) \approx \partial_{\bv y} F(\bv x, f(\bv x)) (\bv y - f(\bv x))
	\approx \partial_{\bv y} F(\bv x_0, \bv y_0) (\bv y - f(\bv x))
\end{equation*}

If we find that $F(\bv x, \bv y) \neq \bv 0$, we know that $\bv y$ is not the $f(\bv x)$ we are searching for, and by our approximation, it is about:
\begin{equation*}
	\Delta \approx \tilde{\Delta} = [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \circ F(\bv x, \bv y)\,.
\end{equation*}

Making use of our estimate of the error to correct $\bv y$, we get $\bv y' = \bv y - \tilde \Delta$. 
However, since we made a approximation (which is too much!), $\bv y'$ is also not $f(\bv x)$. So we repeat the procedure, which is estimate the error, correct it, and estimate the error again \ldots

But wait, would we finally get what we want? 
In analysis this is a bad question -- maybe we shall ask: as we repeat the procedure, would the result gets closed enough to the answer? 
The proof below would answer.

\begin{proof}
	Consider a function from $B(\bv y_0; \beta)$ to $Y$: 
	\begin{equation*}
		\Delta_{\bv x} (\bv y) 
			= \bv y - [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \circ F(\bv x, \bv y)\,,
	\end{equation*}
	
	Obviously, if $\bv y = f(\bv x) \IFF F(\bv x, \bv y)$ then $\Delta_{\bv x} (f(\bv x)) = f(\bv x)$ i.e.\ $f(\bv x)$ is a fix-point of the function $\Delta_{\bv x} (\bv y)$ of $\bv y$ with fixed $\bv x$. 
	Now we need to prove such fix-point exists.

	The function~$F(\bv x, \bv y)$ is differentiable with respect to $\bv y$ in $W$, so is $\Delta_{\bv x}(\bv y)$:
	\begin{equation*}
		\Delta_{\bv x}'(\bv y) 
		= \id_Y - [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv y} F(\bv x, \bv y) 
		= [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} [\partial_{\bv y} F(\bv x_0, \bv y_0) - \partial_{\bv y} F(\bv x, \bv y)]\,.
	\end{equation*}

	Take the norm of each side and by Theorem~\ref{theorem: norm of operator composition}, we have:
	\begin{equation*}
		\|\Delta_{\bv x}'(\bv y)\| 
			\leq \|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1}\|
			\|\partial_{\bv y} F(\bv x_0, \bv y_0) - \partial_{\bv y} F(\bv x, \bv y)\|\,.
	\end{equation*}

	Since $\partial_{\bv y} F$ is continuous at $(\bv x_0, \bv y_0)$, $\forall \varepsilon \in (0, 1)$, if $\gamma$ is small enough, $\forall \bv x \in B(\bv x_0; \gamma/2)$, $\forall \bv y \in B(\bv y_0; \gamma/2)$%
	\footnote{so that $d_{X \times Y} \big((\bv x, \bv y), (\bv x_0, \bv y_0)\big) = \sqrt[p]{\|\bv x - \bv x_0\|_X^p + \|\bv y - \bv y_0\|_Y^p} \leq d_X(\bv x, \bv x_0) + d_Y(\bv y, \bv y_0) < \gamma$} , 
	\begin{equation*}
		\|\partial_{\bv y} F(\bv x_0, \bv y_0) - \partial_{\bv y} F(\bv x, \bv y)\| 
			< \frac{\varepsilon}{\|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1}\|}\,.
	\end{equation*}
	
	By the finite-increment theorem~\ref{theorem: finite-increment theorem}, $\forall \bv y, \bv y' \in B(\bv y_0; \gamma/2)$, 
	\begin{align*}
		\|\Delta_{\bv x}(\bv y') - \Delta_{\bv x}(\bv y)\|_Y 
			&\leq \sup\{\|\Delta_{\bv x}'(\bv \xi)\| \mid \bv \xi \in [\bv y, \bv y']\}
				\|\bv y - \bv y'\|_Y
		\\
			&\leq \|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1}\|
			\|\partial_{\bv y} F(\bv x_0, \bv y_0) - \partial_{\bv y} F(\bv x, \bv y)\|
			\|\bv y - \bv y'\|_Y
		\\
			&< \varepsilon \|\bv y - \bv y'\|_Y \,.
	\end{align*}
	
	In another word, $\Delta_{\bv x} (\bv y)$ is a $\varepsilon$-contraction, from $B(\bv y_0; \gamma/2)$ to $B(\bv y_0; \gamma/2)$. 
	
	To apply the Picard-Banach fixed-point principle~\ref{theorem: Picard-Banach}, we need to find a closed metric subspace $\big(\tilde{B}(\bv y_0; \delta), d_Y\big)$, where $\delta \leq \gamma/2$. By Theorem~\ref{theorem: closed subspace of a complete space is complete}, $\tilde{B}(\bv y_0; \delta)$ is also complete. 
	But we don't know if $\Delta_{\bv x}\big(\tilde{B}(\bv y_0; \delta)\big) \subset \tilde{B}(\bv y_0; \delta)$ yet. 
	To satisfy this, we find a $\zeta \in (0, \gamma/2)$, s.t.\ $\|\Delta_{\bv x}(\bv y_0) - \bv y_0\|_Y < \delta (1 - \varepsilon)$ if $d_X(\bv x, \bv x_0) < \zeta$ so that 
	\begin{equation*}
		\|\Delta_{\bv x}(\bv y) - \bv y_0\|_Y
			\leq \|\Delta_{\bv x}(\bv y) - \Delta_{\bv x}(\bv y_0)\|_Y 
				+ \|\Delta_{\bv x}(\bv y_0) - \bv y_0\|_Y 
			< \varepsilon \|\bv y - \bv y_0\|_Y + (\varepsilon - 1) \delta
			< \varepsilon \varepsilon + (\varepsilon - 1) \delta = \delta\,.
	\end{equation*}
	
	Hence, there exists the unique fixed point for $\Delta_{\bv x}(\bv y) \in \tilde B(\bv y; \delta)$ for each $\bv x \in U := B(\bv x_0; \zeta)$, which is the $f(\bv x)$ we have been searching for.

	Finally we check if $f \colon U \to V$ is continuous at $\bv x_0$. 
	For any $\delta' \in (0, \delta)$, we can find another $\zeta' \in (0, \zeta)$ s.t.\ $\|\Delta_{\bv x}(\bv y_0) - \bv y_0\|_Y < \delta' (1 - \varepsilon)$ if $d_X(\bv x, \bv x_0) < \zeta'$, so that $\|\Delta_{\bv x}(\bv y) - \bv y_0\|_Y < \delta'$.
\end{proof}

\begin{theorem}[Continuity of implicit function]
	\label{theorem: continuity of implicit function}
	Let $X$, $Z$ be normed spaces, and $Y$ be a Banach space.
	$\bv x_0 \in X$, $\bv y_0 \in Y$. Denote
	\begin{equation*}
		W := B(\bv x_0; \alpha) \times B(\bv y_0; \beta)\,,
	\end{equation*}
	where $\alpha, \beta \in \mathbb R_+$.
	If $F \in Z^W$ satisfies:
	\begin{conditionlist}[label=\alph*)]
		\item $F(\bv x_0, \bv y_0) = \bv 0$;
		\item $F \in C (W; Z)$; 
		\item There exists the partial derivative of $F(\bv x, \bv y)$ with respect to $\bv y \in Y$: $\partial_{\bv y} F(\bv x, \bv y)$ in $W$, and $\partial_{\bv y} F$ is continuous at point $(\bv x_0, \bv y_0)$;
		\item $\partial_{\bv y} F(\bv x_0, \bv y_0) \in \mathcal B(Y; Z)$ is reversible,
	\end{conditionlist}
	then, $\exists U \in \mathscr U(\bv x_0)$, $\exists V \in \mathscr U(\bv y_0)$, $\exists f \in C(U; Y)$ s.t.\ $U \times V \subset W$ and $\forall \bv x \in U$, $\forall \bv y \in V$, 
	\begin{equation*}
		F(\bv x, \bv y) = \bv 0
		\IFF
		f(\bv x) = \bv y\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	By Theorem~\ref{theorem: differential of reversion}, $\|\partial F_{\bv y}(\bv x, \bv y)^{-1}\|$ is continuous in some neighbourhoods. 
	Hence, the conditions of implicit function theorem are also satisfied in these neighbourhoods.
\end{proof}

\begin{theorem}[Differentiability of implicit function]
	\label{theorem: differentiability of implicit function}
	Let $X$, $Z$ be normed spaces, and $Y$ be a Banach space.
	$\bv x_0 \in X$, $\bv y_0 \in Y$. Denote
	\begin{equation*}
		W := B(\bv x_0; \alpha) \times B(\bv y_0; \beta)\,,
	\end{equation*}
	where $\alpha, \beta \in \mathbb R_+$.
	If $F \in Z^W$ satisfies:
	\begin{conditionlist}[label=\alph*)]
		\item $F(\bv x_0, \bv y_0) = \bv 0$;
		\item $F$ is continuous at $\bv x_0, \bv y_0$; 
		\item There exist the partial derivatives of $F(\bv x, \bv y)$ with respect to $\bv y \in Y$: $\partial_{\bv y} F(\bv x, \bv y)$ and with respect to $\bv x$: $\partial_{\bv x} F(\bv x, \bv y)$, in $W$, and $\partial_{\bv y} F$, $\partial_{\bv x}(\bv x, \bv y)$ are continuous at point $(\bv x_0, \bv y_0)$;
		\item $\partial_{\bv y} F(\bv x_0, \bv y_0) \in \mathcal B(Y; Z)$ is reversible,
	\end{conditionlist}
	then, $\exists U \in \mathscr U(\bv x_0)$, $\exists V \in \mathscr U(\bv y_0)$, $\exists f \in V^U$ s.t.\ $U \times V \subset W$ and $\forall \bv x \in U$, $\forall \bv y \in V$, 
	\begin{equation*}
		F(\bv x, \bv y) = \bv 0
		\IFF
		f(\bv x) = \bv y\,,
	\end{equation*}
	and, $f$ is differentiable at $\bv x_0$:
	\begin{equation}
		\label{equation: differential of implicit function}
		f'(\bv x_0) = - [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0)\,.
	\end{equation}
\end{theorem}
\begin{proof}
	Let's vertify that the right-hand side of Eq.~\eqref{equation: differential of implicit function} is the differential of $f$ at $\bv x_0$. 
	Find a $\bv x + \Delta \bv x$ within $U$%
		\footnote{notice that $F(\bv x, f(\bv x)) = F(\bv x_0, \bv y_0) = \bv 0$.},
	\begin{align*}
		&\big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y
		\\&\qquad
		= \left\| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1}
			\big(
				\partial_{\bv y} F(\bv x_0, \bv y_0) [f(\bv x_0 + \Delta \bv x) - \bv y_0] 
				+ \partial_{\bv x} F(\bv x_0, \bv y_0) \Delta \bv x
			\big)
		\right\|_Y 
		\\&\qquad
		\leq  \| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \|
			\big\| \big(
				\partial_{\bv y} F(\bv x_0, \bv y_0) [f(\bv x_0 + \Delta \bv x) - \bv y_0] 
				+ \partial_{\bv x} F(\bv x_0, \bv y_0) \Delta \bv x
			\big) 
		\\&\qquad\qquad\qquad\qquad\qquad\qquad
			+ \big( F(\bv x, f(\bv x)) - F(\bv x_0, \bv y_0) \big)
			\big\|_Y\,.
	\end{align*}

	Since $F_{\bv x}'$, $F_{\bv y}'$ are continuous at $(\bv x_0, \bv y_0)$, $F$ is differentiable at $(\bv x_0, \bv y_0)$ (Theorem~\ref{theorem: continuously differentiable iff partial differential is continuous}).
	As $(\bv x_0 + \Delta \bv x, f(\bv x_0 + \Delta \bv x)) \to (\bv x_0, \bv y_0)$:
	\begin{align*}
		&\big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y
		\\&\qquad
		\leq \| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \|
		o\big(\Delta \bv x, f(\bv x_0 + \Delta \bv x) - f(\bv x_0) \big)
		\\&\qquad
		= \| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \| o(1) 
			(\|\Delta \bv x\|_X + \|f(\bv x_0 + \Delta \bv x) - f(\bv x_0)\|_Y)\,.
	\end{align*}

	However, 
	\begin{align*}
		&\|f(\bv x_0 + \Delta \bv x) - f(\bv x_0)\|_Y 
		\\
		&\quad
		= \big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x 
			- [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x 
		\big\|_Y
		\\
		&\quad
		\leq \big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y 
		\\&\qquad\qquad
		+ \|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0)\| 
			\|\Delta \bv x\|_X\,,
	\end{align*}
	hence we have:
	\begin{align*}
		&\big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y
		\\&\qquad
		\leq
		\| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \| 
			\Big[
				(1 + \|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0)\|)\|\Delta \bv x\|_X 
		\\&\qquad\qquad\qquad\qquad
				+ \|f(\bv x_0 + \Delta \bv x) - f(\bv x_0) + [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y \Big] o(1) \,,
	\end{align*}
	or,
	\begin{align*}
		&\big\| f(\bv x_0 + \Delta \bv x) - \bv y_0 
		+ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0) 
			\Delta \bv x \big\|_Y
		\\&\qquad
		\leq
		\frac{\| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \| (\|[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0)\| + 1) }
		{1 - \| [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \| o(1) } o(1) \|\Delta \bv x\|_X\,.
	\end{align*}

	By the continuity of $f$ at $\bv x_0$, as $\Delta \bv x \to \bv 0$, $o(1) \to 0$ as well, hence we have proved that: 
	\begin{equation*}
		f'(\bv x_0) 
			= -[\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \partial_{\bv x} F(\bv x_0, \bv y_0)\,. 
	\end{equation*}
\end{proof}

\begin{theorem}[Continuous differentiability of implicit function]
	\label{theorem: continuous differentiability of implicit function}
	Let $X$, $Z$ be normed spaces, and $Y$ be a Banach space.
	$\bv x_0 \in X$, $\bv y_0 \in Y$. Denote
	\begin{equation*}
		W := B(\bv x_0; \alpha) \times B(\bv y_0; \beta)\,,
	\end{equation*}
	where $\alpha, \beta \in \mathbb R_+$.
	If $F \in Z^W$ satisfies:
	\begin{conditionlist}[label=\alph*)]
		\item $F(\bv x_0, \bv y_0) = \bv 0$;
		\item $F \in C^{(1)}(W; Z)$; 
		\item $\partial_{\bv y} F(\bv x_0, \bv y_0) \in \mathcal B(Y; Z)$ is reversible i.e.\ $\exists [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \in \mathcal B(Z; Y)$ s.t.
		\begin{equation*}
			\partial_{\bv y} F(\bv x_0, \bv y_0) \circ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} 
			= [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \circ \partial_{\bv y} F(\bv x_0, \bv y_0) = \id_Y\,,
		\end{equation*}
	\end{conditionlist}
	then, $\exists U \in \mathscr U(\bv x_0)$, $\exists V \in \mathscr U(\bv y_0)$, $\exists f \in C^{(1)}(U; Y)$ s.t.\ $U \times V \subset W$ and $\forall \bv x \in U$, $\forall \bv y \in V$, 
	\begin{equation*}
		F(\bv x, \bv y) = \bv 0
		\IFF
		f(\bv x) = \bv y\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	By Theorem~\ref{theorem: continuously differentiable iff partial differential is continuous}, we know $\partial_{\bv x} F$ and $\partial_{\bv y} F$ are continuous in $U$, $V$.
	By Theorem~\ref{theorem: differential of reversion}, $[\partial_{\bv y} F]^{-1}$ is also continuous, hence $f'(bv x)$, being the composition of continuous mapping (given by Eq.~\ref{equation: differential of implicit function}), is also continuous.
\end{proof}

Recursively we can prove:

\begin{theorem}[$n$-th continuous differentiability of implicit function]
	\label{theorem: nth continuous differentiability of implicit function}
	Let $X$, $Z$ be normed spaces, and $Y$ be a Banach space.
	$\bv x_0 \in X$, $\bv y_0 \in Y$. Denote
	\begin{equation*}
		W := B(\bv x_0; \alpha) \times B(\bv y_0; \beta)\,,
	\end{equation*}
	where $\alpha, \beta \in \mathbb R_+$.
	If $F \in Z^W$ satisfies:
	\begin{conditionlist}[label=\alph*)]
		\item $F(\bv x_0, \bv y_0) = \bv 0$;
		\item $F \in C^{(k)}(W; Z)$; 
		\item $\partial_{\bv y} F(\bv x_0, \bv y_0) \in \mathcal B(Y; Z)$ is reversible i.e.\ $\exists [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \in \mathcal B(Z; Y)$ s.t.
		\begin{equation*}
			\partial_{\bv y} F(\bv x_0, \bv y_0) \circ [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} 
			= [\partial_{\bv y} F(\bv x_0, \bv y_0)]^{-1} \circ \partial_{\bv y} F(\bv x_0, \bv y_0) = \id_Y\,,
		\end{equation*}
	\end{conditionlist}
	then, $\exists U \in \mathscr U(\bv x_0)$, $\exists V \in \mathscr U(\bv y_0)$, $\exists f \in C^{(k)}(U; Y)$ s.t.\ $U \times V \subset W$ and $\forall \bv x \in U$, $\forall \bv y \in V$, 
	\begin{equation*}
		F(\bv x, \bv y) = \bv 0
		\IFF
		f(\bv x) = \bv y\,.
	\end{equation*}
\end{theorem}



\chapter{Integration}

\section{Lebesgue Measure}

We now generalise the concepts of `length', `area' and `volume', that is, we want to \emph{measure} the subset of a normed space.


\begin{definition}[Cuboid]
	Let $X_i$, $i \in n$ be 1D normed spaces. 
	The \emphbf{cuboids}\index{cuboid}~$I_{\bv a, \bv b}$ in $X := \prod_{i \in n} X_i$, where $\bv a, \bv b \in X$, are defined as:
	\begin{equation*}
		I_{\bv a, \bv b} 
			:= \{\bv x \in X \mid x_i \in  [a_i, b_i],\, \forall i \in n\}\,.
	\end{equation*}
\end{definition}

Before our definition of volume of subsets of $X$, we discuss on the volume of cuboids. 
The volume, or, the measure of the cuboids shall be like:
\begin{equation}
	\label{equation: measure of cuboid}
	\indexmath[mu(I(a, b))]{\mu(I_{\bv a, \bv b})} = \prod_{i \in n} \|a_i - b_i\|_i
\end{equation}

If a (countable) collection of cuboids are pairwise disjoint i.e.\ in which each two cuboids are disjoint, we shall expect their union has a volume:
\begin{equation*}
	\mu \left( 
		\bigcup_{i \in \mathbb N} I_i 
	 \right) = \sum_{i \in \mathbb N} \mu(I_i)\,,
\end{equation*}
where the right hand side could be finite or $\infty$.
Moreover, if they have no common interior point pairwisely, the equation still holds.

If there are a collections of cuboids $\{I_i\}_{i \in n}$ that covers the given cuboid $I$, we shall see:
\begin{equation*}
	\mu(I) \leq \sum_{i \in n} \mu(I_k)\,.
\end{equation*}

We shall expect the measue of the subsets of $X$ has the same properties. 
But we must limit our discussion on \emph{some} subsets of $X$, and we may study the reason in real analysis later.

\begin{definition}[$\sigma$-algebra]
	Let $\mathscr F \in 2^X$ be a collection of subsets of a set~$X$.
	If $\mathscr F$ satisfies:
	\begin{conditionlist}
		\item $\varnothing \in \mathscr F$;
		\item $\forall A \in \mathscr F$, $X - A \in \mathscr F$ (closed under complementation);
		\item $\forall \langle A_i\rangle_{i \in \mathbb N} \in \mathscr F^\mathbb N$, $\bigcup_{i \in \mathbb N} A_i \in \mathscr F$ (closed under counterable unions),
	\end{conditionlist}
	then $\mathscr F$ is said to be a \emphbf{$\sigma$-algebra}\index{sigma-algebra@$\sigma$-algebra}.
\end{definition}

As an example, the $\sigma$-algebra closure of cuboids (The intersections of all $\sigma$-algeras containing all cuboids) is called the \indexbf{Borel sets}.

\begin{definition}[Measure]
	Let $\mathscr F$ be a $\sigma$-algebra over $X$, $\mu \in (\{0\} \cup \mathbb R_+)^\mathscr F$. 
	If the function~$\mu$ satisfies:
	\begin{conditionlist}
		\item $\mu(\varnothing) = 0$;
		\item (Countable additivity) If $\langle A_i\rangle_{i \in \mathbb N} \in \mathscr F^\mathbb N$ are pair wise disjoint, then
		\begin{equation*}
			\mu \left( 
				\bigcup_{i \in \mathbb N} A_i 
			 \right) = \sum_{i \in \mathbb N} \mu(A_i)\,,
		\end{equation*}
	\end{conditionlist}
		then $\mu$ is called a \indexbf{measure function}.

		The pair $(X, \mathscr F, \mu)$ is called a \indexbf{measurable space}, and the sets in $\mathscr F$ are called \emphbf{measurable sets}\index{measurable set}.
		The image of a set in $\mathscr F$ under $\mu$ is called the measure of the set.
	
\end{definition}

We shall study one of the most import measures: Lebesgue measure. 

\begin{definition}[Lebesgue outer measure]
	The \indexbf{Lebsgue outer measure}~$\lambda^*$ is a function from $2^X$ to $[0, \infty] \subset \overline{\mathbb R} := \mathbb R \cup \{-\infty, \infty\}$, and is defined as:
	\begin{equation*}
		\lambda^*(A) := \inf \left\{
			\sum_{i \in \mathbb N} \mu(I_i) 
		\middle|
			A \subseteq \bigcup_{i \in \mathbb N} I_i 
		\right\}\,,
	\end{equation*}
	where the volume of the cuboids~$\mu$ is defined as Eq.~\eqref{equation: measure of cuboid}.
\end{definition}

\begin{theorem}[Monotone of Lebesgue outer measure]
	\label{theorem: monotone of Lebesgue outer measure}
	If $A \subseteq B$, then $\lambda^*(A) \leq \lambda^*(B)$.
\end{theorem}
\begin{proof}
	If $\{I_i\}_{i \in \mathbb N}$ covers $B$, then they must cover $A$.
\end{proof}

\begin{theorem}[Countable subadditivity of Lebesgue outer measure]
	\label{theorem: countable subadditivity of Lebesgue outer measure}
	$\forall \langle A_k \rangle_{k \in \mathbb N} \in (2^X)^\mathbb N$, 
	\begin{equation*}
		\lambda^* \left( \bigcup_{k \in \mathbb N} A_k \right)
		\leq
		\sum_{k \in \mathbb N} \lambda^*(A_k)\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	$\forall \varepsilon \in \mathbb R_+$, by the definition of infimum, for each $k \in \mathbb N$, find a sequence of cuboids~$\langle I^{(k)}_i \rangle_{i \in n}$ that covers $A_k$, and:
	\begin{equation*}
		\lambda^*(A_k) + \frac{\varepsilon}{2^k} > \sum_{i \in \mathbb N} \mu(I_i^{(k)})\,.
	\end{equation*}

	Summing the equation over $k$, we have:
	\begin{equation*}
		\sum_{k \in \mathbb N} \sum_{i \in \mathbb N} \mu(I_i^{(k)})
		\leq \sum_{k \in \mathbb N} \lambda^*(A_k) + \varepsilon\,.
	\end{equation*}

	As $\langle I^{(k)}_i \rangle_{i, k \in \mathbb N}$ covers $\bigcup_{k \in \mathbb N} A_k$, we have:
	\begin{equation*}
		\sum_{k \in \mathbb N} \lambda^*(A_k) + \varepsilon 
			\geq \sum_{k \in \mathbb N} \sum_{i \in \mathbb N} \mu(I_i^{(k)})
			\geq \lambda^* \left( 
				\bigcup_{k \in \mathbb N} A_k
			 \right)\,.
	\end{equation*}

	The inequality holds for any positive real number $\varepsilon$, hence:
	\begin{equation*}
		\sum_{k \in \mathbb N} \lambda^*(A_k) 
			\geq \lambda^* \left( 
				\bigcup_{k \in \mathbb N} A_k
			 \right)\,.
	\end{equation*}
\end{proof}

\begin{definition}[Carath\'eodory criterion]
	\index{Caratheodory criterion@Carath\'eodory criterion}%
	If $E \in 2^X$ satisfies that $\forall A \in 2^X$:
	\begin{equation*}
		\lambda^*(A) = \lambda^*(A \cap E) + \lambda^*(A  - E)\,,
	\end{equation*}
	then we say that $E$ is \indexbf{Lebesgue measurable}, and we can say $\lambda(E) := \lambda^*(E)$.
\end{definition}

We shall denote the collection of Lebesgue measurable sets in $X$ by $\mathscr F$.

\begin{theorem}[Lebesgue measurable sets is closed under finite unions]
	\label{theorem: Lebesgue measurable sets is closed under finite unions}
	Let $E_1$, $E_2$ be two Lebesgue measuable sets. 
	$E_1 \cup E_2 \in \mathscr F$.
\end{theorem}
\begin{proof}
	$\forall A \in 2^X$, 
	\begin{align*}
		\lambda^*(A) 
			&= \lambda^*(A \cap E_1) + \lambda^*(A - E_1)
		\\
			&= \lambda^*(A \cap E_1 \cap E_2) + \lambda^*(A \cap E_1 - E_2)
		+ \lambda^*((A - E_1) \cap E_2) + \lambda^*(A - E_1 - E_2)\,.
	\end{align*}

	It is easy to verify that:
	\begin{equation*}
		(A \cap E_1 \cap E_2) \cup ((A \cap E_1) - E_2) \cup ((A - E_1) \cap E_2)
		= A \cap (E_1 \cup E_2)\,,
	\end{equation*}
	therefore by Theorem~\ref{theorem: countable subadditivity of Lebesgue outer measure}:
	\begin{equation*}
		\lambda^*(A) \geq \lambda^*(A \cap (E_1 \cup E_2)) + \lambda^*(A - (E_1 \cup E_2))\,.
	\end{equation*}

	But $(A \cap (E_1 \cup E_2)) \cup (A - (E_1 \cup E_2)) = A$, again by Theorem~\ref{theorem: countable subadditivity of Lebesgue outer measure}, the reverse of the inequality holds.
\end{proof}

\begin{theorem}[Finite additivity of Lebesgue measure]
	\label{theorem: finite additivity of Lebesgue measure}
	Let $\langle E_i \rangle_{i \in n} \in \mathscr F^n$ be pairwise disjoint.
	$\forall A \in 2^X$, 
	\begin{equation*}
		\lambda^*\left(A \cap \bigcup_{i \in n} E_i \right)
		= \sum_{i \in n} \lambda^* (A \cap E_i)\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	We might prove this inductively.

	As $n = 1$, the proposition is trivial. Assume that for $n \in \mathbb N_+$ the proposition holds:
	\begin{align*}
		\lambda^*\left( A \cap \bigcup_{i \in n + 1} E_i \right)
		&= \lambda^*\left( A \cap \bigcup_{i \in n + 1} E_i \cap E_n \right)
		+  \lambda^*\left( A \cap \bigcup_{i \in n + 1} E_i - E_n \right)
		\\
		&= \lambda^*( A \cap E_n ) + \lambda^*\left( A \cap \bigcup_{i \in n} E_i \right)
		= \sum_{i \in n + 1} \lambda^*(A \cap E_i)\,.
	\end{align*}
\end{proof}

\begin{theorem}[Lebesgue measurable sets are $\sigma$-algebra]
	\label{theorem: Lebesgue measurable sets are sigma-algebra}
	$\mathscr F$ is a $\sigma$-algebra.
\end{theorem}
\begin{proof}
	It is obvious that $\varnothing \in \mathscr F$.
	Since $A \cap E = A - (X - E)$, $A - E = A \cap (X - E)$, the complement of a Lebesgue measurable set is also Lebesgue measurable.

	For any (convergent) sequence of sets $\langle E_i \rangle_{i \in \mathbb N}$, a pairwise disjoint sequence can be consturcted:
	\begin{equation*}
		F_i = E_i - \bigcup_{j \in i} E_j\,,
	\end{equation*}
	so that $\bigcup_{i \in n} F_i = \bigcup_{i \in n} E_i$.

	By the monotone of $\lambda^*$ (Theorem~\ref{theorem: monotone of Lebesgue outer measure}):
	\begin{equation*}
		\lambda^* \left( A - \bigcup_{i \in n} F_i \right) 
			\geq \lambda^* \left( A - \bigcup_{i \in \mathbb N} F_i \right)\,.
	\end{equation*}

	Since $\mathscr F$ is closed under finite unions%
		(Theorem~\ref{theorem: Lebesgue measurable sets is closed under finite unions}), 
	$\bigcup_{i \in n} F_i$ is also Lebesgue measurable.
	Also, $\lambda^*$ is countably subadditive:
	\begin{align*}
		\lambda^*(A) 
		&= \lambda^*\left( A - \bigcup_{i \in n} F_i \right) 
			+  \lambda^*\left( A \cap \bigcup_{i \in n} F_i \right)
		\\
		&\geq  \lambda^* \left( A - \bigcup_{i \in \mathbb N} F_i \right) 
			+ \sum_{i \in n} \lambda^* (A \cap F_i)\,. 
	\end{align*}

	Pass $n$ to the infinity, the inequality becomes:
	\begin{equation*}
		\lambda^*(A) 
		\geq  \lambda^* \left( A - \bigcup_{i \in \mathbb N} F_i \right) 
			+ \sum_{i \in \mathbb N} \lambda^* (A \cap F_i)
		\geq \lambda^* \left( A - \bigcup_{i \in \mathbb N} F_i \right) 
		+ \lambda^* \left( A \cap \bigcup_{i \in \mathbb N} F_i \right) \,.
	\end{equation*}

	The validity of the second `$\leq$' is again by the countable subadditivity of $\lambda^*$.
\end{proof}

\begin{theorem}[Countable additivity of Lebesgue measure]
	\label{theorem: countable additivity of Lebesgue measure}
	If $\langle E_i\rangle_{i \in \mathbb N} \in \mathscr F^\mathbb N$ is pairwise disjoint, then
	\begin{equation*}
		\lambda \left( 
				\bigcup_{i \in \mathbb N} A_i 
			 \right) = \sum_{i \in \mathbb N} \lambda(A_i)\,.
	\end{equation*}
\end{theorem}
\begin{proof}
	By Theorem~\ref{theorem: finite additivity of Lebesgue measure}, we have:
	\begin{equation*}
		\lambda^*\left( \bigcup_{i \in \mathbb N} E_i \right) 
			\geq \lambda^*\left( \bigcup_{i \in n} E_i \right)
			= \sum_{i \in n} \lambda^*(E_i)\,.
	\end{equation*}

	Passing $n \to \infty$, 
	\begin{equation*}
		\lambda^*\left( \bigcup_{i \in \mathbb N} E_i \right) 
			\geq  \sum_{i \in \mathbb N} \lambda^*(E_i)\,,
	\end{equation*}
	while the subadditive of $\lambda^*$ yields the reverse.
\end{proof}

\begin{definition}[Measure zero]
	If a set $E \in 2^X$ is Lebesgue measurable ($E \in \mathscr F$), and its measure is $0$, we say it is a set of (Lebesgue) \indexbf{measure zero}. 
	In another word, $E$ has measure zero, meaning, $\forall \varepsilon \in \mathbb R_+$, $\exists \langle I_i\rangle_{i \in \mathbb N}$ s.t.\ $E \subset \bigcup_{i \in \mathbb N} I_i$ and $\sum_{i \in \mathbb N} \mu(I_i) < \varepsilon$. 
	Here $I_i$ are cuboids.
\end{definition}

We can easily conclude that the sets containing only a point is of measure zero.

\begin{theorem}[The countable union of sets of measure zero is also of measure zero]
	\label{theorem: the countable union of sets of measure zero is also of measure zero}
	Let $E_k$, $k \in \mathbb N$ be sets of measure zero, then $\bigcup_{k \in \mathbb N} E_k = 0$.
\end{theorem}
\begin{proof}
	For each set $E_k$, find it a cover with cuboids that the sum of the measure of the cuboids are less than $\varepsilon / 2^k$.
\end{proof}

\begin{theorem}[The subset of a set of measure zero is also of measure zero]
	\label{theorem: the subset of a set of measure zero is also of measure zero}
	Let $E$ be of measure zero, $F \subset E$. $F$ is of measure zero.
\end{theorem}

\begin{lemma}
	\label{lemma: zero measure defined by open cuboids}
	$E$ has measure zero iff $\forall \varepsilon \in \mathbb R_+$, $\exists \langle I'_i\rangle_{i \in \mathbb N}$ s.t.\ $E \subset \bigcup_{i \in \mathbb N} I'_i$ and $\sum_{i \in \mathbb N} \mu(I'_i) < \varepsilon$.
	Here $I'_i$ are open cuboids, defined by products of $n$ open intervals. 
\end{lemma}
\begin{proof}
	For any $\varepsilon$ we multiply it by $\lambda^n$ where $\lambda < 1$, the definition yield that we can find a sequence of cuboids, the sum of the measure of which is less than $\lambda^n \varepsilon$.
	We extend the cuboids by $\lambda^{-1}$, we see that the interior point of which contain the previous cuboids.
\end{proof}

\begin{theorem}
	\label{theorem: compact zero measure defined by finite cuboids}
	A compact set~$K$ has measure zero iff $\forall \varepsilon \in \mathbb R_+$, $\exists \langle I_i\rangle_{i \in \mathbb N}$ s.t.\ $E \subset \bigcup_{i \in \mathbb N} I_i$ and $\sum_{i \in \mathbb N} \mu(I_i) < \varepsilon$. 
\end{theorem}
\begin{proof}
	By Lemma~\ref{lemma: zero measure defined by open cuboids}, we can find an open cover with measure less than $\varepsilon$ of $E$, and therefore there is a finite subcover. 
	The measure of the subcover is of course less than that of the cover. 
\end{proof}

\section{\texorpdfstring{Riemann Integral over $n$-D cuboids}{Riemann Integral over n-D cuboids}}

Now we introduce the partition of the cuboid: 
\begin{definition}[Partition of a cuboid]
	A \indexbf{partition}~$P$ of a cuboid~$I_{\bv a, \bv b}$, is defined as a \emph{finite} collection of cuboids which have no common interior point pairwisely, and the union of which is the cuboid itself $I_{\bv a, \bv b}$.
\end{definition}

\begin{definition}[Mesh]
	The \indexbf{mesh} of a partition $P$ is the maximum diametre of the cuboids in $P$:
	\begin{equation*}
		\indexmath[lambda(P)]{\lambda(P)} := \max \{d(I') \mid I' \in P\}.
	\end{equation*}
\end{definition}

\begin{definition}[Distinguished points]
	The image of a choose function from $P$ to $I$ is the distinguished points of $P$, denoted by $\bv \xi_j \in I_j$, $I_j \in P$, $j \in \card P$. $\bv \xi := (\bv \xi_j)_{j \in \card P}$.
\end{definition}

All partitions of a cuboid $I$ is denoted by $\mathfrak P(I)$.
Now define a filter base $\lambda(P) \to 0$, the elements of which are $B_\delta := \{(P, \bv \xi) \in \mathfrak P(I) \mid \lambda(P) < \delta\}$, $\delta \in \mathbb R_+$.

\begin{definition}[Riemann sum]
	Let $X := \prod_{i \in n} X_i$, $Y$ be normed spaces, where $X_i$ are 1-D spaces.
	Let $I$ be a cuboid in $X$, $f \in Y^I$, $(P, \bv \xi) \in \mathfrak P(I)$. 
	$N := \card P$, $P := \{I_j \mid j \in N\}$.
	The \indexbf{Riemann sum} of $f$ over $P$ with distinguished points $\bv \xi$ is defined as:
	\begin{equation*}
		\indexmath[sigma(f, P, xi)]{\sigma(f, P, \bv \xi)} := \sum_{j \in N} f(\bv \xi_j) \mu(I_j).
	\end{equation*}
\end{definition}

\begin{definition}{Riemann integral}
	If the following limit exists, we define:
	\begin{equation*}
		\indexmath[int I f(x) dx]{\int\limits_I f(\bv x) \dif \bv x} := \lim_{\lambda(P) \to 0} \sigma(f, P, \bv \xi)
	\end{equation*}
	as the \indexbf{Riemann integral} of $f$ on $I$.
\end{definition}

\begin{definition}[Riemann integrable]
	If the integral of $f$ in $I$ exists, we call $f$ {Riemann integrable}. The Riemann integrable functions on $I$ is denoted by $\indexmath[R(I)]{\mathfrak R(I)}$.
\end{definition}

\begin{theorem}[Riemann integrable then bounded]
	\label{theorem: Riemann integrable then bounded}
	$f \in \mathfrak R(I) \; \to \; \exists M \in \mathbb R_+ \forall \bv x \in I \,(\|f(\bv x)\|_Y < M)$.
\end{theorem}
\begin{proof}
	If $f$ is not bounded, $\forall M \in \mathbb R_+$ there always exists a $\bv x_j \in I_j \in P$, $\forall \delta \in \mathbb R_+$, even if $\lambda(P) < \delta$, $\sigma(f, P, \bv \xi) \geq \|f(\bv x_j)\| \mu(I_j) > M$.
\end{proof}

We say a proposition $p(\bv x)$ holds \indexbf{almost everywhere} or \indexbf{a.e.}\ on $X$, meaning $\exists E \subset X$, s.t.\ $E$ is of measure zero and $\forall \bv x \in (X - E) \big(p (\bv x)\big)$. 

\begin{theorem}[Lebesgue's criterion]
	\label{theorem: Lebesgue's criterion}
	Let $f \in \mathbb R^I$, where $I$ is a cuboid in a $n$-D space.
	$f \in \mathfrak R(I)$ $\IFF$ $f$ is bounded in $I$ and $f$ is almost everywhere continuous on $I$.
\end{theorem}
\begin{proof}
	$\to$: $f \in \mathfrak R(I) \to$ $f$ is bounded on $I$ (Theorem~\ref{theorem: Riemann integrable then bounded}).
	Denote the discontinuous points of $f$ on $I$ by $E$. In another word, $E = \{\bv x \in I \mid \omega(f; \bv x) > 0\}$.

	Now consider a sequence of sets $E_k := \{x \in I \mid \omega(f; \bv x) \geq 1/k\}$, which is monotone, and limits at $E$: $E = \bigcup_{k \in \mathbb N_+} E_k$.

	If $E$ is not of measure zero, since it is a union of a countable sequence, $\exists k_0 \in \mathbb N_+$, $E_{k_0}$ is not of measure zero.

	Assume that there were a partition $P = \{I_j \mid j \in N\}$ of $I$. Let:
	\begin{equation*}
		A = \{I_j \in P \mid I_j \cap E_{k_0} \neq \varnothing \wedge \omega(f; I_i) \geq 1/2k_0\},
	\end{equation*}
	and $B = P - A$.

	Now we prove: $E_{k_0} \subset \cup A$. 
	If a point $\bv x$ of $E_{k_0}$ locates as an interior point in $I_j$, then there exists a neighbourhood of $\bv x$, where the oscillation of $f$ is larger than $1/k_0 - 1/2k_0 = 1/2k_0$
		\footnote{We take the $\varepsilon = 1/2k_0$ in the definition of oscillation at a point (as a limit)}.
	
	Else, if $\bv x$ locates as a boundary point of cuboids in $P$, we denote these cuboids by $C(\bv x) := \{I_j \in P \mid \bv x \in I_j\}$. 
	If (assuming) $\forall I_j \in C(\bv x)$, $\omega(f; I_j) < 1/2k_0$ (that is, $C(\bv x) \cap A \neq \varnothing$). $\forall \varepsilon \in \mathbb R_+$, $\exists \delta \in \mathbb R_+$ s.t.\ $\forall \bv x_1, \bv x_2 \in B(\bv x; \delta)\subset \cup C(\bv x) $, 
	\begin{equation*}
		d(f(\bv x_1), f(\bv x_2)) \leq d(f(\bv x), f(\bv x_1)) + d(f(\bv x), f(\bv x_2)) < \frac{1}{k_0} - \varepsilon.
	\end{equation*}

	Passing $\delta \to 0$, we have: $\forall \varepsilon$, $\omega(f; \bv x) \leq 1/k_0 - \varepsilon$, or $\omega(f; \bv x) < 1/k_0$, which contradicts with the fact that $\bv x \in E_{k_0}$. Hence: there must be a $I_j \in C(\bv x)$, $\omega(f; I_j) \geq 1/2k_0$, therefore such $I_j \in A$.

	In conclusion, we have proved that $A$ covers $E_{k_0}$. 

	Since $E_{k_0}$, by our assumption, is not of measure zero, then $\exists \varepsilon_0 \in \mathbb R_+$, $\sum_{I_j \in A} \mu(I_j) > \varepsilon_0$. Take two sets of distinguished points $\bv \xi$ and $\bv \xi'$, when they belong to $I_j \in A$, we let $d(f(\bv \xi_j), f(\bv \xi'_j)) > 1/3k_0$
		\footnote{which is possible, because $\omega(f; I_j) \geq 1/2k_0$.}, and when $I_j \in B$, $\bv \xi_j = \bv \xi'_j$.
	\begin{equation*}
		d\big(\sigma(f, P, \bv \xi), \sigma(f, P, \bv \xi')\big) 
		= \sum_{I_j \in A} \mu(I_j) d(f(\bv \xi_j), f(\bv \xi'_j))
		> \frac{\varepsilon_0}{3k_0} .
	\end{equation*}

	By Cauchy's criterion, $\sigma(f, P, \bv \xi)$ would have no limit.

	$\gets$: Let $\varepsilon \in \mathbb R_+$ and $E_\varepsilon = \{\bv x \in I \mid \omega(f; \bv x) \geq \varepsilon\}$. Since $f$ is a.e.\ continuous on $I$, $\mu(E_\varepsilon) = 0$.

	Now we prove that $E_\varepsilon$ is closed. If $\bv x \notin E_\varepsilon$ i.e.\ $\omega(f; \bv x) \leq \varepsilon'$ where $\varepsilon' < \varepsilon$. 
	By the definition of the oscillation at a point, $\forall \varepsilon'' \in \mathbb R_+$, there exists a ball $B(\bv x; \delta)$ on which $\omega(f, B(\bv x; \delta)) < \varepsilon' + \varepsilon''$. 
	Let $\varepsilon'' = \varepsilon - \varepsilon'$, and notice that $\omega(f; \bv x') \leq \omega(f, B(\bv x, \delta))$ where $\bv x' \in B(\bv x, \delta)$. 
	Therefore, $B(\bv x; \delta) \subset I - E_\varepsilon$. 
	Hence: $E_\varepsilon$ is closed. 
	
	Since $E_\varepsilon$ is closed in a compact set~$I$
		\footnote{Lemma~\ref{lemma: n-dimensional cuboids are compact}}, 
	we know by Theorem~\ref{theorem: closed subset of compact set} that $E_\varepsilon$ is also compact. 
	By Theorem~\ref{theorem: compact zero measure defined by finite cuboids} we can find a finite cover $C_1 = \{I_j \mid j \in k\}$ of $E_\varepsilon$ with $\sum_{j \in k} \mu(I_j) < \varepsilon$. Now we extend these cuboids by $\alpha > 1$, $\beta > \alpha$ to get $C_2 = \{\alpha I_j \mid j \in k\}$ and $C_3 = \{\beta I_j \mid j \in k\}$.

	Let $\delta = d\big(\cup C_2, \partial (\cup C_3)\big)$. 
	Since any point in $\cup C_2$ is an interior point of one of the $\beta I_j$, we claim: $\delta > 0$.

	Let $K = I - (\cup C_2 - \partial (\cup C_2))$. Obviously $K$ is also compact, and $E_\varepsilon \subset I - K$. $\forall \bv x \in K$, since $\bv x \notin E_\varepsilon$, $\omega(f; \bv x) < \varepsilon$.

	By Theorem~\ref{theorem: generalised Cantor}, $\exists \delta' \in \mathbb R_+$, if $\bv x', \bv x'' \in K$ satisfies that $d(\bv x', \bv x'') < \delta'$, $d(f(\bv x'), f(\bv x'')) < 2\varepsilon$. 
	Let $\delta'' = \min\{\delta, \delta'\}$.

	Assume that there were two partitions $P, P' \in \mathfrak P(I)$ s.t.\ $\lambda(P) < \delta''$, $\lambda(P') < \delta''$. Let $P'' := \{I''_{jj'} := I_j \cap I'_{j'} \mid I_j \in P \wedge I'_{j'} \in P'\}$.

	\begin{align*}
		d\big(\sigma(f, P, \bv \xi), \sigma(f, P'', \bv \xi'')\big)
			&= d\left( 
				\sum_{j \in N} \sum_{j' \in N'} f(\bv \xi_j) \mu(I''_{jj'}), \sum_{j' \in N'}\sum_{j \in N} f(\bv \xi''_{jj'}) \mu(I''_{jj'})
			 \right)
		\\
		&\leq \sum_{j \in N} \sum_{j' \in N'} d\big(f(\bv \xi_j), f(\bv \xi''_{jj'})\big) 
			\mu(I''_{jj'}).
	\end{align*}

	Now we divide $P''$ into two parts: $A := \{I''_{jj'} \in P'' \mid I_j \subset \cup C_3\}$, $B = P'' - A$. 
	We shall see $\cup B \subset K$: if there were a cuboid $I_j$ in $P$ s.t.\ $I_j \cap (I - \cup C_3) \neq \varnothing$, since $\lambda(I_j) < \delta'' \leq \delta$, there is no way that $I_j \cap \cup C_2 \neq \varnothing$.

	We assume the function $f$ to be bounded, let $2M \geq \sup \{d(f(\bv x), f(\bv x')) \mid \bv x, \bv x' \in I\}$.

	Therefore:
	\begin{align*}
		d\big(\sigma(f, P, \bv \xi), \sigma(f, P'', \bv \xi'')\big)
		&\leq \sum_{I''_{jj'} \in A} d\big(f(\bv \xi_j), f(\bv \xi''_{jj'})\big) \mu(I''_{jj'})
			+ \sum_{I''_{jj'} \in B} d\big(f(\bv \xi_j), f(\bv \xi''_{jj'})\big) \mu(I''_{jj'})
		\\
		&<  2 M \sum_{I''_{jj'} \in A} \mu(I''_{jj'}) + \varepsilon \sum_{I''_{jj'} \in B} \mu(I''_{jj'})
		\\
		&\leq 2M \cdot \beta^n \varepsilon + \varepsilon \mu(I)
		=  ( 2M \cdot \beta^n + \mu(I)) \varepsilon.
	\end{align*}

	Similarly we have $d\big(\sigma(f, P', \bv \xi'), \sigma(f, P'', \bv \xi'')\big) < ( 2M \cdot \beta^n + \mu(I)) \varepsilon$, then by triangle inequality:
	\begin{equation*}
		d\big(\sigma(f, P, \bv \xi), \sigma(f, P', \bv \xi')\big) < 2( 2M \cdot \beta^n + \mu(I)) \varepsilon.
	\end{equation*}

	Therefore, $f \in \mathfrak R(I)$.
\end{proof}

\begin{definition}[Darboux sum]
	Let $f \in \mathbb R^I$, where $I$ is a cuboid in a $n$-D space.
	$P = \{I_j \mid j \in N\} \in \mathfrak P(I)$, the \indexbf{Darboux lower sum} and the \indexbf{Darboux upper sum} is defined as:
	\begin{equation*}
		\indexmath[s(f, P)]{s(f, P)} = \sum_{I_j \in P} \mu(I_j) \inf\{f(\bv x) \mid \bv x \in I_j\},
		\quad
		\indexmath[S(f, P)]{S(f, P)} = \sum_{I_j \in P} \mu(I_j) \sup\{f(\bv x) \mid \bv x \in I_j\}.
	\end{equation*}
\end{definition}

\begin{lemma}
	\label{lemma: Darboux sum}
	$\forall P, P' \in \mathfrak P(I)$, $s(f, P) \leq S(f, P')$.
\end{lemma}
\begin{proof}
	Let $P'' := \{I_j \cap I'_j \mid I_{j'} \in P \wedge I'_{j'} \in P'\}$, we have:
	\begin{equation*}
		s(f, P) \leq s(f, P'') \leq S(f, P'') \leq S(f, P').
	\end{equation*}
\end{proof}

\begin{definition}[Darboux integrals]
	Let $f \in \mathbb R^I$, where $I$ is a cuboid in a $n$-D space.
	The \indexbf{lower Darboux integral} and the \indexbf{upper Darboux integral} are defined as:
	\begin{equation*}
		\indexmath[underline I]{\underline{\mathfrak I}} := \sup \{s(f, P) \mid P \in \mathfrak P\},
		\quad
		\indexmath[overline I]{\overline{\mathfrak I}} := \inf \{S(f, P) \mid P \in \mathfrak P\}.
	\end{equation*}
\end{definition}

\begin{theorem}[Darboux theorem]
	\label{theorem: Darboux}
	Let $f \in \mathbb R^I$, where $I$ is a cuboid in a $n$-D space.
	If $f$ is bounded on $I$, then the limits of Darboux sums exist (as $\lambda(P) \to 0$):
	\begin{equation*}
		\underline{\mathfrak I} = \lim_{\lambda(P) \to 0} s(f, P),
		\quad
		\overline{\mathfrak I} = \lim_{\lambda(P) \to 0} S(f, P).
	\end{equation*}
\end{theorem}
\begin{proof}
	We will only prove the lower Darboux theorem.

	$\forall \varepsilon \in \mathbb R_+$, $\exists P_\varepsilon \in \mathfrak P(I)$ s.t.\ $s(f, P_\varepsilon) > \underline{\mathfrak I} - \varepsilon$.
	Let $\varGamma_\varepsilon := \bigcup_{I_j \in P_\varepsilon} \partial I_j$.
	Obviously, $\lambda(\varGamma_\varepsilon) = 0$.

	We claim that: $\exists \delta \in \mathbb R_+$ s.t.\ $\forall P \in \mathfrak P$, if $\lambda(P) < \delta$, then
	\begin{equation*}
		\sum_{\substack{I_j \in P;\\ I_j \cap \varGamma_\varepsilon \neq \varnothing}} \mu(I_j) < \varepsilon.
	\end{equation*}
	This can be proved by assuming the opposite, then there exists a lower bound (that is non-zero) for the sum of the measure of the cuboids that covers $\varGamma_\varepsilon$, which contradicts with the fact that $\lambda(\varGamma_\varepsilon) = 0$.

	Now let $P' := \{I_j \cap J_{j'} \mid I_j \in P_\varepsilon \wedge J_{j'} \in P\}$, we can see:
	\begin{equation*}
		\underline{\mathfrak I} - \varepsilon < s(f, P_\varepsilon) \leq s(f, P') \leq \underline{\mathfrak I}.
	\end{equation*}

	\begin{align*}
		&|s(f, P') - s(f, P)| 
		\\
		&= \left|
			\sum_{\substack{J_{j'} \in P,\\ J_{j'} \cap \varGamma_\varepsilon \neq \varnothing}}
				\left(
					\sum_{I_j \in P_\varepsilon} \inf\{f(\bv x)\mid \bv x \in J_{j'} \cap I_j\} \mu(J_{j'} \cap I_j)
					-
					\inf\{f(\bv x)\mid \bv x \in J_{j'}\} \mu(J_{j'})
				\right)
		\right|
		\\
		&\leq M \left|
		\sum_{\substack{J_{j'} \in P,\\ J_{j'} \cap \varGamma_\varepsilon \neq \varnothing}}
			\left(
				\sum_{I_j \in P_\varepsilon} \mu(J_{j'} \cap I_j)
				+ \mu(J_{j'})
			\right)
		\right|
		= 2M \sum_{\substack{J_{j'} \in P,\\ J_{j'} \cap \varGamma_\varepsilon \neq \varnothing}}\mu(J_{j'}) < 2M \varepsilon.
	\end{align*}

	Hence: $s(f, P') > s(f, P) - 2M \varepsilon > \underline{\mathfrak I} - \varepsilon$, or, $\underline{\mathfrak I} \geq s(f, P) > (2M + 1)\underline{\mathfrak I} - \varepsilon$. 
	Therefore:
	\begin{equation*}
		\lim_{\lambda(P) \to 0} s(f, P) = \underline{\mathfrak I}.
	\end{equation*}
\end{proof}

\begin{theorem}[Darboux's criterion]
	\label{theorem: Darboux's criterion}
	Let $f \in \mathbb R^I$, where $I$ is a cuboid in a $n$-D space.
	$f \in \mathfrak R(I)$ $\IFF$ $f$ is bounded on $I$, and $\underline{\mathfrak I} = \overline{\mathfrak I}$.
\end{theorem}
\begin{proof}
	$\to$: If $f \in \mathfrak R(I)$, $f$ is bounded (Theorem~\ref{theorem: Riemann integrable then bounded}), then both upper integral and lower integral exists. 
	As $\lambda(P) \to 0$, the infimum and supremum of Riemann sums must converge to the Riemann integral itself.

	$\gets$: We only need to notice that $s(f, P) \leq \sigma(f, P, \bv \xi) \leq S(f, P)$.
\end{proof}

\section{Riemann Integral over Jordan Measurable sets}

\begin{definition}[Jordan Measurable]
	A set $E$ in a $n$-D normed space $X$ is said to be \indexbf{Jordan measurable} if it is bounded, and its boundary $\partial E$ is of measure zero.
\end{definition}

In fact, Jordan measurable set is not a $\sigma$-algeba. 
For example, sets of a single points in $\mathbb R^n$ is Jordan measurable, but their countable union $\mathbb Q^n \cap [0, 1]^n$ is not Jordan measurable.

\begin{lemma}[Jordan measurable sets is closed under finite union, finite intersection and difference]
	\label{lemma: Jordan measurable sets is closed under finite union, finite intersection and difference}
	If $A$, $B$ are two Jordan measurable sets, $A \cap B$, $A \cup B$, $A - B$ are also Jordan measurable.
\end{lemma}
\begin{proof}
	Only to notice that $\partial(A \cup B) \subset \partial A \cup \partial B$, $\partial(A \cap B) \subset \partial A \cup \partial B$, $\partial(A - B) \subset \partial A \cup \partial B$.
\end{proof}

\begin{definition}[Characteristic function]
	Let $E$ be a set in a $n$-D normed space $X$, $\chi_E \in X \to 2$ is defined as:
	\begin{equation*}
		\chi_E(\bv x) := \begin{cases}
			1 & \bv x \in E,
			\\
			0 & \bv x \notin E.
		\end{cases}
	\end{equation*}
\end{definition}

If a function $f$ is defined on $E$, and $E \subset I$ where $I$ is a cuboid. 
By default, we assign any values to $f(\bv x)$ when $\bv x \in I - E$, so that $\chi_E(\bv x) f(\bv x)$ is considered equal to $f(\bv x)$ when $\bv x \in E$, $\chi_E(\bv x) f(\bv x)$ is zero when $\bv x \notin E$. 
We might denote the function $\bv x \mapsto \chi_E(\bv x) f(\bv x)$ by $\chi_E f$.

\begin{lemma}
	Let $f \in Y^E$ where $E$ is a set in $n$-D normed space $X$ and $Y$ is a normed space.
	$E \subset I' \cap I''$ where $I'$ and $I''$ are cuboids in $X$. 
	If $\chi_E \cdot f|_I \in \mathfrak R(I)$, then $\chi_E \cdot f|_{I'} \in \mathfrak R(I')$, and
	\begin{equation*}
		\int\limits_{I} \chi_E(\bv x) f(\bv x) \dif \bv x,
			= \int\limits_{I'} \chi_E(\bv x) f(\bv x) \dif \bv x.
	\end{equation*} 
\end{lemma}
\begin{proof}
	Let $I = I' \cap I''$. 

	Since all discontinuous points of $\chi_E f$ are contained in $E \cup \partial E = \overline{E}\subset I$\footnote{The closure of $E$ is the smallest closed set that contain $E$.}, therefore, by Lebesgue's criterion~\ref{theorem: Lebesgue's criterion} if $\chi_E f$ is Riemann integrable in either all of or none of $I$, $I'$ and $I''$.

	If the integrals exist, we choose partitions such that $P \in \mathfrak P(I)$ is a subset of $P' \in \mathfrak P(I')$. Passing $\lambda(P') \to 0$, we can prove the equality.
\end{proof}

\begin{definition}[Riemann integrals over a set]
	Let $f \in Y^E$ where $E$ is a bounded set in $n$-D normed space $X$ and $Y$ is a normed space.
	The Riemann integral of $f$ over $E$ is defined as:
	\begin{equation*}
		\int\limits_E f(\bv x) \dif \bv x := \int\limits_I \chi_E(\bv x) f(\bv x) \dif \bv x,
	\end{equation*}
	where $I$ is a arbitary cuboid that contains $E$.
\end{definition}

\begin{theorem}[Lebesgue's criterion over a set]
	\label{Lebesgue's criterion over a set}
	Let $f \in \mathbb R^E$, where $E$ is a Jordan measurable set in a $n$-D space.
	$f \in \mathfrak R(E)$ $\IFF$ $f$ is bounded in $E$ and $f$ is almost everywhere continuous on $E$.
\end{theorem}
\begin{proof}
	The Lebesgue's criterion over a cuboid~\ref{theorem: Lebesgue's criterion} and the definition of Jordan measurable set.
\end{proof}

The definition of Darboux integrals and the Darboux's criterion can be generalised to Riemann integrals over a bounded set. We might denote the Darboux lower and upper integrals by:
\begin{equation*}
	\indexmath[overline int E f(x) dx]{\overline{\int\limits_E} f(\bv x) \dif \bv x},
	\quad
	\indexmath[underline int E f(x) dx]{\underline{\int\limits_E} f(\bv x) \dif \bv x}.
\end{equation*}

\begin{definition}[Jordan content]
	Let $E$ be a Jordan measurable set. The \indexbf{Jordan content} or the \indexbf{Jordan measure}
		\footnote{Though Jordan content is not a measure.}
	is defined as: 
	\begin{equation*}
		\indexmath[mu E]{\mu(E)} := \int\limits_E 1 \dif \bv x.
	\end{equation*}
\end{definition}

We might call the Jordan content of a set the content, the area or the volume of it.

\begin{definition}[Zero content]
	A set $E$ is said to be of \indexbf{zero content}, if it is Jordan measurable, and $\mu(E) = 0$.
\end{definition}

A set of zero content must be of zero measure.

\begin{theorem}
	A set $E$ is of zero content, iff $\forall \varepsilon \in \mathbb R_+$, $\exists \langle I_j\rangle_{j \in N}$ s.t.\ 
	\begin{equation*}
		E \subset \bigcup_{j \in N} I_j, \quad
		\sum_{j \in N} \mu(I_j) < \varepsilon.
	\end{equation*}
\end{theorem}

\section{Properties of Riemann Integrals}

\begin{theorem}[Integrals are linear operators]
	Let $E$ be a bounded set in an $n$-D normed space $X$, $\mathfrak R(E)$ is a linear space, and $\int_E \dif \bv x \colon \mathfrak R(E) \to Y$ is a linear operator.
\end{theorem}

\begin{theorem}
	If a Riemann integrable function $f \in \mathfrak R(E)$ is a.e. zero over $E$, $\int_E f(\bv x) \dif \bv x = 0$.
\end{theorem}
\begin{proof}
	Choosing distinguished point $\bv \xi$ such that $f(\bv \xi_j) = 0$, the Riemann sum $\sigma(f, P, \bv \xi)$ must be zero, therefore limits to zero as $\lambda(P) \to 0$.
\end{proof}

We can define a equivalence relation $\sim$ on $\mathfrak R(E)$, so that $f \sim g$ as long as $f(\bv x) = g(\bv x)$ a.e.\ in $E$, which induces a equivalence class $\tilde{\mathfrak R}(E)$. 
$\tilde{\mathfrak R}(E)$ is also a linear space, $\int_E \dif \bv x$ is also a linear operators from $\tilde{\mathfrak R}(E)$.

\part{Real Analysis}


\part{Functional Analysis}
\part{Complex Analysis}

%\appendix

\backmatter
\nocite{*} % 这个表示列出所有没有在文中被引用的参考文献
\printbibliography[heading=bibliography, title={Bibliography}]

\indexprologue{Here listed the important symbols used in this notes.}
\printindex[symbol]

\printindex

\end{document}